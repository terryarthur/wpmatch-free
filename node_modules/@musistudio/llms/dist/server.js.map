{
  "version": 3,
  "sources": ["../src/server.ts", "../src/services/config.ts", "../src/utils/log.ts", "../src/api/middleware.ts", "../src/services/provider.ts", "../src/utils/converter.ts", "../src/utils/request.ts", "../src/services/llm.ts", "../src/transformer/anthropic.transformer.ts", "../src/transformer/gemini.transformer.ts", "../src/transformer/deepseek.transformer.ts", "../src/services/transformer.ts", "../src/api/routes.ts"],
  "sourcesContent": ["import Fastify, {\n  FastifyInstance,\n  FastifyReply,\n  FastifyRequest,\n} from \"fastify\";\nimport cors from \"@fastify/cors\";\nimport { configService } from \"./services/config\";\nimport { log } from \"./utils/log\";\nimport { errorHandler } from \"./api/middleware\";\nimport { registerApiRoutes } from \"./api/routes\";\n\n// Server configuration interface\ninterface ServerConfig {\n  port: number;\n  host: string;\n  logger: boolean;\n}\n\n// Application factory\nasync function createApp(): Promise<FastifyInstance> {\n  const fastify = Fastify({\n    logger: configService.get(\"NODE_ENV\") !== \"test\",\n  });\n\n  // Register error handler\n  fastify.setErrorHandler(errorHandler);\n\n  // Register CORS\n  await fastify.register(cors);\n\n  fastify.addHook(\n    \"preHandler\",\n    async (req: FastifyRequest, reply: FastifyReply) => {\n      try {\n        // req.body.model = \"deepseek,deepseek-chat\";\n        if (!req.body || !req.body.model) {\n          return reply\n            .code(400)\n            .send({ error: \"Missing model in request body\" });\n        }\n        const [provider, model] = req.body.model.split(\",\");\n        req.body.model = model;\n        req.provider = provider;\n        return;\n      } catch (err) {\n        req.log.error(\"Error in modelProviderMiddleware:\", err);\n        return reply.code(500).send({ error: \"Internal server error\" });\n      }\n    }\n  );\n\n  // Register all API routes\n  await fastify.register(registerApiRoutes);\n\n  return fastify;\n}\n\n// Server class\nclass Server {\n  private config: ServerConfig;\n\n  constructor() {\n    this.config = {\n      port: parseInt(configService.get(\"PORT\") || \"3000\", 10),\n      host: configService.get(\"HOST\") || \"0.0.0.0\",\n      logger: configService.get(\"NODE_ENV\") !== \"test\",\n    };\n  }\n\n  async start(): Promise<void> {\n    try {\n      const app = await createApp();\n\n      const address = await app.listen({\n        port: this.config.port,\n        host: this.config.host,\n      });\n\n      log(`\uD83D\uDE80 LLM Smart Router API server listening on ${address}`);\n      // Graceful shutdown\n      const shutdown = async (signal: string) => {\n        log(`Received ${signal}, shutting down gracefully...`);\n        await app.close();\n        process.exit(0);\n      };\n\n      process.on(\"SIGINT\", () => shutdown(\"SIGINT\"));\n      process.on(\"SIGTERM\", () => shutdown(\"SIGTERM\"));\n    } catch (error) {\n      log(`Error starting server: ${error}`);\n      process.exit(1);\n    }\n  }\n}\n\n// Initialize and start server\nasync function main() {\n  // Log configuration summary\n  log(\"\uD83D\uDD27 Configuration loaded:\");\n  log(configService.getConfigSummary());\n\n  const server = new Server();\n  await server.start();\n}\n\n// Handle unhandled errors\nprocess.on(\"unhandledRejection\", (reason, promise) => {\n  log(`Unhandled Rejection at: ${promise}, reason: ${reason}`);\n  process.exit(1);\n});\n\nprocess.on(\"uncaughtException\", (error) => {\n  log(`Uncaught Exception: ${error}`);\n  process.exit(1);\n});\n\nif (require.main === module) {\n  main().catch(console.error);\n}\n", "import { readFileSync, existsSync } from \"fs\";\nimport { join } from \"path\";\nimport { config } from \"dotenv\";\n\nexport interface ConfigOptions {\n  envPath?: string;\n  jsonPath?: string;\n  useEnvFile?: boolean;\n  useJsonFile?: boolean;\n  useEnvironmentVariables?: boolean;\n}\n\nexport interface AppConfig {\n  [key: string]: any;\n}\n\nexport class ConfigService {\n  private config: AppConfig = {};\n  private options: ConfigOptions;\n\n  constructor(\n    options: ConfigOptions = {\n      jsonPath: \"./config.json\",\n    }\n  ) {\n    this.options = {\n      envPath: options.envPath || \".env\",\n      jsonPath: options.jsonPath,\n      useEnvFile: options.useEnvFile !== false,\n      useJsonFile: options.useJsonFile !== false,\n      useEnvironmentVariables: options.useEnvironmentVariables !== false,\n      ...options,\n    };\n\n    this.loadConfig();\n  }\n\n  private loadConfig(): void {\n    if (this.options.useEnvFile) {\n      this.loadEnvConfig();\n    }\n\n    if (this.options.useJsonFile && this.options.jsonPath) {\n      this.loadJsonConfig();\n    }\n\n    if (this.options.useEnvironmentVariables) {\n      this.loadEnvironmentVariables();\n    }\n  }\n\n  private loadJsonConfig(): void {\n    if (!this.options.jsonPath) return;\n\n    const jsonPath = this.isAbsolutePath(this.options.jsonPath)\n      ? this.options.jsonPath\n      : join(process.cwd(), this.options.jsonPath);\n\n    if (existsSync(jsonPath)) {\n      try {\n        const jsonContent = readFileSync(jsonPath, \"utf-8\");\n        const jsonConfig = JSON.parse(jsonContent);\n        this.config = { ...this.config, ...jsonConfig };\n        console.log(`Loaded JSON config from: ${jsonPath}`);\n      } catch (error) {\n        console.warn(`Failed to load JSON config from ${jsonPath}:`, error);\n      }\n    } else {\n      console.warn(`JSON config file not found: ${jsonPath}`);\n    }\n  }\n\n  private loadEnvConfig(): void {\n    const envPath = this.isAbsolutePath(this.options.envPath!)\n      ? this.options.envPath!\n      : join(process.cwd(), this.options.envPath!);\n\n    if (existsSync(envPath)) {\n      try {\n        const result = config({ path: envPath });\n        if (result.parsed) {\n          this.config = {\n            ...this.config,\n            ...this.parseEnvConfig(result.parsed),\n          };\n        }\n      } catch (error) {\n        console.warn(`Failed to load .env config from ${envPath}:`, error);\n      }\n    } else {\n      console.warn(`.env file not found: ${envPath}`);\n    }\n  }\n\n  private loadEnvironmentVariables(): void {\n    const envConfig = this.parseEnvConfig(process.env);\n    this.config = { ...this.config, ...envConfig };\n  }\n\n  private parseEnvConfig(\n    env: Record<string, string | undefined>\n  ): Partial<AppConfig> {\n    const parsed: Partial<AppConfig> = {};\n\n    Object.assign(parsed, env);\n\n    return parsed;\n  }\n\n  private isAbsolutePath(path: string): boolean {\n    return path.startsWith(\"/\") || path.includes(\":\");\n  }\n\n  public get<T = any>(key: keyof AppConfig): T | undefined;\n  public get<T = any>(key: keyof AppConfig, defaultValue: T): T;\n  public get<T = any>(key: keyof AppConfig, defaultValue?: T): T | undefined {\n    const value = this.config[key];\n    return value !== undefined ? (value as T) : defaultValue;\n  }\n\n  public getAll(): AppConfig {\n    return { ...this.config };\n  }\n\n  public getHttpsProxy(): string | undefined {\n    return (\n      this.get(\"HTTPS_PROXY\") ||\n      this.get(\"https_proxy\") ||\n      this.get(\"httpsProxy\")\n    );\n  }\n\n  public has(key: keyof AppConfig): boolean {\n    return this.config[key] !== undefined;\n  }\n\n  public set(key: keyof AppConfig, value: any): void {\n    this.config[key] = value;\n  }\n\n  public reload(): void {\n    this.config = {};\n    this.loadConfig();\n  }\n\n  public getConfigSummary(): string {\n    const summary: string[] = [];\n\n    if (this.options.useJsonFile && this.options.jsonPath) {\n      summary.push(`JSON: ${this.options.jsonPath}`);\n    }\n\n    if (this.options.useEnvFile) {\n      summary.push(`ENV: ${this.options.envPath}`);\n    }\n\n    if (this.options.useEnvironmentVariables) {\n      summary.push(\"Environment Variables\");\n    }\n\n    return `Config sources: ${summary.join(\", \")}`;\n  }\n}\n\nexport const configService = new ConfigService();\n", "import fs from \"node:fs\";\n\nconst LOG_FILE = \"app.log\";\n\n\nexport function log(...args: any[]) {\n  console.log(...args);\n  // Check if logging is enabled via environment variable\n  const isLogEnabled = true;\n\n  if (!isLogEnabled) {\n    return;\n  }\n\n  const timestamp = new Date().toISOString();\n  const logMessage = `[${timestamp}] ${\n    Array.isArray(args)\n      ? args\n          .map((arg) =>\n            typeof arg === \"object\" ? JSON.stringify(arg) : String(arg)\n          )\n          .join(\" \")\n      : \"\"\n  }\\n`;\n\n  // Append to log file\n  fs.appendFileSync(LOG_FILE, logMessage, \"utf8\");\n}\n", "import { FastifyRequest, FastifyReply } from \"fastify\";\n\nexport interface ApiError extends Error {\n  statusCode?: number;\n  code?: string;\n  type?: string;\n}\n\nexport function createApiError(\n  message: string,\n  statusCode: number = 500,\n  code: string = \"internal_error\",\n  type: string = \"api_error\"\n): ApiError {\n  const error = new Error(message) as ApiError;\n  error.statusCode = statusCode;\n  error.code = code;\n  error.type = type;\n  return error;\n}\n\nexport async function errorHandler(\n  error: ApiError,\n  request: FastifyRequest,\n  reply: FastifyReply\n) {\n  request.log.error(error);\n\n  const statusCode = error.statusCode || 500;\n  const response = {\n    error: {\n      message: error.message || \"Internal Server Error\",\n      type: error.type || \"api_error\",\n      code: error.code || \"internal_error\",\n    },\n  };\n\n  return reply.code(statusCode).send(response);\n}\n", "import {\n  LLMProvider,\n  RegisterProviderRequest,\n  ModelRoute,\n  RequestRouteInfo,\n  ConfigProvider,\n} from \"../types/llm\";\nimport { log } from \"../utils/log\";\nimport { configService } from \"./config\";\n\nexport class ProviderService {\n  private providers: Map<string, LLMProvider> = new Map();\n  private modelRoutes: Map<string, ModelRoute> = new Map();\n\n  constructor() {\n    this.initializeCustomProviders();\n  }\n\n  private initializeCustomProviders() {\n    const providersConfig = configService.get<ConfigProvider[]>(\"providers\");\n    if (providersConfig && Array.isArray(providersConfig)) {\n      this.initializeFromProvidersArray(providersConfig);\n      return;\n    }\n  }\n\n  private initializeFromProvidersArray(providersConfig: ConfigProvider[]) {\n    providersConfig.forEach((providerConfig: ConfigProvider) => {\n      try {\n        if (\n          !providerConfig.name ||\n          !providerConfig.api_base_url ||\n          !providerConfig.api_key\n        ) {\n          return;\n        }\n\n        this.registerProvider({\n          name: providerConfig.name,\n          baseUrl: providerConfig.api_base_url,\n          apiKey: providerConfig.api_key,\n          models: providerConfig.models || [`${providerConfig.id}-default`],\n          transformer: providerConfig.transformer || {},\n        });\n\n        log(`${providerConfig.name} provider registered`);\n      } catch (error) {\n        log(`${providerConfig.name} provider registered error: ${error}`);\n      }\n    });\n  }\n\n  /**\n   * \u6CE8\u518C\u65B0\u7684\u670D\u52A1\u5546\n   */\n  registerProvider(request: RegisterProviderRequest): LLMProvider {\n    const provider: LLMProvider = {\n      ...request,\n    };\n\n    this.providers.set(provider.name, provider);\n\n    // \u6CE8\u518C\u6A21\u578B\u8DEF\u7531\n    request.models.forEach((model) => {\n      const fullModel = `${provider.name},${model}`;\n      const route: ModelRoute = {\n        provider: provider.name,\n        model,\n        fullModel,\n      };\n      this.modelRoutes.set(fullModel, route);\n      // \u4E5F\u6CE8\u518C\u4E0D\u5E26\u524D\u7F00\u7684\u6A21\u578B\u540D\uFF08\u4E3A\u4E86\u517C\u5BB9\u6027\uFF09\n      if (!this.modelRoutes.has(model)) {\n        this.modelRoutes.set(model, route);\n      }\n    });\n\n    return provider;\n  }\n\n  /**\n   * \u83B7\u53D6\u6240\u6709\u670D\u52A1\u5546\n   */\n  getProviders(): LLMProvider[] {\n    return Array.from(this.providers.values());\n  }\n\n  /**\n   * \u6839\u636E ID \u83B7\u53D6\u670D\u52A1\u5546\n   */\n  getProvider(id: string): LLMProvider | undefined {\n    return this.providers.get(id);\n  }\n\n  /**\n   * \u66F4\u65B0\u670D\u52A1\u5546\n   */\n  updateProvider(\n    id: string,\n    updates: Partial<LLMProvider>\n  ): LLMProvider | null {\n    const provider = this.providers.get(id);\n    if (!provider) {\n      return null;\n    }\n\n    const updatedProvider = {\n      ...provider,\n      ...updates,\n      updatedAt: new Date(),\n    };\n\n    this.providers.set(id, updatedProvider);\n\n    // \u5982\u679C\u66F4\u65B0\u4E86\u6A21\u578B\u5217\u8868\uFF0C\u91CD\u65B0\u6CE8\u518C\u8DEF\u7531\n    if (updates.models) {\n      // \u5220\u9664\u65E7\u7684\u8DEF\u7531\n      provider.models.forEach((model) => {\n        const fullModel = `${provider.id},${model}`;\n        this.modelRoutes.delete(fullModel);\n        this.modelRoutes.delete(model);\n      });\n\n      // \u6DFB\u52A0\u65B0\u7684\u8DEF\u7531\n      updates.models.forEach((model) => {\n        const fullModel = `${provider.id},${model}`;\n        const route: ModelRoute = {\n          providerId: provider.id,\n          model,\n          fullModel,\n        };\n        this.modelRoutes.set(fullModel, route);\n        if (!this.modelRoutes.has(model)) {\n          this.modelRoutes.set(model, route);\n        }\n      });\n    }\n\n    log(`\u2705 \u66F4\u65B0\u670D\u52A1\u5546 ${updatedProvider.name} (${id})`);\n    return updatedProvider;\n  }\n\n  /**\n   * \u5220\u9664\u670D\u52A1\u5546\n   */\n  deleteProvider(id: string): boolean {\n    const provider = this.providers.get(id);\n    if (!provider) {\n      return false;\n    }\n\n    // \u5220\u9664\u76F8\u5173\u7684\u6A21\u578B\u8DEF\u7531\n    provider.models.forEach((model) => {\n      const fullModel = `${provider.id},${model}`;\n      this.modelRoutes.delete(fullModel);\n      this.modelRoutes.delete(model);\n    });\n\n    this.providers.delete(id);\n    log(`\u2705 \u5220\u9664\u670D\u52A1\u5546 ${provider.name} (${id})`);\n    return true;\n  }\n\n  /**\n   * \u5207\u6362\u670D\u52A1\u5546\u72B6\u6001\n   */\n  toggleProvider(id: string, enabled: boolean): boolean {\n    const provider = this.providers.get(id);\n    if (!provider) {\n      return false;\n    }\n\n    provider.enabled = enabled;\n    provider.updatedAt = new Date();\n\n    log(`\u2705 ${enabled ? \"\u542F\u7528\" : \"\u7981\u7528\"}\u670D\u52A1\u5546 ${provider.name} (${id})`);\n    return true;\n  }\n\n  /**\n   * \u89E3\u6790\u6A21\u578B\u8DEF\u7531\n   */\n  resolveModelRoute(modelName: string): RequestRouteInfo | null {\n    const route = this.modelRoutes.get(modelName);\n    if (!route) {\n      return null;\n    }\n\n    const provider = this.providers.get(route.providerId);\n    if (!provider || !provider.enabled) {\n      return null;\n    }\n\n    return {\n      provider,\n      originalModel: modelName,\n      targetModel: route.model,\n    };\n  }\n\n  /**\n   * \u83B7\u53D6\u53EF\u7528\u7684\u6A21\u578B\u540D\u79F0\u5217\u8868\n   */\n  getAvailableModelNames(): string[] {\n    const modelNames: string[] = [];\n    this.providers.forEach((provider) => {\n      if (provider.enabled) {\n        provider.models.forEach((model) => {\n          modelNames.push(model);\n          modelNames.push(`${provider.id},${model}`);\n        });\n      }\n    });\n    return modelNames;\n  }\n\n  /**\n   * \u83B7\u53D6\u6A21\u578B\u8DEF\u7531\u4FE1\u606F\n   */\n  getModelRoutes(): ModelRoute[] {\n    return Array.from(this.modelRoutes.values());\n  }\n\n  /**\n   * \u83B7\u53D6\u53EF\u7528\u6A21\u578B\uFF08\u7528\u4E8EAPI\u54CD\u5E94\uFF09\n   */\n  async getAvailableModels(): Promise<{\n    object: string;\n    data: Array<{\n      id: string;\n      object: string;\n      created: number;\n      owned_by: string;\n      provider: string;\n    }>;\n  }> {\n    const models: Array<{\n      id: string;\n      object: string;\n      created: number;\n      owned_by: string;\n      provider: string;\n    }> = [];\n\n    this.providers.forEach((provider) => {\n      if (provider.enabled) {\n        provider.models.forEach((model) => {\n          models.push({\n            id: model,\n            object: \"model\",\n            created: Math.floor(provider.createdAt.getTime() / 1000),\n            owned_by: provider.name,\n            provider: provider.name,\n          });\n\n          // \u4E5F\u6DFB\u52A0\u5E26\u524D\u7F00\u7684\u6A21\u578B\u540D\n          models.push({\n            id: `${provider.id},${model}`,\n            object: \"model\",\n            created: Math.floor(provider.createdAt.getTime() / 1000),\n            owned_by: provider.name,\n            provider: provider.id,\n          });\n        });\n      }\n    });\n\n    return {\n      object: \"list\",\n      data: models,\n    };\n  }\n}\n", "import type { ChatCompletionMessageParam as OpenAIMessage } from \"openai/resources/chat/completions\";\nimport type { MessageParam as AnthropicMessage } from \"@anthropic-ai/sdk/resources/messages\";\nimport type { ChatCompletionTool } from \"openai/resources/chat/completions\";\nimport type { Tool as AnthropicTool } from \"@anthropic-ai/sdk/resources/messages\";\nimport {\n  UnifiedMessage,\n  UnifiedChatRequest,\n  UnifiedTool,\n  OpenAIChatRequest,\n  AnthropicChatRequest,\n  ConversionOptions,\n} from \"../types/llm\";\nimport { log } from \"./log\";\n\nexport function convertToolsToOpenAI(\n  tools: UnifiedTool[]\n): ChatCompletionTool[] {\n  return tools.map((tool) => ({\n    type: \"function\" as const,\n    function: {\n      name: tool.function.name,\n      description: tool.function.description,\n      parameters: tool.function.parameters,\n    },\n  }));\n}\n\nexport function convertToolsToAnthropic(tools: UnifiedTool[]): AnthropicTool[] {\n  return tools.map((tool) => ({\n    name: tool.function.name,\n    description: tool.function.description,\n    input_schema: tool.function.parameters,\n  }));\n}\n\nexport function convertToolsFromOpenAI(\n  tools: ChatCompletionTool[]\n): UnifiedTool[] {\n  return tools.map((tool) => ({\n    type: \"function\" as const,\n    function: {\n      name: tool.function.name,\n      description: tool.function.description || \"\",\n      parameters: tool.function.parameters as any,\n    },\n  }));\n}\n\nexport function convertToolsFromAnthropic(\n  tools: AnthropicTool[]\n): UnifiedTool[] {\n  return tools.map((tool) => ({\n    type: \"function\" as const,\n    function: {\n      name: tool.name,\n      description: tool.description || \"\",\n      parameters: tool.input_schema as any,\n    },\n  }));\n}\n\nexport function convertToOpenAI(\n  request: UnifiedChatRequest\n): OpenAIChatRequest {\n  const messages: OpenAIMessage[] = [];\n  const toolResponsesQueue: Map<string, any> = new Map(); // \u7528\u4E8E\u5B58\u50A8\u5DE5\u5177\u54CD\u5E94\n\n  request.messages.forEach((msg) => {\n    if (msg.role === \"tool\" && msg.tool_call_id) {\n      if (!toolResponsesQueue.has(msg.tool_call_id)) {\n        toolResponsesQueue.set(msg.tool_call_id, []);\n      }\n      toolResponsesQueue.get(msg.tool_call_id).push({\n        role: \"tool\",\n        content: msg.content,\n        tool_call_id: msg.tool_call_id,\n      });\n    }\n  });\n\n  for (let i = 0; i < request.messages.length; i++) {\n    const msg = request.messages[i];\n\n    if (msg.role === \"tool\") {\n      continue;\n    }\n\n    const message: any = {\n      role: msg.role,\n      content: msg.content,\n    };\n\n    if (msg.tool_calls && msg.tool_calls.length > 0) {\n      message.tool_calls = msg.tool_calls;\n      if (message.content === null) {\n        message.content = null;\n      }\n    }\n\n    messages.push(message);\n\n    if (\n      msg.role === \"assistant\" &&\n      msg.tool_calls &&\n      msg.tool_calls.length > 0\n    ) {\n      for (const toolCall of msg.tool_calls) {\n        if (toolResponsesQueue.has(toolCall.id)) {\n          const responses = toolResponsesQueue.get(toolCall.id);\n\n          responses.forEach((response) => {\n            messages.push(response);\n          });\n\n          toolResponsesQueue.delete(toolCall.id);\n        } else {\n          messages.push({\n            role: \"tool\",\n            content: JSON.stringify({\n              success: true,\n              message: \"Tool call executed successfully\",\n              tool_call_id: toolCall.id,\n            }),\n            tool_call_id: toolCall.id,\n          } as any);\n        }\n      }\n    }\n  }\n\n  if (toolResponsesQueue.size > 0) {\n    for (const [id, responses] of toolResponsesQueue.entries()) {\n      responses.forEach((response) => {\n        messages.push(response);\n      });\n    }\n  }\n\n  const result: any = {\n    messages,\n    model: request.model,\n    max_tokens: request.max_tokens,\n    temperature: request.temperature,\n    stream: request.stream,\n  };\n\n  if (request.tools && request.tools.length > 0) {\n    result.tools = convertToolsToOpenAI(request.tools);\n    if (request.tool_choice) {\n      if (request.tool_choice === \"auto\" || request.tool_choice === \"none\") {\n        result.tool_choice = request.tool_choice;\n      } else {\n        result.tool_choice = {\n          type: \"function\",\n          function: { name: request.tool_choice },\n        };\n      }\n    }\n  }\n\n  return result;\n}\n\nexport function convertToAnthropic(\n  request: UnifiedChatRequest\n): AnthropicChatRequest {\n  // \u63D0\u53D6system\u6D88\u606F\n  const systemMessages = request.messages.filter(\n    (msg) => msg.role === \"system\"\n  );\n  const nonSystemMessages = request.messages.filter(\n    (msg) => msg.role !== \"system\"\n  );\n\n  // Anthropic\u8981\u6C42system\u6D88\u606F\u5355\u72EC\u5904\u7406\n  const system =\n    systemMessages.length > 0\n      ? systemMessages.map((msg) => msg.content).join(\"\\n\")\n      : undefined;\n\n  const messages: AnthropicMessage[] = [];\n\n  // \u5904\u7406\u6D88\u606F\uFF0C\u5408\u5E76\u5DE5\u5177\u8C03\u7528\u548C\u5DE5\u5177\u54CD\u5E94\n  for (let i = 0; i < nonSystemMessages.length; i++) {\n    const msg = nonSystemMessages[i];\n\n    if (msg.role === \"tool\") {\n      // \u8DF3\u8FC7tool\u6D88\u606F\uFF0C\u5B83\u4EEC\u4F1A\u88AB\u5408\u5E76\u5230\u5408\u9002\u7684\u7528\u6237\u6D88\u606F\u4E2D\n      continue;\n    }\n\n    const message: any = {\n      role: msg.role as \"user\" | \"assistant\",\n    };\n\n    // \u5904\u7406tool_calls\u8F6C\u6362\u4E3AAnthropic\u683C\u5F0F\n    if (msg.tool_calls && msg.tool_calls.length > 0) {\n      log(\"\uD83D\uDD27 \u8F6C\u6362tool_calls\u4E3AAnthropic\u683C\u5F0F\");\n      const content: any[] = [];\n\n      // \u5982\u679C\u6709\u6587\u672C\u5185\u5BB9\uFF0C\u5148\u6DFB\u52A0\u6587\u672C (\u6CE8\u610F: null\u8F6C\u6362\u540E\u53EF\u80FD\u53D8\u6210\u5B57\u7B26\u4E32\"null\")\n      if (\n        msg.content &&\n        msg.content !== null &&\n        msg.content !== \"null\" &&\n        msg.content.trim()\n      ) {\n        content.push({\n          type: \"text\",\n          text: msg.content,\n        });\n      }\n\n      // \u6DFB\u52A0\u5DE5\u5177\u8C03\u7528\n      msg.tool_calls.forEach((toolCall) => {\n        content.push({\n          type: \"tool_use\",\n          id: toolCall.id,\n          name: toolCall.function.name,\n          input: JSON.parse(toolCall.function.arguments || \"{}\"),\n        });\n      });\n\n      message.content = content;\n    } else if (msg.role === \"user\") {\n      // \u7528\u6237\u6D88\u606F\uFF1A\u68C0\u67E5\u524D\u9762\u662F\u5426\u6709\u5DE5\u5177\u54CD\u5E94\u9700\u8981\u5408\u5E76\n      const content: any[] = [];\n\n      // \u67E5\u627E\u524D\u9762\u7684tool\u6D88\u606F\uFF08\u5728\u5F53\u524D\u7528\u6237\u6D88\u606F\u4E4B\u524D\uFF09\n      let j = i - 1;\n      const toolResponses: any[] = [];\n      while (j >= 0 && nonSystemMessages[j].role === \"tool\") {\n        toolResponses.unshift(nonSystemMessages[j]); // \u4FDD\u6301\u987A\u5E8F\n        j--;\n      }\n\n      // \u5982\u679C\u627E\u5230\u4E86\u5DE5\u5177\u54CD\u5E94\uFF0C\u5148\u6DFB\u52A0\u5B83\u4EEC\n      toolResponses.forEach((toolMsg) => {\n        content.push({\n          type: \"tool_result\",\n          tool_use_id: toolMsg.tool_call_id, // \u4F7F\u7528 tool_call_id \u6620\u5C04\u5230 tool_use_id\n          content: toolMsg.content || \"\",\n        });\n      });\n\n      // \u7136\u540E\u6DFB\u52A0\u7528\u6237\u6587\u672C\u5185\u5BB9\n      if (msg.content && msg.content.trim()) {\n        content.push({\n          type: \"text\",\n          text: msg.content,\n        });\n      }\n\n      // \u5982\u679C\u53EA\u6709\u6587\u672C\u5185\u5BB9\uFF0C\u76F4\u63A5\u4F7F\u7528\u5B57\u7B26\u4E32\n      if (content.length === 1 && content[0].type === \"text\") {\n        message.content = content[0].text;\n      } else if (content.length === 0) {\n        // \u5982\u679C\u6CA1\u6709\u5185\u5BB9\uFF0C\u8BBE\u7F6E\u4E3A\u7A7A\u5B57\u7B26\u4E32\n        message.content = \"\";\n      } else {\n        message.content = content;\n      }\n    } else {\n      // \u666E\u901A\u6587\u672C\u6D88\u606F\n      message.content = msg.content || \"\";\n    }\n\n    messages.push(message);\n  }\n\n  // \u5982\u679C\u6700\u540E\u8FD8\u6709tool\u6D88\u606F\u6CA1\u6709\u88AB\u5904\u7406\uFF08\u5373\u6CA1\u6709\u540E\u7EED\u7528\u6237\u6D88\u606F\uFF09\uFF0C\n  // \u6211\u4EEC\u9700\u8981\u521B\u5EFA\u4E00\u4E2A\u865A\u62DF\u7684\u7528\u6237\u6D88\u606F\u6765\u5305\u542B\u8FD9\u4E9B\u5DE5\u5177\u54CD\u5E94\n  const lastProcessedIndex = nonSystemMessages.length - 1;\n  let hasUnprocessedToolMessages = false;\n  const unprocessedToolMessages: any[] = [];\n\n  // \u4ECE\u540E\u5F80\u524D\u67E5\u627E\u672A\u5904\u7406\u7684tool\u6D88\u606F\n  for (\n    let i = lastProcessedIndex;\n    i >= 0 && nonSystemMessages[i].role === \"tool\";\n    i--\n  ) {\n    unprocessedToolMessages.unshift(nonSystemMessages[i]);\n    hasUnprocessedToolMessages = true;\n  }\n\n  if (hasUnprocessedToolMessages) {\n    log(\"\uD83D\uDD27 \u53D1\u73B0\u672A\u5904\u7406\u7684\u5DE5\u5177\u54CD\u5E94\uFF0C\u521B\u5EFA\u865A\u62DF\u7528\u6237\u6D88\u606F\");\n    const toolResultsContent: any[] = [];\n\n    unprocessedToolMessages.forEach((toolMsg) => {\n      toolResultsContent.push({\n        type: \"tool_result\",\n        tool_use_id: toolMsg.tool_call_id, // \u4F7F\u7528 tool_call_id \u6620\u5C04\u5230 tool_use_id\n        content: toolMsg.content || \"\",\n      });\n    });\n\n    // \u521B\u5EFA\u4E00\u4E2A\u5305\u542B\u5DE5\u5177\u7ED3\u679C\u7684\u7528\u6237\u6D88\u606F\n    messages.push({\n      role: \"user\",\n      content: toolResultsContent,\n    });\n  }\n\n  const result: any = {\n    messages,\n    model: request.model,\n    max_tokens: request.max_tokens || 1024, // Anthropic\u8981\u6C42\u5FC5\u987B\u63D0\u4F9Bmax_tokens\n    temperature: request.temperature,\n    stream: request.stream,\n    system,\n  };\n\n  // \u6DFB\u52A0\u5DE5\u5177\u652F\u6301\n  if (request.tools && request.tools.length > 0) {\n    result.tools = convertToolsToAnthropic(request.tools);\n\n    // Anthropic\u5DE5\u5177\u9009\u62E9\u5904\u7406\n    if (request.tool_choice) {\n      if (request.tool_choice === \"auto\") {\n        result.tool_choice = { type: \"auto\" };\n      } else if (request.tool_choice === \"none\") {\n        // Anthropic\u6CA1\u6709\u76F4\u63A5\u7684none\u9009\u9879\uFF0C\u901A\u8FC7\u4E0D\u4F20tools\u6765\u5B9E\u73B0\n        delete result.tools;\n      } else {\n        // \u7279\u5B9A\u5DE5\u5177\u9009\u62E9\n        result.tool_choice = {\n          type: \"tool\",\n          name: request.tool_choice,\n        };\n      }\n    }\n  }\n\n  return result;\n}\n\nfunction isToolCallContent(content: string): boolean {\n  try {\n    const parsed = JSON.parse(content);\n    return (\n      Array.isArray(parsed) &&\n      parsed.some((item) => item.type === \"tool_use\" && item.id && item.name)\n    );\n  } catch {\n    return false;\n  }\n}\n\nexport function convertFromOpenAI(\n  request: OpenAIChatRequest\n): UnifiedChatRequest {\n  const messages: UnifiedMessage[] = request.messages.map((msg) => {\n    if (\n      msg.role === \"assistant\" &&\n      typeof msg.content === \"string\" &&\n      isToolCallContent(msg.content)\n    ) {\n      try {\n        const toolCalls = JSON.parse(msg.content);\n        const convertedToolCalls = toolCalls.map((call: any) => ({\n          id: call.id,\n          type: \"function\" as const,\n          function: {\n            name: call.name,\n            arguments: JSON.stringify(call.input || {}),\n          },\n        }));\n\n        return {\n          role: msg.role as \"user\" | \"assistant\" | \"system\",\n          content: null,\n          tool_calls: convertedToolCalls,\n        };\n      } catch (error) {\n        return {\n          role: msg.role as \"user\" | \"assistant\" | \"system\",\n          content: msg.content,\n        };\n      }\n    }\n\n    if (msg.role === \"tool\") {\n      return {\n        role: msg.role as \"tool\",\n        content:\n          typeof msg.content === \"string\"\n            ? msg.content\n            : JSON.stringify(msg.content),\n        tool_call_id: (msg as any).tool_call_id,\n      };\n    }\n\n    return {\n      role: msg.role as \"user\" | \"assistant\" | \"system\",\n      content:\n        typeof msg.content === \"string\"\n          ? msg.content\n          : JSON.stringify(msg.content),\n      ...((msg as any).tool_calls && { tool_calls: (msg as any).tool_calls }),\n    };\n  });\n\n  const result: UnifiedChatRequest = {\n    messages,\n    model: request.model,\n    max_tokens: request.max_tokens,\n    temperature: request.temperature,\n    stream: request.stream,\n  };\n\n  if (request.tools && request.tools.length > 0) {\n    result.tools = convertToolsFromOpenAI(request.tools);\n\n    if (request.tool_choice) {\n      if (typeof request.tool_choice === \"string\") {\n        result.tool_choice = request.tool_choice;\n      } else if (request.tool_choice.type === \"function\") {\n        result.tool_choice = request.tool_choice.function.name;\n      }\n    }\n  }\n\n  return result;\n}\n\nexport function convertFromAnthropic(\n  request: AnthropicChatRequest\n): UnifiedChatRequest {\n  const messages: UnifiedMessage[] = [];\n\n  if (request.system) {\n    messages.push({\n      role: \"system\",\n      content: request.system,\n    });\n  }\n  const pendingToolCalls: any[] = [];\n  const pendingTextContent: string[] = [];\n  let lastRole: string | null = null;\n\n  for (let i = 0; i < request.messages.length; i++) {\n    const msg = request.messages[i];\n\n    if (typeof msg.content === \"string\") {\n      if (\n        lastRole === \"assistant\" &&\n        pendingToolCalls.length > 0 &&\n        msg.role !== \"assistant\"\n      ) {\n        const assistantMessage: UnifiedMessage = {\n          role: \"assistant\",\n          content: pendingTextContent.join(\"\") || null,\n          tool_calls:\n            pendingToolCalls.length > 0 ? pendingToolCalls : undefined,\n        };\n        if (assistantMessage.tool_calls && pendingTextContent.length === 0) {\n          assistantMessage.content = null;\n        }\n        messages.push(assistantMessage);\n        pendingToolCalls.length = 0;\n        pendingTextContent.length = 0;\n      }\n\n      messages.push({\n        role: msg.role,\n        content: msg.content,\n      });\n    } else if (Array.isArray(msg.content)) {\n      const textBlocks: string[] = [];\n      const toolCalls: any[] = [];\n      const toolResults: any[] = [];\n\n      msg.content.forEach((block) => {\n        if (block.type === \"text\") {\n          textBlocks.push(block.text);\n        } else if (block.type === \"tool_use\") {\n          toolCalls.push({\n            id: block.id,\n            type: \"function\" as const,\n            function: {\n              name: block.name,\n              arguments: JSON.stringify(block.input || {}),\n            },\n          });\n        } else if (block.type === \"tool_result\") {\n          toolResults.push(block);\n        }\n      });\n\n      if (toolResults.length > 0) {\n        if (lastRole === \"assistant\" && pendingToolCalls.length > 0) {\n          const assistantMessage: UnifiedMessage = {\n            role: \"assistant\",\n            content: pendingTextContent.join(\"\") || null,\n            tool_calls: pendingToolCalls,\n          };\n          if (pendingTextContent.length === 0) {\n            assistantMessage.content = null;\n          }\n          messages.push(assistantMessage);\n          pendingToolCalls.length = 0;\n          pendingTextContent.length = 0;\n        }\n\n        toolResults.forEach((toolResult) => {\n          messages.push({\n            role: \"tool\",\n            content:\n              typeof toolResult.content === \"string\"\n                ? toolResult.content\n                : JSON.stringify(toolResult.content),\n            tool_call_id: toolResult.tool_use_id,\n          });\n        });\n      } else if (msg.role === \"assistant\") {\n        if (lastRole === \"assistant\") {\n          pendingToolCalls.push(...toolCalls);\n          pendingTextContent.push(...textBlocks);\n        } else {\n          if (pendingToolCalls.length > 0) {\n            const prevAssistantMessage: UnifiedMessage = {\n              role: \"assistant\",\n              content: pendingTextContent.join(\"\") || null,\n              tool_calls: pendingToolCalls,\n            };\n            if (pendingTextContent.length === 0) {\n              prevAssistantMessage.content = null;\n            }\n            messages.push(prevAssistantMessage);\n          }\n\n          pendingToolCalls.length = 0;\n          pendingTextContent.length = 0;\n          pendingToolCalls.push(...toolCalls);\n          pendingTextContent.push(...textBlocks);\n        }\n      } else {\n        if (lastRole === \"assistant\" && pendingToolCalls.length > 0) {\n          const assistantMessage: UnifiedMessage = {\n            role: \"assistant\",\n            content: pendingTextContent.join(\"\") || null,\n            tool_calls: pendingToolCalls,\n          };\n          if (pendingTextContent.length === 0) {\n            assistantMessage.content = null;\n          }\n          messages.push(assistantMessage);\n          pendingToolCalls.length = 0;\n          pendingTextContent.length = 0;\n        }\n\n        const message: UnifiedMessage = {\n          role: msg.role,\n          content: textBlocks.join(\"\") || null,\n        };\n\n        if (toolCalls.length > 0) {\n          message.tool_calls = toolCalls;\n          if (textBlocks.length === 0) {\n            message.content = null;\n          }\n        }\n\n        messages.push(message);\n      }\n    } else {\n      if (lastRole === \"assistant\" && pendingToolCalls.length > 0) {\n        const assistantMessage: UnifiedMessage = {\n          role: \"assistant\",\n          content: pendingTextContent.join(\"\") || null,\n          tool_calls: pendingToolCalls,\n        };\n        if (pendingTextContent.length === 0) {\n          assistantMessage.content = null;\n        }\n        messages.push(assistantMessage);\n        pendingToolCalls.length = 0;\n        pendingTextContent.length = 0;\n      }\n\n      messages.push({\n        role: msg.role,\n        content: JSON.stringify(msg.content),\n      });\n    }\n\n    lastRole = msg.role;\n  }\n\n  if (lastRole === \"assistant\" && pendingToolCalls.length > 0) {\n    const assistantMessage: UnifiedMessage = {\n      role: \"assistant\",\n      content: pendingTextContent.join(\"\") || null,\n      tool_calls: pendingToolCalls,\n    };\n    if (pendingTextContent.length === 0) {\n      assistantMessage.content = null;\n    }\n    messages.push(assistantMessage);\n  }\n\n  const result: UnifiedChatRequest = {\n    messages,\n    model: request.model,\n    max_tokens: request.max_tokens,\n    temperature: request.temperature,\n    stream: request.stream,\n  };\n\n  if (request.tools && request.tools.length > 0) {\n    result.tools = convertToolsFromAnthropic(request.tools);\n\n    if (request.tool_choice) {\n      if (request.tool_choice.type === \"auto\") {\n        result.tool_choice = \"auto\";\n      } else if (request.tool_choice.type === \"tool\") {\n        result.tool_choice = request.tool_choice.name;\n      }\n    }\n  }\n\n  return result;\n}\n\nexport function convertRequest(\n  request: OpenAIChatRequest | AnthropicChatRequest | UnifiedChatRequest,\n  options: ConversionOptions\n): OpenAIChatRequest | AnthropicChatRequest {\n  let unifiedRequest: UnifiedChatRequest;\n  if (options.sourceProvider === \"openai\") {\n    unifiedRequest = convertFromOpenAI(request as OpenAIChatRequest);\n  } else if (options.sourceProvider === \"anthropic\") {\n    unifiedRequest = convertFromAnthropic(request as AnthropicChatRequest);\n  } else {\n    unifiedRequest = request as UnifiedChatRequest;\n  }\n\n  if (options.targetProvider === \"openai\") {\n    return convertToOpenAI(unifiedRequest);\n  } else {\n    return convertToAnthropic(unifiedRequest);\n  }\n}\n", "import { UnifiedChatRequest } from \"../types/llm\";\nimport { configService } from \"../services/config\";\nimport { ProxyAgent } from \"undici\";\n\nexport function sendUnifiedRequest(\n  url: URL | string,\n  request: UnifiedChatRequest,\n  config: any\n): Promise<Response> {\n  const headers = new Headers({\n    \"Content-Type\": \"application/json\",\n  });\n  if (config.headers) {\n    Object.entries(config.headers).forEach(([key, value]) => {\n      headers.set(key, value as string);\n    });\n  }\n  let combinedSignal: AbortSignal;\n  const timeoutSignal = AbortSignal.timeout(config.TIMEOUT ?? 60 * 1000 * 60);\n\n  if (config.signal) {\n    const controller = new AbortController();\n    const abortHandler = () => controller.abort();\n    config.signal.addEventListener(\"abort\", abortHandler);\n    timeoutSignal.addEventListener(\"abort\", abortHandler);\n    combinedSignal = controller.signal;\n  } else {\n    combinedSignal = timeoutSignal;\n  }\n\n  const fetchOptions: RequestInit = {\n    method: \"POST\",\n    headers: headers,\n    body: JSON.stringify(request),\n    signal: combinedSignal,\n  };\n  const httpsProxy = configService.getHttpsProxy();\n  if (httpsProxy && typeof global !== \"undefined\") {\n    (fetchOptions as any).dispatcher = new ProxyAgent(\n      new URL(httpsProxy).toString()\n    );\n  }\n  return fetch(\n    typeof url === \"string\" ? url : url.toString(),\n    fetchOptions\n  );\n}\n", "import type {\n  ChatCompletion,\n  ChatCompletionChunk,\n} from \"openai/resources/chat/completions\";\nimport type { Message } from \"@anthropic-ai/sdk/resources/messages\";\nimport { ProviderService } from \"./provider\";\nimport { convertRequest } from \"../utils/converter\";\nimport {\n  LLMProvider,\n  RegisterProviderRequest,\n  RequestRouteInfo,\n  UnifiedChatRequest,\n  UnifiedTool,\n} from \"../types/llm\";\nimport { log } from \"../utils/log\";\nimport { sendUnifiedRequest } from \"../utils/request\";\n\nexport class LLMService {\n  private providerService: ProviderService;\n\n  constructor() {\n    this.providerService = new ProviderService();\n  }\n\n  registerProvider(request: RegisterProviderRequest): LLMProvider {\n    return this.providerService.registerProvider(request);\n  }\n\n  getProviders(): LLMProvider[] {\n    return this.providerService.getProviders();\n  }\n\n  getProvider(id: string): LLMProvider | undefined {\n    return this.providerService.getProvider(id);\n  }\n\n  updateProvider(\n    id: string,\n    updates: Partial<LLMProvider>\n  ): LLMProvider | null {\n    const result = this.providerService.updateProvider(id, updates);\n    return result;\n  }\n\n  deleteProvider(id: string): boolean {\n    const result = this.providerService.deleteProvider(id);\n    return result;\n  }\n\n  toggleProvider(id: string, enabled: boolean): boolean {\n    return this.providerService.toggleProvider(id, enabled);\n  }\n\n  private resolveRoute(modelName: string): RequestRouteInfo {\n    const route = this.providerService.resolveModelRoute(modelName);\n    if (!route) {\n      throw new Error(\n        `Model ${modelName} not found. Available models: ${this.getAvailableModelNames().join(\n          \", \"\n        )}`\n      );\n    }\n    return route;\n  }\n\n  async handleOpenAIFormatRequest(\n    requestBody: any,\n    signal?: AbortSignal\n  ): Promise<Response> {\n    try {\n      this.validateRequest(requestBody);\n      const modelName = requestBody.model;\n      const route = this.resolveRoute(modelName);\n      const { provider, targetModel } = route;\n      const unifiedReq = this.convertOpenAIToUnified(requestBody);\n      unifiedReq.model = targetModel;\n      let providerRequest: any;\n      if (provider.type === \"anthropic\") {\n        providerRequest = convertRequest(unifiedReq, {\n          sourceProvider: \"openai\",\n          targetProvider: \"anthropic\",\n        });\n      } else {\n        providerRequest = unifiedReq;\n      }\n      if (signal?.aborted) {\n        throw new Error(\"Request was aborted\");\n      }\n      const response = await sendUnifiedRequest(\n        this.getProvider(provider.id)!,\n        providerRequest,\n        { signal }\n      );\n      if (signal?.aborted) {\n        throw new Error(\"Request was aborted\");\n      }\n\n      const isStream = requestBody.stream === true;\n      if (provider.type === \"anthropic\") {\n        if (isStream) {\n          if (!response.body) {\n            throw new Error(\"Stream response body is null\");\n          }\n          const convertedStream = await this.convertAnthropicStreamToOpenAI(\n            response.body\n          );\n          return new Response(convertedStream, {\n            headers: {\n              \"Content-Type\": \"text/event-stream\",\n              \"Cache-Control\": \"no-cache\",\n              Connection: \"keep-alive\",\n            },\n          });\n        } else {\n          const data = await response.json();\n          const openaiResponse = this.convertAnthropicResponseToOpenAI(data);\n          return new Response(JSON.stringify(openaiResponse), {\n            headers: { \"Content-Type\": \"application/json\" },\n          });\n        }\n      } else {\n        return response;\n      }\n    } catch (error) {\n      if (\n        error instanceof Error &&\n        (error.message.includes(\"aborted\") || error.name === \"AbortError\")\n      ) {\n        throw error;\n      }\n\n      if (requestBody?.stream) {\n        const errorStream = this.createOpenAIErrorStream(error as Error);\n        return new Response(errorStream, {\n          headers: {\n            \"Content-Type\": \"text/event-stream\",\n            \"Cache-Control\": \"no-cache\",\n            Connection: \"keep-alive\",\n          },\n        });\n      } else {\n        throw error;\n      }\n    }\n  }\n\n  private convertAnthropicResponseToOpenAI(\n    anthropicResponse: Message\n  ): ChatCompletion {\n    const textContent = anthropicResponse.content.find(\n      (content: any) => content.type === \"text\"\n    ) as any;\n    const toolUseContent = anthropicResponse.content.filter(\n      (content: any) => content.type === \"tool_use\"\n    );\n\n    // \u6784\u5EFAtool_calls\n    const tool_calls = toolUseContent.map((toolUse: any, index: number) => ({\n      id: toolUse.id || `call_${Date.now()}_${index}`,\n      type: \"function\" as const,\n      function: {\n        name: toolUse.name,\n        arguments: JSON.stringify(toolUse.input || {}),\n      },\n    }));\n\n    return {\n      id: `chatcmpl-${Date.now()}`,\n      object: \"chat.completion\",\n      created: Math.floor(Date.now() / 1000),\n      model: anthropicResponse.model,\n      choices: [\n        {\n          index: 0,\n          message: {\n            role: \"assistant\",\n            content: textContent?.text || null,\n            refusal: null,\n            tool_calls: tool_calls.length > 0 ? tool_calls : undefined,\n          },\n          logprobs: null,\n          finish_reason:\n            anthropicResponse.stop_reason === \"end_turn\"\n              ? \"stop\"\n              : anthropicResponse.stop_reason === \"max_tokens\"\n              ? \"length\"\n              : anthropicResponse.stop_reason === \"tool_use\"\n              ? \"tool_calls\"\n              : anthropicResponse.stop_reason === \"stop_sequence\"\n              ? \"stop\"\n              : \"stop\",\n        },\n      ],\n      usage: {\n        prompt_tokens: anthropicResponse.usage.input_tokens,\n        completion_tokens: anthropicResponse.usage.output_tokens,\n        total_tokens:\n          anthropicResponse.usage.input_tokens +\n          anthropicResponse.usage.output_tokens,\n      },\n    };\n  }\n\n  private async convertAnthropicStreamToOpenAI(\n    anthropicStream: ReadableStream\n  ): Promise<ReadableStream> {\n    const readable = new ReadableStream({\n      async start(controller) {\n        const encoder = new TextEncoder();\n        let messageId = \"\";\n        let model = \"unknown\";\n        const toolCalls = new Map<number, any>();\n        let isClosed = false; // \u6807\u8BB0\u63A7\u5236\u5668\u662F\u5426\u5DF2\u5173\u95ED\n\n        // \u5B89\u5168\u7684enqueue\u51FD\u6570\uFF0C\u68C0\u67E5\u63A7\u5236\u5668\u72B6\u6001\n        const safeEnqueue = (data: Uint8Array) => {\n          if (!isClosed) {\n            try {\n              controller.enqueue(data);\n            } catch (error) {\n              if (\n                error instanceof TypeError &&\n                error.message.includes(\"Controller is already closed\")\n              ) {\n                log(\"\u26A0\uFE0F \u63A7\u5236\u5668\u5DF2\u5173\u95ED\uFF0C\u505C\u6B62\u53D1\u9001\u6570\u636E\");\n                isClosed = true;\n              } else {\n                throw error;\n              }\n            }\n          }\n        };\n\n        // \u5B89\u5168\u7684close\u51FD\u6570\n        const safeClose = () => {\n          if (!isClosed) {\n            try {\n              controller.close();\n              isClosed = true;\n            } catch (error) {\n              if (\n                error instanceof TypeError &&\n                error.message.includes(\"Controller is already closed\")\n              ) {\n                log(\"\u26A0\uFE0F \u63A7\u5236\u5668\u5DF2\u7ECF\u5173\u95ED\");\n                isClosed = true;\n              } else {\n                throw error;\n              }\n            }\n          }\n        };\n\n        let reader: ReadableStreamDefaultReader<Uint8Array> | null = null;\n\n        try {\n          reader = anthropicStream.getReader();\n          const decoder = new TextDecoder();\n          let buffer = \"\";\n\n          while (true) {\n            if (isClosed) {\n              log(\"\u26A0\uFE0F \u63A7\u5236\u5668\u5DF2\u5173\u95ED\uFF0C\u9000\u51FA\u6D41\u5904\u7406\");\n              break;\n            }\n\n            const { done, value } = await reader.read();\n            if (done) break;\n\n            buffer += decoder.decode(value, { stream: true });\n            const lines = buffer.split(\"\\n\");\n            buffer = lines.pop() || \"\";\n\n            for (const line of lines) {\n              if (isClosed) break; // \u68C0\u67E5\u662F\u5426\u5DF2\u5173\u95ED\n\n              if (line.startsWith(\"data: \")) {\n                const data = line.slice(6);\n                if (data === \"[DONE]\") continue;\n\n                try {\n                  const chunk = JSON.parse(data);\n                  let openaiChunk: ChatCompletionChunk | null = null;\n\n                  if (chunk.type === \"message_start\" && !isClosed) {\n                    messageId = `chatcmpl-${Date.now()}`;\n                    model = chunk.message?.model || \"unknown\";\n                    openaiChunk = {\n                      id: messageId,\n                      object: \"chat.completion.chunk\",\n                      created: Math.floor(Date.now() / 1000),\n                      model: model,\n                      choices: [\n                        {\n                          index: 0,\n                          delta: {\n                            role: \"assistant\",\n                            content: \"\",\n                          },\n                          logprobs: null,\n                          finish_reason: null,\n                        },\n                      ],\n                    };\n                  } else if (\n                    chunk.type === \"content_block_start\" &&\n                    !isClosed\n                  ) {\n                    const block = (chunk as any).content_block;\n                    if (block?.type === \"tool_use\") {\n                      // \u5F00\u59CB\u5DE5\u5177\u8C03\u7528\n                      const toolCallId =\n                        block.id ||\n                        `call_${Date.now()}_${(chunk as any).index}`;\n                      const toolCall = {\n                        index: (chunk as any).index,\n                        id: toolCallId,\n                        type: \"function\" as const,\n                        function: {\n                          name: block.name,\n                          arguments: \"\",\n                        },\n                      };\n                      toolCalls.set((chunk as any).index, toolCall);\n\n                      openaiChunk = {\n                        id: messageId || `chatcmpl-${Date.now()}`,\n                        object: \"chat.completion.chunk\",\n                        created: Math.floor(Date.now() / 1000),\n                        model: model,\n                        choices: [\n                          {\n                            index: 0,\n                            delta: {\n                              tool_calls: [toolCall],\n                            },\n                            logprobs: null,\n                            finish_reason: null,\n                          },\n                        ],\n                      };\n                    }\n                  } else if (\n                    chunk.type === \"content_block_delta\" &&\n                    !isClosed\n                  ) {\n                    const delta = (chunk as any).delta;\n                    if (delta?.type === \"text_delta\" && delta.text) {\n                      openaiChunk = {\n                        id: messageId || `chatcmpl-${Date.now()}`,\n                        object: \"chat.completion.chunk\",\n                        created: Math.floor(Date.now() / 1000),\n                        model: model,\n                        choices: [\n                          {\n                            index: 0,\n                            delta: { content: delta.text },\n                            logprobs: null,\n                            finish_reason: null,\n                          },\n                        ],\n                      };\n                    } else if (\n                      delta?.type === \"input_json_delta\" &&\n                      delta.partial_json\n                    ) {\n                      // \u5DE5\u5177\u8C03\u7528\u53C2\u6570\u589E\u91CF\n                      const index = (chunk as any).index;\n                      const existingToolCall = toolCalls.get(index);\n                      if (existingToolCall) {\n                        openaiChunk = {\n                          id: messageId || `chatcmpl-${Date.now()}`,\n                          object: \"chat.completion.chunk\",\n                          created: Math.floor(Date.now() / 1000),\n                          model: model,\n                          choices: [\n                            {\n                              index: 0,\n                              delta: {\n                                tool_calls: [\n                                  {\n                                    index: index,\n                                    function: {\n                                      arguments: delta.partial_json,\n                                    },\n                                  },\n                                ],\n                              },\n                              logprobs: null,\n                              finish_reason: null,\n                            },\n                          ],\n                        };\n                      }\n                    }\n                  } else if (\n                    chunk.type === \"message_delta\" &&\n                    (chunk.delta as any)?.stop_reason &&\n                    !isClosed\n                  ) {\n                    const stopReason = (chunk.delta as any).stop_reason;\n                    openaiChunk = {\n                      id: messageId || `chatcmpl-${Date.now()}`,\n                      object: \"chat.completion.chunk\",\n                      created: Math.floor(Date.now() / 1000),\n                      model: model,\n                      choices: [\n                        {\n                          index: 0,\n                          delta: {},\n                          logprobs: null,\n                          finish_reason:\n                            stopReason === \"end_turn\"\n                              ? \"stop\"\n                              : stopReason === \"max_tokens\"\n                              ? \"length\"\n                              : stopReason === \"tool_use\"\n                              ? \"tool_calls\"\n                              : \"stop\",\n                        },\n                      ],\n                    };\n                  }\n\n                  if (openaiChunk && !isClosed) {\n                    const data = `data: ${JSON.stringify(openaiChunk)}\\n\\n`;\n                    safeEnqueue(encoder.encode(data));\n                  }\n                } catch (parseError) {\n                  console.warn(\"Failed to parse chunk:\", parseError);\n                }\n              }\n            }\n          }\n\n          // \u53D1\u9001\u7ED3\u675F\u6807\u8BB0\n          if (!isClosed) {\n            safeEnqueue(encoder.encode(`data: [DONE]\\n\\n`));\n          }\n          safeClose();\n        } catch (error) {\n          console.error(\"\u274C Anthropic\u6D41\u8F6C\u6362\u51FA\u9519:\", error);\n          if (!isClosed) {\n            try {\n              controller.error(error);\n            } catch (controllerError) {\n              log(\"\u26A0\uFE0F \u65E0\u6CD5\u8BBE\u7F6E\u63A7\u5236\u5668\u9519\u8BEF\u72B6\u6001:\", controllerError);\n            }\n          }\n        } finally {\n          // \u786E\u4FDDreader\u88AB\u91CA\u653E\n          if (reader) {\n            try {\n              reader.releaseLock();\n            } catch (releaseError) {\n              log(\"\u26A0\uFE0F \u91CA\u653Ereader\u9501\u5931\u8D25:\", releaseError);\n            }\n          }\n        }\n      },\n      cancel(reason) {\n        log(\"\uD83D\uDD04 Anthropic\u6D41\u88AB\u53D6\u6D88:\", reason);\n        // \u5BA2\u6237\u7AEF\u53D6\u6D88\u4E86\u6D41\uFF0C\u8FD9\u91CC\u53EF\u4EE5\u505A\u4E00\u4E9B\u6E05\u7406\u5DE5\u4F5C\n      },\n    });\n\n    return readable;\n  }\n\n  private createOpenAIErrorStream(error: Error): ReadableStream {\n    return new ReadableStream({\n      start(controller) {\n        const encoder = new TextEncoder();\n        const errorChunk = {\n          id: `chatcmpl-error-${Date.now()}`,\n          object: \"chat.completion.chunk\",\n          created: Math.floor(Date.now() / 1000),\n          model: \"error\",\n          choices: [\n            {\n              index: 0,\n              delta: { content: `Error: ${error.message}` },\n              logprobs: null,\n              finish_reason: \"stop\",\n            },\n          ],\n        };\n\n        controller.enqueue(\n          encoder.encode(`data: ${JSON.stringify(errorChunk)}\\n\\n`)\n        );\n        controller.enqueue(encoder.encode(`data: [DONE]\\n\\n`));\n        controller.close();\n      },\n    });\n  }\n\n  private validateRequest(requestBody: any): void {\n    if (!requestBody) {\n      throw new Error(\"Request body is required\");\n    }\n\n    if (!requestBody.model) {\n      throw new Error(\"Model is required in request body\");\n    }\n\n    if (!requestBody.messages || !Array.isArray(requestBody.messages)) {\n      throw new Error(\"Messages array is required in request body\");\n    }\n\n    if (requestBody.messages.length === 0) {\n      throw new Error(\"At least one message is required\");\n    }\n  }\n\n  private convertOpenAIToUnified(openaiRequest: any): UnifiedChatRequest {\n    return {\n      messages: openaiRequest.messages.map((msg: any) => ({\n        role: msg.role,\n        content: msg.content,\n        tool_calls: msg.tool_calls,\n        tool_call_id: msg.tool_call_id,\n      })),\n      model: openaiRequest.model,\n      max_tokens: openaiRequest.max_tokens,\n      temperature: openaiRequest.temperature,\n      stream: openaiRequest.stream,\n      tools: openaiRequest.tools\n        ? this.convertOpenAIToolsToUnified(openaiRequest.tools)\n        : undefined,\n      tool_choice: openaiRequest.tool_choice,\n    };\n  }\n\n  private convertOpenAIToolsToUnified(tools: any[]): UnifiedTool[] {\n    return tools.map((tool) => ({\n      type: \"function\" as const,\n      function: {\n        name: tool.function.name,\n        description: tool.function.description || \"\",\n        parameters: tool.function.parameters,\n      },\n    }));\n  }\n\n  async getAvailableModels(): Promise<any> {\n    const providers = this.providerService.getAvailableModels();\n\n    return {\n      object: \"list\",\n      data: providers.flatMap((provider) =>\n        provider.models.map((model) => ({\n          id: model,\n          object: \"model\",\n          provider: provider.provider,\n          created: Math.floor(Date.now() / 1000),\n          owned_by: provider.provider,\n        }))\n      ),\n    };\n  }\n\n  private getAvailableModelNames(): string[] {\n    return this.providerService\n      .getModelRoutes()\n      .map((route) => route.fullModel);\n  }\n\n  getModelRoutes() {\n    return this.providerService.getModelRoutes();\n  }\n}\n", "import { ChatCompletion } from \"openai/resources\";\nimport { UnifiedChatRequest, UnifiedMessage, UnifiedTool } from \"../types/llm\";\nimport { Transformer } from \"../types/transformer\";\nimport { log } from \"../utils/log\";\n\nexport class AnthropicTransformer implements Transformer {\n  name = \"Anthropic\";\n  endPoint = \"/v1/messages\";\n\n  transformRequestOut(request: Record<string, any>): UnifiedChatRequest {\n    log(\"Anthropic Request:\", JSON.stringify(request, null, 2));\n\n    const messages: UnifiedMessage[] = [];\n    if (request.system) {\n      let systemContent = \"\";\n      if (typeof request.system === \"string\") {\n        systemContent = request.system;\n      } else if (Array.isArray(request.system)) {\n        const textParts = request.system\n          .filter((item: any) => item.type === \"text\")\n          .map((item: any) => item.text);\n        systemContent = textParts.join(\"\\n\");\n      }\n\n      if (systemContent) {\n        messages.push({\n          role: \"system\",\n          content: systemContent,\n        });\n      }\n    }\n\n    const requestMessages = JSON.parse(JSON.stringify(request.messages || []));\n    const preprocessedMessages = this.preprocessMessages(requestMessages);\n\n    preprocessedMessages?.forEach((msg: any, index: number) => {\n      if (msg.appended) return;\n      if (msg.role === \"user\" || msg.role === \"assistant\") {\n        const unifiedMsg: UnifiedMessage = {\n          role: msg.role,\n          content: null,\n        };\n        if (typeof msg.content === \"string\") {\n          unifiedMsg.content = msg.content;\n          messages.push(unifiedMsg);\n        } else if (Array.isArray(msg.content)) {\n          const textParts: string[] = [];\n          const toolUseContent = msg.content.filter(\n            (c: any) => c.type === \"tool_use\"\n          );\n          const toolResultContent = msg.content.filter(\n            (c: any) => c.type === \"tool_result\"\n          );\n\n          msg.content.forEach((contentItem: any, contentIndex: number) => {\n            if (contentItem.type === \"text\") {\n              if (contentItem.text) {\n                textParts.push(contentItem.text);\n              }\n            }\n          });\n\n          if (textParts.length > 0) {\n            unifiedMsg.content = textParts.join(\"\\n\");\n          } else {\n            log(`message ${index + 1} - can not find text content`);\n          }\n\n          if (toolUseContent.length > 0) {\n            unifiedMsg.tool_calls = toolUseContent.map(\n              (tool: any, toolIndex: number) => {\n                let argumentsStr = \"{}\";\n                try {\n                  if (tool.input && typeof tool.input === \"object\") {\n                    argumentsStr = JSON.stringify(tool.input);\n                  } else if (typeof tool.input === \"string\") {\n                    JSON.parse(tool.input);\n                    argumentsStr = tool.input;\n                  }\n                } catch (error) {\n                  log(\n                    `covert tool use error:`,\n                    error,\n                    \"origin tool input\",\n                    tool.input\n                  );\n                  argumentsStr = JSON.stringify(tool.input || {});\n                }\n\n                return {\n                  id: tool.id,\n                  type: \"function\" as const,\n                  function: {\n                    name: tool.name,\n                    arguments: argumentsStr,\n                  },\n                };\n              }\n            );\n          }\n          const hasAssistantContent =\n            unifiedMsg.content ||\n            (unifiedMsg.tool_calls && unifiedMsg.tool_calls.length > 0);\n\n          if (hasAssistantContent) {\n            messages.push(unifiedMsg);\n          }\n\n          if (toolResultContent.length > 0) {\n            toolResultContent.forEach((result: any, resultIndex: number) => {\n              const toolMessage: UnifiedMessage = {\n                role: \"tool\",\n                content:\n                  typeof result.content === \"string\"\n                    ? result.content\n                    : JSON.stringify(result.content),\n                tool_call_id: result.tool_use_id,\n              };\n              messages.push(toolMessage);\n            });\n          }\n\n          if (!hasAssistantContent && toolResultContent.length > 0) {\n          }\n        }\n      }\n    });\n\n    const result: UnifiedChatRequest = {\n      messages,\n      model: request.model,\n      max_tokens: request.max_tokens,\n      temperature: request.temperature,\n      stream: request.stream,\n      tools: request.tools\n        ? this.convertAnthropicToolsToUnified(request.tools)\n        : undefined,\n      tool_choice: request.tool_choice,\n    };\n    return result;\n  }\n\n  async transformResponseOut(response: Response) {\n    const isStream = response.headers\n      .get(\"Content-Type\")\n      ?.includes(\"text/event-stream\");\n    if (isStream) {\n      if (!response.body) {\n        throw new Error(\"Stream response body is null\");\n      }\n      const convertedStream = await this.convertOpenAIStreamToAnthropic(\n        response.body\n      );\n      return new Response(convertedStream, {\n        headers: {\n          \"Content-Type\": \"text/event-stream\",\n          \"Cache-Control\": \"no-cache\",\n          Connection: \"keep-alive\",\n        },\n      });\n    } else {\n      const data = await response.json();\n      const anthropicResponse = this.convertOpenAIResponseToAnthropic(data);\n      return new Response(JSON.stringify(anthropicResponse), {\n        headers: { \"Content-Type\": \"application/json\" },\n      });\n    }\n  }\n\n  private preprocessMessages(messages: any[]): any[] {\n    const processedMessages: any[] = [];\n    const allToolResults = new Map<string, any>();\n    const toolResultToMessageIndex = new Map<string, number>();\n    messages.forEach((msg, msgIndex) => {\n      if (Array.isArray(msg.content)) {\n        msg.content.forEach((item: any) => {\n          if (item.type === \"tool_result\" && item.tool_use_id) {\n            allToolResults.set(item.tool_use_id, item);\n            toolResultToMessageIndex.set(item.tool_use_id, msgIndex);\n          }\n        });\n      }\n    });\n    const usedToolResultIds = new Set<string>();\n\n    for (let i = 0; i < messages.length; i++) {\n      const currentMsg = messages[i];\n      if (\n        currentMsg.role === \"assistant\" &&\n        Array.isArray(currentMsg.content)\n      ) {\n        const toolUseItems = currentMsg.content.filter(\n          (item: any) => item.type === \"tool_use\"\n        );\n\n        if (toolUseItems.length > 0) {\n          processedMessages.push(currentMsg);\n\n          const nextMsg = i + 1 < messages.length ? messages[i + 1] : null;\n          const toolUseIds: Array<string> = toolUseItems.map(\n            (item: any) => item.id\n          );\n\n          let hasAllResults = false;\n          let nextMsgToolResultIds: string[] = [];\n\n          if (nextMsg && Array.isArray(nextMsg.content)) {\n            const toolResults = nextMsg.content.filter(\n              (item: any) => item.type === \"tool_result\"\n            );\n            nextMsgToolResultIds = toolResults.map(\n              (item: any) => item.tool_use_id\n            );\n            hasAllResults = toolUseIds.every((id) =>\n              nextMsgToolResultIds.includes(id)\n            );\n          }\n\n          if (!hasAllResults) {\n            const missingIds = toolUseIds.filter(\n              (id) => !nextMsgToolResultIds.includes(id)\n            );\n            const foundResults: any[] = [];\n\n            missingIds.forEach((missingId) => {\n              const foundResult = allToolResults.get(missingId);\n              if (foundResult) {\n                foundResults.push(foundResult);\n                usedToolResultIds.add(missingId);\n              }\n            });\n\n            if (foundResults.length > 0) {\n              const toolResultMsg = {\n                role: \"user\",\n                content: foundResults,\n                appended: true,\n              };\n\n              processedMessages.push(toolResultMsg);\n            }\n          }\n        }\n      } else {\n        if (Array.isArray(currentMsg.content)) {\n          const remainingContent = currentMsg.content.filter((item: any) => {\n            if (item.type === \"tool_result\" && item.tool_use_id) {\n              return !usedToolResultIds.has(item.tool_use_id);\n            }\n            return true;\n          });\n\n          if (remainingContent.length > 0) {\n            const modifiedMsg = {\n              ...currentMsg,\n              content: remainingContent,\n            };\n            processedMessages.push(modifiedMsg);\n\n            if (remainingContent.length !== currentMsg.content.length) {\n              const removedCount =\n                currentMsg.content.length - remainingContent.length;\n            }\n          }\n        } else {\n          processedMessages.push(currentMsg);\n        }\n      }\n    }\n    return processedMessages;\n  }\n\n  private convertAnthropicToolsToUnified(tools: any[]): UnifiedTool[] {\n    return tools.map((tool) => ({\n      type: \"function\",\n      function: {\n        name: tool.name,\n        description: tool.description || \"\",\n        parameters: tool.input_schema,\n      },\n    }));\n  }\n\n  private async convertOpenAIStreamToAnthropic(\n    openaiStream: ReadableStream\n  ): Promise<ReadableStream> {\n    const readable = new ReadableStream({\n      async start(controller) {\n        const encoder = new TextEncoder();\n        const messageId = `msg_${Date.now()}`;\n        let model = \"unknown\";\n        let hasStarted = false;\n        let hasTextContentStarted = false;\n        let hasFinished = false;\n        const toolCalls = new Map<number, any>();\n        const toolCallIndexToContentBlockIndex = new Map<number, number>();\n        let totalChunks = 0;\n        let contentChunks = 0;\n        let toolCallChunks = 0;\n        let isClosed = false;\n        let isThinkingStarted = false;\n        const conversionStats = {\n          originalChunks: 0,\n          processedChunks: 0,\n          textDeltas: 0,\n          toolCallDeltas: 0,\n          errorChunks: 0,\n          skippedChunks: 0,\n          sentEvents: 0,\n        };\n\n        const safeEnqueue = (data: Uint8Array) => {\n          if (!isClosed) {\n            try {\n              controller.enqueue(data);\n              conversionStats.sentEvents++;\n              const dataStr = new TextDecoder().decode(data);\n              log(\"send data:\", dataStr.trim());\n            } catch (error) {\n              if (\n                error instanceof TypeError &&\n                error.message.includes(\"Controller is already closed\")\n              ) {\n                isClosed = true;\n              } else {\n                log(`send data error: ${error.message}`);\n                throw error;\n              }\n            }\n          }\n        };\n\n        const safeClose = () => {\n          if (!isClosed) {\n            try {\n              controller.close();\n              isClosed = true;\n            } catch (error) {\n              if (\n                error instanceof TypeError &&\n                error.message.includes(\"Controller is already closed\")\n              ) {\n                isClosed = true;\n              } else {\n                throw error;\n              }\n            }\n          }\n        };\n\n        let reader: ReadableStreamDefaultReader<Uint8Array> | null = null;\n\n        try {\n          reader = openaiStream.getReader();\n          const decoder = new TextDecoder();\n          let buffer = \"\";\n\n          while (true) {\n            if (isClosed) {\n              break;\n            }\n\n            const { done, value } = await reader.read();\n            if (done) break;\n\n            buffer += decoder.decode(value, { stream: true });\n            const lines = buffer.split(\"\\n\");\n            buffer = lines.pop() || \"\";\n\n            for (const line of lines) {\n              if (isClosed || hasFinished) break;\n\n              if (line.startsWith(\"data: \")) {\n                const data = line.slice(6);\n                if (data === \"[DONE]\") {\n                  continue;\n                }\n\n                try {\n                  const chunk = JSON.parse(data);\n                  conversionStats.originalChunks++;\n                  totalChunks++;\n                  log(`Original OpenAI data:`, JSON.stringify(chunk, null, 2));\n\n                  model = chunk.model || model;\n\n                  if (!hasStarted && !isClosed && !hasFinished) {\n                    hasStarted = true;\n\n                    const messageStart = {\n                      type: \"message_start\",\n                      message: {\n                        id: messageId,\n                        type: \"message\",\n                        role: \"assistant\",\n                        content: [],\n                        model: model,\n                        stop_reason: null,\n                        stop_sequence: null,\n                      },\n                    };\n\n                    log(\n                      \"send message_start event:\",\n                      JSON.stringify(messageStart, null, 2)\n                    );\n                    safeEnqueue(\n                      encoder.encode(\n                        `event: message_start\\ndata: ${JSON.stringify(\n                          messageStart\n                        )}\\n\\n`\n                      )\n                    );\n                  }\n\n                  const choice = chunk.choices?.[0];\n                  if (!choice) {\n                    conversionStats.skippedChunks++;\n                    continue;\n                  }\n\n                  log(`Choice Data:`, JSON.stringify(choice, null, 2));\n                  conversionStats.processedChunks++;\n\n                  if (choice?.delta?.thinking && !isClosed && !hasFinished) {\n                    if (!isThinkingStarted) {\n                      const contentBlockStart = {\n                        type: \"content_block_start\",\n                        index: 0,\n                        content_block: { type: \"thinking\", thinking: \"\" },\n                      };\n                      safeEnqueue(\n                        encoder.encode(\n                          `event: content_block_start\\ndata: ${JSON.stringify(\n                            contentBlockStart\n                          )}\\n\\n`\n                        )\n                      );\n                      isThinkingStarted = true;\n                    }\n                    if (choice.delta.thinking.signature) {\n                      const thinkingSignature = {\n                        type: \"content_block_delta\",\n                        index: 0,\n                        delta: {\n                          type: \"signature_delta\",\n                          signature: choice.delta.thinking.signature,\n                        },\n                      };\n                      safeEnqueue(\n                        encoder.encode(\n                          `event: content_block_delta\\ndata: ${JSON.stringify(\n                            thinkingSignature\n                          )}\\n\\n`\n                        )\n                      );\n\n                      const contentBlockStop = {\n                        type: \"content_block_stop\",\n                        index: 0,\n                      };\n                      safeEnqueue(\n                        encoder.encode(\n                          `event: content_block_stop\\ndata: ${JSON.stringify(\n                            contentBlockStop\n                          )}\\n\\n`\n                        )\n                      );\n                    } else if (choice.delta.thinking.content) {\n                      const thinkingChunk = {\n                        type: \"content_block_delta\",\n                        index: 0,\n                        delta: {\n                          type: \"thinking_delta\",\n                          thinking: choice.delta.thinking.content || \"\",\n                        },\n                      };\n                      safeEnqueue(\n                        encoder.encode(\n                          `event: content_block_delta\\ndata: ${JSON.stringify(\n                            thinkingChunk\n                          )}\\n\\n`\n                        )\n                      );\n                    }\n                  }\n\n                  if (choice?.delta?.content && !isClosed && !hasFinished) {\n                    contentChunks++;\n                    conversionStats.textDeltas++;\n\n                    if (!hasTextContentStarted && !hasFinished) {\n                      hasTextContentStarted = true;\n                      const contentBlockStart = {\n                        type: \"content_block_start\",\n                        index: 0,\n                        content_block: {\n                          type: \"text\",\n                          text: \"\",\n                        },\n                      };\n                      log(\n                        \"send content_block_start data:\",\n                        JSON.stringify(contentBlockStart, null, 2)\n                      );\n                      safeEnqueue(\n                        encoder.encode(\n                          `event: content_block_start\\ndata: ${JSON.stringify(\n                            contentBlockStart\n                          )}\\n\\n`\n                        )\n                      );\n                    }\n\n                    if (!isClosed && !hasFinished) {\n                      const anthropicChunk = {\n                        type: \"content_block_delta\",\n                        index: 0,\n                        delta: {\n                          type: \"text_delta\",\n                          text: choice.delta.content,\n                        },\n                      };\n                      log(`compare data:`);\n                      log(\n                        `   OpenAI:    choice.delta.content = \"${choice.delta.content}\"`\n                      );\n                      log(\n                        `   Anthropic: delta.text = \"${anthropicChunk.delta.text}\"`\n                      );\n\n                      safeEnqueue(\n                        encoder.encode(\n                          `event: content_block_delta\\ndata: ${JSON.stringify(\n                            anthropicChunk\n                          )}\\n\\n`\n                        )\n                      );\n                    }\n                  }\n\n                  if (choice?.delta?.tool_calls && !isClosed && !hasFinished) {\n                    toolCallChunks++;\n                    conversionStats.toolCallDeltas++;\n                    const processedInThisChunk = new Set<number>();\n\n                    for (const toolCall of choice.delta.tool_calls) {\n                      if (isClosed) break;\n                      const toolCallIndex = toolCall.index ?? 0;\n                      if (processedInThisChunk.has(toolCallIndex)) {\n                        continue;\n                      }\n                      processedInThisChunk.add(toolCallIndex);\n                      const isUnknownIndex =\n                        !toolCallIndexToContentBlockIndex.has(toolCallIndex);\n\n                      if (isUnknownIndex) {\n                        const newContentBlockIndex = hasTextContentStarted\n                          ? toolCallIndexToContentBlockIndex.size + 1\n                          : toolCallIndexToContentBlockIndex.size;\n                        if (newContentBlockIndex !== 0) {\n                          const contentBlockStop = {\n                            type: \"content_block_stop\",\n                            index: newContentBlockIndex - 1,\n                          };\n                          safeEnqueue(\n                            encoder.encode(\n                              `event: content_block_stop\\ndata: ${JSON.stringify(\n                                contentBlockStop\n                              )}\\n\\n`\n                            )\n                          );\n                        }\n                        toolCallIndexToContentBlockIndex.set(\n                          toolCallIndex,\n                          newContentBlockIndex\n                        );\n                        const toolCallId =\n                          toolCall.id || `call_${Date.now()}_${toolCallIndex}`;\n                        const toolCallName =\n                          toolCall.function?.name || `tool_${toolCallIndex}`;\n                        const contentBlockStart = {\n                          type: \"content_block_start\",\n                          index: newContentBlockIndex,\n                          content_block: {\n                            type: \"tool_use\",\n                            id: toolCallId,\n                            name: toolCallName,\n                            input: {},\n                          },\n                        };\n\n                        safeEnqueue(\n                          encoder.encode(\n                            `event: content_block_start\\ndata: ${JSON.stringify(\n                              contentBlockStart\n                            )}\\n\\n`\n                          )\n                        );\n\n                        const toolCallInfo = {\n                          id: toolCallId,\n                          name: toolCallName,\n                          arguments: \"\",\n                          contentBlockIndex: newContentBlockIndex,\n                        };\n                        toolCalls.set(toolCallIndex, toolCallInfo);\n                      } else if (toolCall.id && toolCall.function?.name) {\n                        const existingToolCall = toolCalls.get(toolCallIndex)!;\n                        const wasTemporary =\n                          existingToolCall.id.startsWith(\"call_\") &&\n                          existingToolCall.name.startsWith(\"tool_\");\n\n                        if (wasTemporary) {\n                          existingToolCall.id = toolCall.id;\n                          existingToolCall.name = toolCall.function.name;\n                        }\n                      }\n\n                      if (\n                        toolCall.function?.arguments &&\n                        !isClosed &&\n                        !hasFinished\n                      ) {\n                        const blockIndex =\n                          toolCallIndexToContentBlockIndex.get(toolCallIndex);\n                        if (blockIndex === undefined) {\n                          continue;\n                        }\n                        const currentToolCall = toolCalls.get(toolCallIndex);\n                        if (currentToolCall) {\n                          const oldArguments = currentToolCall.arguments;\n                          currentToolCall.arguments +=\n                            toolCall.function.arguments;\n                          try {\n                            let parsedParams = null;\n                            const trimmedArgs =\n                              currentToolCall.arguments.trim();\n                            if (\n                              trimmedArgs.startsWith(\"{\") &&\n                              trimmedArgs.endsWith(\"}\")\n                            ) {\n                              try {\n                                parsedParams = JSON.parse(trimmedArgs);\n                              } catch (e: any) {\n                                log(\n                                  \"Tool call index:\",\n                                  toolCallIndex,\n                                  \"error\",\n                                  e.message\n                                );\n                              }\n                            }\n                          } catch (e: any) {\n                            log(\n                              \"Tool call index:\",\n                              toolCallIndex,\n                              \"error\",\n                              e.message\n                            );\n                          }\n                        }\n\n                        try {\n                          const anthropicChunk = {\n                            type: \"content_block_delta\",\n                            index: blockIndex,\n                            delta: {\n                              type: \"input_json_delta\",\n                              partial_json: toolCall.function.arguments,\n                            },\n                          };\n                          safeEnqueue(\n                            encoder.encode(\n                              `event: content_block_delta\\ndata: ${JSON.stringify(\n                                anthropicChunk\n                              )}\\n\\n`\n                            )\n                          );\n                        } catch (error) {\n                          try {\n                            const fixedArgument = toolCall.function.arguments\n                              .replace(/[\\x00-\\x1F\\x7F-\\x9F]/g, \"\")\n                              .replace(/\\\\/g, \"\\\\\\\\\")\n                              .replace(/\"/g, '\\\\\"');\n\n                            const fixedChunk = {\n                              type: \"content_block_delta\",\n                              index: blockIndex,\n                              delta: {\n                                type: \"input_json_delta\",\n                                partial_json: fixedArgument,\n                              },\n                            };\n                            safeEnqueue(\n                              encoder.encode(\n                                `event: content_block_delta\\ndata: ${JSON.stringify(\n                                  fixedChunk\n                                )}\\n\\n`\n                              )\n                            );\n                          } catch (fixError) {\n                            console.error(fixError);\n                          }\n                        }\n                      }\n                    }\n                  }\n\n                  if (choice?.finish_reason && !isClosed && !hasFinished) {\n                    hasFinished = true;\n                    if (contentChunks === 0 && toolCallChunks === 0) {\n                      console.error(\n                        \"Warning: No content in the stream response!\"\n                      );\n                    }\n\n                    if (hasTextContentStarted && !isClosed) {\n                      const contentBlockStop = {\n                        type: \"content_block_stop\",\n                        index: 0,\n                      };\n                      safeEnqueue(\n                        encoder.encode(\n                          `event: content_block_stop\\ndata: ${JSON.stringify(\n                            contentBlockStop\n                          )}\\n\\n`\n                        )\n                      );\n                    }\n\n                    if (toolCallChunks > 0 && !isClosed) {\n                      for (const [\n                        toolIdx,\n                        blockIdx,\n                      ] of toolCallIndexToContentBlockIndex.entries()) {\n                        if (isClosed) break;\n                        const toolCall = toolCalls.get(toolIdx);\n                        if (toolCall && toolCall.arguments) {\n                          try {\n                            let jsonString = toolCall.arguments.trim();\n                            if (!jsonString.startsWith(\"{\")) {\n                              jsonString = \"{\" + jsonString;\n                            }\n                            if (!jsonString.endsWith(\"}\")) {\n                              jsonString = jsonString + \"}\";\n                            }\n                            JSON.parse(jsonString);\n                          } catch (e: any) {\n                            log(\n                              \"Tool call final arguments parsing failed:\",\n                              e.message,\n                              \"original arguments:\",\n                              toolCall.arguments\n                            );\n                          }\n                        }\n                      }\n\n                      const contentBlockStop = {\n                        type: \"content_block_stop\",\n                        index: toolCallIndexToContentBlockIndex.size - 1,\n                      };\n                      safeEnqueue(\n                        encoder.encode(\n                          `event: content_block_stop\\ndata: ${JSON.stringify(\n                            contentBlockStop\n                          )}\\n\\n`\n                        )\n                      );\n                    }\n                    if (!isClosed) {\n                      const stopReasonMapping = {\n                        stop: \"end_turn\",\n                        length: \"max_tokens\",\n                        tool_calls: \"tool_use\",\n                        content_filter: \"stop_sequence\",\n                      };\n\n                      const anthropicStopReason =\n                        stopReasonMapping[choice.finish_reason] || \"end_turn\";\n\n                      const messageDelta = {\n                        type: \"message_delta\",\n                        delta: {\n                          stop_reason: anthropicStopReason,\n                          stop_sequence: null,\n                        },\n                        usage: {\n                          input_tokens: chunk.usage?.prompt_tokens || 0,\n                          output_tokens: chunk.usage?.completion_tokens || 0,\n                        },\n                      };\n                      safeEnqueue(\n                        encoder.encode(\n                          `event: message_delta\\ndata: ${JSON.stringify(\n                            messageDelta\n                          )}\\n\\n`\n                        )\n                      );\n                    }\n\n                    if (!isClosed) {\n                      const messageStop = {\n                        type: \"message_stop\",\n                      };\n                      safeEnqueue(\n                        encoder.encode(\n                          `event: message_stop\\ndata: ${JSON.stringify(\n                            messageStop\n                          )}\\n\\n`\n                        )\n                      );\n                    }\n\n                    break;\n                  }\n                } catch (parseError) {\n                  conversionStats.errorChunks++;\n                }\n              }\n            }\n          }\n          safeClose();\n        } catch (error) {\n          if (!isClosed) {\n            try {\n              controller.error(error);\n            } catch (controllerError) {\n              console.error(controllerError);\n            }\n          }\n        } finally {\n          if (reader) {\n            try {\n              reader.releaseLock();\n            } catch (releaseError) {\n              console.error(releaseError);\n            }\n          }\n        }\n      },\n      cancel(reason) {\n        log(\"cancle stream:\", reason);\n      },\n    });\n\n    return readable;\n  }\n\n  private convertOpenAIResponseToAnthropic(\n    openaiResponse: ChatCompletion\n  ): any {\n    log(\"Original OpenAI response:\", JSON.stringify(openaiResponse, null, 2));\n\n    const choice = openaiResponse.choices[0];\n    if (!choice) {\n      throw new Error(\"No choices found in OpenAI response\");\n    }\n    const content: any[] = [];\n    if (choice.message.content) {\n      content.push({\n        type: \"text\",\n        text: choice.message.content,\n      });\n    }\n    if (choice.message.tool_calls && choice.message.tool_calls.length > 0) {\n      choice.message.tool_calls.forEach((toolCall, index) => {\n        let parsedInput = {};\n        try {\n          const argumentsStr = toolCall.function.arguments || \"{}\";\n\n          if (typeof argumentsStr === \"object\") {\n            parsedInput = argumentsStr;\n          } else if (typeof argumentsStr === \"string\") {\n            parsedInput = JSON.parse(argumentsStr);\n          }\n        } catch (parseError) {\n          parsedInput = { text: toolCall.function.arguments || \"\" };\n        }\n\n        content.push({\n          type: \"tool_use\",\n          id: toolCall.id,\n          name: toolCall.function.name,\n          input: parsedInput,\n        });\n      });\n    }\n\n    const result = {\n      id: openaiResponse.id,\n      type: \"message\",\n      role: \"assistant\",\n      model: openaiResponse.model,\n      content: content,\n      stop_reason:\n        choice.finish_reason === \"stop\"\n          ? \"end_turn\"\n          : choice.finish_reason === \"length\"\n          ? \"max_tokens\"\n          : choice.finish_reason === \"tool_calls\"\n          ? \"tool_use\"\n          : choice.finish_reason === \"content_filter\"\n          ? \"stop_sequence\"\n          : \"end_turn\",\n      stop_sequence: null,\n      usage: {\n        input_tokens: openaiResponse.usage?.prompt_tokens || 0,\n        output_tokens: openaiResponse.usage?.completion_tokens || 0,\n      },\n    };\n    log(\n      \"Conversion complete, final Anthropic response:\",\n      JSON.stringify(result, null, 2)\n    );\n    return result;\n  }\n}\n", "import { UnifiedChatRequest } from \"../types/llm\";\nimport { Transformer } from \"../types/transformer\";\n\nexport class GeminiTransformer implements Transformer {\n  name = \"Gemini\";\n\n  endPoint = \"/v1beta/models/:model\";\n\n  // transformRequestIn(request: UnifiedChatRequest) {\n  //     return {\n  //         model: this.model,\n  //         messages: request.messages.map(message => ({\n  //             role: message.role,\n  //             content: message.content,\n  //             tool_calls: message.tool_calls || [],\n  //         })),\n  //         max_tokens: request.max_tokens,\n  //         temperature: request.temperature,\n  //         stream: request.stream,\n  //         tools: request.tools?.map(tool => ({\n  //             type: tool.type,\n  //             function: {\n  //                 name: tool.function.name,\n  //                 description: tool.function.description,\n  //                 parameters: tool.function.parameters,\n  //             },\n  //         })),\n  //         tool_choice: request.tool_choice,\n  //     };\n  // }\n\n  transformRequestOut(request: UnifiedChatRequest): UnifiedChatRequest {\n    if (Array.isArray(request.tools)) {\n      // rewrite tools definition\n      request.tools.forEach((tool) => {\n        if (tool.function.name === \"BatchTool\") {\n          // HACK: Gemini does not support objects with empty properties\n          tool.function.parameters.properties.invocations.items.properties.input.type =\n            \"number\";\n          return;\n        }\n        Object.keys(tool.function.parameters.properties).forEach((key) => {\n          const prop = tool.function.parameters.properties[key];\n          if (\n            prop.type === \"string\" &&\n            ![\"enum\", \"date-time\"].includes(prop.format)\n          ) {\n            delete prop.format;\n          }\n        });\n      });\n    }\n    return request;\n  }\n\n  // transformResponseIn(response: GeminiChatResponse): UnifiedChatResponse {\n  //     return {\n  //         id: response.id,\n  //         model: response.model,\n  //         content: response.content || null,\n  //         usage: response.usage ? {\n  //             prompt_tokens: response.usage.prompt_tokens,\n  //             completion_tokens: response.usage.completion_tokens,\n  //             total_tokens: response.usage.total_tokens,\n  //         } : undefined,\n  //         tool_calls: response.tool_calls?.map(call => ({\n  //             id: call.id,\n  //             type: call.type,\n  //             function: {\n  //                 name: call.function.name,\n  //                 arguments: call.function.arguments,\n  //             },\n  //         })),\n  //     };\n  // }\n\n  async transformResponseOut(response: Response): Promise<Response> {\n    return response;\n  }\n}\n", "import { UnifiedChatRequest } from \"../types/llm\";\nimport { Transformer } from \"../types/transformer\";\n\nexport class DeepseekTransformer implements Transformer {\n  name = \"deepseek\";\n\n  transformRequestOut(request: UnifiedChatRequest): UnifiedChatRequest {\n    if (request.max_tokens && request.max_tokens > 8192) {\n      request.max_tokens = 8192; // DeepSeek has a max token limit of 8192\n    }\n    return request;\n  }\n\n  async transformResponseOut(response: Response): Promise<Response> {\n    if (response.headers.get(\"Content-Type\")?.includes(\"application/json\")) {\n      const jsonResponse = await response.json();\n      // Handle non-streaming response if needed\n      return new Response(JSON.stringify(jsonResponse), {\n        status: response.status,\n        statusText: response.statusText,\n        headers: response.headers,\n      });\n    } else if (response.headers.get(\"Content-Type\")?.includes(\"stream\")) {\n      // Handle streaming response\n      if (!response.body) {\n        return response;\n      }\n\n      const decoder = new TextDecoder();\n      const encoder = new TextEncoder();\n      let reasoningContent = \"\";\n      let isReasoningComplete = false;\n\n      const stream = new ReadableStream({\n        async start(controller) {\n          const reader = response.body!.getReader();\n          try {\n            while (true) {\n              const { done, value } = await reader.read();\n              if (done) break;\n\n              const chunk = decoder.decode(value, { stream: true });\n              const lines = chunk.split('\\n');\n\n              for (const line of lines) {\n                if (line.startsWith('data: ') && line.trim() !== 'data: [DONE]') {\n                  try {\n                    const data = JSON.parse(line.slice(6));\n\n                    // Extract reasoning_content from delta\n                    if (data.choices?.[0]?.delta?.reasoning_content) {\n                      reasoningContent += data.choices[0].delta.reasoning_content;\n                      const thinkingChunk = {\n                        ...data,\n                        choices: [{\n                          ...data.choices[0],\n                          delta: {\n                            ...data.choices[0].delta,\n                            thinking: {\n                              content: data.choices[0].delta.reasoning_content,\n                            }\n                          }\n                        }]\n                      };\n                      const thinkingLine = `data: ${JSON.stringify(thinkingChunk)}\\n\\n`;\n                      controller.enqueue(encoder.encode(thinkingLine));\n                    }\n\n                    // Check if reasoning is complete (when delta has content but no reasoning_content)\n                    if (data.choices?.[0]?.delta?.content && !data.choices[0].delta.reasoning_content && reasoningContent && !isReasoningComplete) {\n                      isReasoningComplete = true;\n                      const signature = Date.now().toString();\n\n                      // Create a new chunk with thinking block\n                      const thinkingChunk = {\n                        ...data,\n                        choices: [{\n                          ...data.choices[0],\n                          delta: {\n                            ...data.choices[0].delta,\n                            thinking: {\n                              content: reasoningContent,\n                              signature: signature\n                            }\n                          }\n                        }]\n                      };\n\n                      console.log(\"Thinking chunk created:\", thinkingChunk);\n\n                      // Send the thinking chunk\n                      const thinkingLine = `data: ${JSON.stringify(thinkingChunk)}\\n\\n`;\n                      controller.enqueue(encoder.encode(thinkingLine));\n                    }\n\n                    // Remove reasoning_content from the original delta to avoid duplication\n                    if (data.choices?.[0]?.delta?.reasoning_content) {\n                      delete data.choices[0].delta.reasoning_content;\n                    }\n\n                    // Send the modified chunk\n                    if (data.choices?.[0]?.delta && Object.keys(data.choices[0].delta).length > 0) {\n                      const modifiedLine = `data: ${JSON.stringify(data)}\\n\\n`;\n                      controller.enqueue(encoder.encode(modifiedLine));\n                    }\n                  } catch (e) {\n                    // If JSON parsing fails, pass through the original line\n                    controller.enqueue(encoder.encode(line + '\\n'));\n                  }\n                } else {\n                  // Pass through non-data lines (like [DONE])\n                  controller.enqueue(encoder.encode(line + '\\n'));\n                }\n              }\n            }\n          } catch (error) {\n            controller.error(error);\n          } finally {\n            try {\n              reader.releaseLock();\n            } catch (e) {\n              // Ignore errors when releasing lock\n            }\n            controller.close();\n          }\n        }\n      });\n\n      return new Response(stream, {\n        status: response.status,\n        statusText: response.statusText,\n        headers: {\n          'Content-Type': response.headers.get('Content-Type') || 'text/plain',\n          'Cache-Control': 'no-cache',\n          'Connection': 'keep-alive',\n        },\n      });\n    }\n\n    return response;\n  }\n}", "import { Transformer } from \"../types/transformer\";\nimport { log } from \"../utils/log\";\nimport { configService } from \"./config\";\nimport { AnthropicTransformer } from \"../transformer/anthropic.transformer\";\nimport { GeminiTransformer } from \"../transformer/gemini.transformer\";\nimport { DeepseekTransformer } from \"../transformer/deepseek.transformer\";\n\ninterface TransformerConfig {\n  transformers: Array<{\n    name: string;\n    type: \"class\" | \"module\";\n    path?: string;\n    options?: any;\n  }>;\n}\n\nexport class TransformerService {\n  private transformers: Map<string, Transformer> = new Map();\n\n  constructor() {\n    this.initialize();\n  }\n\n  registerTransformer(name: string, transformer: Transformer): void {\n    this.transformers.set(name, transformer);\n    log(\n      `register transformer: ${name}${\n        transformer.endPoint\n          ? ` (endpoint: ${transformer.endPoint})`\n          : \" (\u65E0endpoint)\"\n      }`\n    );\n  }\n\n  getTransformer(name: string): Transformer | undefined {\n    return this.transformers.get(name);\n  }\n\n  getAllTransformers(): Map<string, Transformer> {\n    return new Map(this.transformers);\n  }\n\n  getTransformersWithEndpoint(): { name: string; transformer: Transformer }[] {\n    const result: { name: string; transformer: Transformer }[] = [];\n\n    this.transformers.forEach((transformer, name) => {\n      if (transformer.endPoint) {\n        result.push({ name, transformer });\n      }\n    });\n\n    return result;\n  }\n\n  getTransformersWithoutEndpoint(): {\n    name: string;\n    transformer: Transformer;\n  }[] {\n    const result: { name: string; transformer: Transformer }[] = [];\n\n    this.transformers.forEach((transformer, name) => {\n      if (!transformer.endPoint) {\n        result.push({ name, transformer });\n      }\n    });\n\n    return result;\n  }\n\n  removeTransformer(name: string): boolean {\n    return this.transformers.delete(name);\n  }\n\n  hasTransformer(name: string): boolean {\n    return this.transformers.has(name);\n  }\n\n  async registerTransformerFromConfig(config: {\n    path?: string;\n    options?: any;\n  }): Promise<boolean> {\n    try {\n      if (config.path) {\n        const module = require(config.path);\n        if (module) {\n          const instance = new module(config.options);\n          if (!instance.name) {\n            throw new Error(\n              `Transformer instance from ${config.path} does not have a name property.`\n            );\n          }\n          this.registerTransformer(instance.name, instance);\n          return true;\n        }\n      }\n      return false;\n    } catch (error) {\n      log(`load transformer (${config.path}):`, error);\n      return false;\n    }\n  }\n\n  private async initialize(): Promise<void> {\n    try {\n      await this.registerDefaultTransformersInternal();\n      await this.loadFromConfig();\n    } catch (error) {\n      log(\"TransformerService init error:\", error);\n    }\n  }\n\n  private async registerDefaultTransformersInternal(): Promise<void> {\n    try {\n      const anthropic = new AnthropicTransformer();\n      const gemini = new GeminiTransformer();\n      const deepseek = new DeepseekTransformer();\n      this.registerTransformer(anthropic.name, anthropic);\n      this.registerTransformer(gemini.name, gemini);\n      this.registerTransformer(deepseek.name, deepseek);\n    } catch (error) {\n      log(\"transformer regist error:\", error);\n    }\n  }\n\n  private async loadFromConfig(): Promise<void> {\n    const transformers = configService.get<TransformerConfig[\"transformers\"]>(\n      \"transformers\",\n      []\n    );\n    for (const transformer of transformers) {\n      await this.registerTransformerFromConfig(transformer);\n    }\n  }\n}\n", "import {\n  FastifyInstance,\n  FastifyPluginAsync,\n  FastifyRequest,\n  FastifyReply,\n} from \"fastify\";\nimport { LLMService } from \"../services/llm\";\nimport { ProviderService } from \"../services/provider\";\nimport { TransformerService } from \"../services/transformer\";\nimport {\n  UnifiedChatRequest,\n  RegisterProviderRequest,\n  LLMProvider,\n} from \"../types/llm\";\nimport { sendUnifiedRequest } from \"../utils/request\";\nimport { createApiError } from \"./middleware\";\n\nexport const registerApiRoutes: FastifyPluginAsync = async (\n  fastify: FastifyInstance\n) => {\n  const llmService = new LLMService();\n  const providerService = new ProviderService();\n  const transformerService = new TransformerService();\n\n  // Health and info endpoints\n  fastify.get(\"/\", async (request, reply) => {\n    return { message: \"LLMs API\", version: \"1.0.0\" };\n  });\n\n  fastify.get(\"/health\", async (request, reply) => {\n    return { status: \"ok\", timestamp: new Date().toISOString() };\n  });\n\n  // Chat completions endpoints\n  fastify.post(\n    \"/v1/chat/completions\",\n    {\n      schema: {\n        body: {\n          type: \"object\",\n          properties: {\n            messages: { type: \"array\" },\n            model: { type: \"string\" },\n            max_tokens: { type: \"number\" },\n            temperature: { type: \"number\" },\n            stream: { type: \"boolean\" },\n          },\n          required: [\"messages\", \"model\"],\n        },\n      },\n    },\n    async (request: FastifyRequest, reply: FastifyReply) => {\n      const response = await llmService.handleOpenAIFormatRequest({\n        ...(request.body as UnifiedChatRequest),\n        model: \"deepseek,deepseek-chat\",\n        max_tokens: 8192,\n      });\n\n      const isStream = (request.body as any)?.stream === true;\n      if (isStream) {\n        reply.header(\"Content-Type\", \"text/event-stream\");\n        reply.header(\"Cache-Control\", \"no-cache\");\n        reply.header(\"Connection\", \"keep-alive\");\n        return reply.send(response.body);\n      } else {\n        return response.json();\n      }\n    }\n  );\n\n  const transformersWithEndpoint =\n    transformerService.getTransformersWithEndpoint();\n\n  for (const { name, transformer } of transformersWithEndpoint) {\n    if (transformer.endPoint) {\n      fastify.post(\n        transformer.endPoint,\n        async (req: FastifyRequest, reply: FastifyReply) => {\n          const body = req.body as any;\n          const providerNmae = req.provider!;\n          const provider = providerService.getProvider(providerNmae);\n          if (!provider) {\n            throw createApiError(\n              `Provider '${providerNmae}' not found`,\n              404,\n              \"provider_not_found\"\n            );\n          }\n          let requestBody =\n            typeof transformer.transformRequestOut === \"function\"\n              ? transformer.transformRequestOut(body as UnifiedChatRequest)\n              : body;\n          if (provider.transformer?.use?.length) {\n            for (const transformerName of provider.transformer.use) {\n              const transformer = transformerService.getTransformer(transformerName);\n              if (!transformer || typeof transformer.transformRequestOut !== \"function\") {\n                continue;\n              }\n              requestBody = transformer.transformRequestOut(requestBody);\n            }\n          }\n          if (provider.transformers?.[req.body.model]?.use?.length) {\n            for (const transformerName of provider.transformers[req.body.model].use) {\n              const transformer = transformerService.getTransformer(transformerName);\n              if (!transformer || typeof transformer.transformRequestOut !== \"function\") {\n                continue;\n              }\n              requestBody = transformer.transformRequestOut(requestBody);\n            }\n          }\n          const url = new URL(\n            '/v1/chat/completions',\n            provider.baseUrl.endsWith(\"/\") ? provider.baseUrl : `${provider.baseUrl}/`\n          );\n          const response = await sendUnifiedRequest(url, requestBody, {\n            headers: {\n              \"Authorization\": `Bearer ${provider.apiKey}`\n            },\n          });\n          let finalResponse = response;\n          if (provider.transformer?.use?.length) {\n            for (const transformerName of provider.transformer.use) {\n              const transformer = transformerService.getTransformer(transformerName);\n              if (!transformer || typeof transformer.transformResponseOut !== \"function\") {\n                continue;\n              }\n              finalResponse = await transformer.transformResponseOut(finalResponse);\n            }\n          }\n          if (provider.transformers?.[req.body.model]?.use?.length) {\n            for (const transformerName of provider.transformers[req.body.model].use) {\n              const transformer = transformerService.getTransformer(transformerName);\n              if (!transformer || typeof transformer.transformResponseOut !== \"function\") {\n                continue;\n              }\n              finalResponse = await transformer.transformResponseOut(finalResponse);\n            }\n          }\n          if (transformer.transformResponseOut) {\n            finalResponse = await transformer.transformResponseOut(finalResponse);\n          }\n          if (!finalResponse.ok) {\n            reply.code(finalResponse.status);\n          }\n          const isStream = body?.stream === true;\n          if (isStream) {\n            reply.header(\"Content-Type\", \"text/event-stream\");\n            reply.header(\"Cache-Control\", \"no-cache\");\n            reply.header(\"Connection\", \"keep-alive\");\n            return reply.send(finalResponse.body);\n          } else {\n            return finalResponse.json();\n          }\n        }\n      );\n    }\n  }\n\n  fastify.post(\n    \"/providers\",\n    {\n      schema: {\n        body: {\n          type: \"object\",\n          properties: {\n            id: { type: \"string\" },\n            name: { type: \"string\" },\n            type: { type: \"string\", enum: [\"openai\", \"anthropic\"] },\n            baseUrl: { type: \"string\" },\n            apiKey: { type: \"string\" },\n            models: { type: \"array\", items: { type: \"string\" } },\n          },\n          required: [\"id\", \"name\", \"type\", \"baseUrl\", \"apiKey\", \"models\"],\n        },\n      },\n    },\n    async (\n      request: FastifyRequest<{ Body: RegisterProviderRequest }>,\n      reply: FastifyReply\n    ) => {\n      // Validation\n      const { name, type, baseUrl, apiKey, models } = request.body;\n\n      if (!name?.trim()) {\n        throw createApiError(\n          \"Provider name is required\",\n          400,\n          \"invalid_request\"\n        );\n      }\n\n      if (!baseUrl || !isValidUrl(baseUrl)) {\n        throw createApiError(\n          \"Valid base URL is required\",\n          400,\n          \"invalid_request\"\n        );\n      }\n\n      if (!apiKey?.trim()) {\n        throw createApiError(\"API key is required\", 400, \"invalid_request\");\n      }\n\n      if (!models || !Array.isArray(models) || models.length === 0) {\n        throw createApiError(\n          \"At least one model is required\",\n          400,\n          \"invalid_request\"\n        );\n      }\n\n      // Check if provider already exists\n      if (providerService.getProvider(id)) {\n        throw createApiError(\n          `Provider with ID '${id}' already exists`,\n          400,\n          \"provider_exists\"\n        );\n      }\n\n      const provider = providerService.registerProvider(request.body);\n      return provider;\n    }\n  );\n\n  fastify.get(\"/providers\", async (request, reply) => {\n    return providerService.getProviders();\n  });\n\n  fastify.get(\n    \"/providers/:id\",\n    {\n      schema: {\n        params: {\n          type: \"object\",\n          properties: { id: { type: \"string\" } },\n          required: [\"id\"],\n        },\n      },\n    },\n    async (request: FastifyRequest<{ Params: { id: string } }>, reply) => {\n      const provider = providerService.getProvider(request.params.id);\n      if (!provider) {\n        return reply.code(404).send({ error: \"Provider not found\" });\n      }\n      return provider;\n    }\n  );\n\n  fastify.put(\n    \"/providers/:id\",\n    {\n      schema: {\n        params: {\n          type: \"object\",\n          properties: { id: { type: \"string\" } },\n          required: [\"id\"],\n        },\n        body: {\n          type: \"object\",\n          properties: {\n            name: { type: \"string\" },\n            type: { type: \"string\", enum: [\"openai\", \"anthropic\"] },\n            baseUrl: { type: \"string\" },\n            apiKey: { type: \"string\" },\n            models: { type: \"array\", items: { type: \"string\" } },\n            enabled: { type: \"boolean\" },\n          },\n        },\n      },\n    },\n    async (\n      request: FastifyRequest<{\n        Params: { id: string };\n        Body: Partial<LLMProvider>;\n      }>,\n      reply\n    ) => {\n      const provider = providerService.updateProvider(\n        request.params.id,\n        request.body\n      );\n      if (!provider) {\n        return reply.code(404).send({ error: \"Provider not found\" });\n      }\n      return provider;\n    }\n  );\n\n  fastify.delete(\n    \"/providers/:id\",\n    {\n      schema: {\n        params: {\n          type: \"object\",\n          properties: { id: { type: \"string\" } },\n          required: [\"id\"],\n        },\n      },\n    },\n    async (request: FastifyRequest<{ Params: { id: string } }>, reply) => {\n      const success = providerService.deleteProvider(request.params.id);\n      if (!success) {\n        return reply.code(404).send({ error: \"Provider not found\" });\n      }\n      return { message: \"Provider deleted successfully\" };\n    }\n  );\n\n  fastify.patch(\n    \"/providers/:id/toggle\",\n    {\n      schema: {\n        params: {\n          type: \"object\",\n          properties: { id: { type: \"string\" } },\n          required: [\"id\"],\n        },\n        body: {\n          type: \"object\",\n          properties: { enabled: { type: \"boolean\" } },\n          required: [\"enabled\"],\n        },\n      },\n    },\n    async (\n      request: FastifyRequest<{\n        Params: { id: string };\n        Body: { enabled: boolean };\n      }>,\n      reply\n    ) => {\n      const success = providerService.toggleProvider(\n        request.params.id,\n        request.body.enabled\n      );\n      if (!success) {\n        return reply.code(404).send({ error: \"Provider not found\" });\n      }\n      return {\n        message: `Provider ${request.body.enabled ? \"enabled\" : \"disabled\"\n          } successfully`,\n      };\n    }\n  );\n};\n\n// Helper function\nfunction isValidUrl(url: string): boolean {\n  try {\n    new URL(url);\n    return true;\n  } catch {\n    return false;\n  }\n}\n"],
  "mappings": "ueAAA,IAAAA,GAIO,sBACPC,GAAiB,4BCLjB,IAAAC,EAAyC,cACzCC,EAAqB,gBACrBC,GAAuB,kBAcVC,EAAN,KAAoB,CACjB,OAAoB,CAAC,EACrB,QAER,YACEC,EAAyB,CACvB,SAAU,eACZ,EACA,CACA,KAAK,QAAU,CACb,QAASA,EAAQ,SAAW,OAC5B,SAAUA,EAAQ,SAClB,WAAYA,EAAQ,aAAe,GACnC,YAAaA,EAAQ,cAAgB,GACrC,wBAAyBA,EAAQ,0BAA4B,GAC7D,GAAGA,CACL,EAEA,KAAK,WAAW,CAClB,CAEQ,YAAmB,CACrB,KAAK,QAAQ,YACf,KAAK,cAAc,EAGjB,KAAK,QAAQ,aAAe,KAAK,QAAQ,UAC3C,KAAK,eAAe,EAGlB,KAAK,QAAQ,yBACf,KAAK,yBAAyB,CAElC,CAEQ,gBAAuB,CAC7B,GAAI,CAAC,KAAK,QAAQ,SAAU,OAE5B,IAAMC,EAAW,KAAK,eAAe,KAAK,QAAQ,QAAQ,EACtD,KAAK,QAAQ,YACb,QAAK,QAAQ,IAAI,EAAG,KAAK,QAAQ,QAAQ,EAE7C,MAAI,cAAWA,CAAQ,EACrB,GAAI,CACF,IAAMC,KAAc,gBAAaD,EAAU,OAAO,EAC5CE,EAAa,KAAK,MAAMD,CAAW,EACzC,KAAK,OAAS,CAAE,GAAG,KAAK,OAAQ,GAAGC,CAAW,EAC9C,QAAQ,IAAI,4BAA4BF,CAAQ,EAAE,CACpD,OAASG,EAAO,CACd,QAAQ,KAAK,mCAAmCH,CAAQ,IAAKG,CAAK,CACpE,MAEA,QAAQ,KAAK,+BAA+BH,CAAQ,EAAE,CAE1D,CAEQ,eAAsB,CAC5B,IAAMI,EAAU,KAAK,eAAe,KAAK,QAAQ,OAAQ,EACrD,KAAK,QAAQ,WACb,QAAK,QAAQ,IAAI,EAAG,KAAK,QAAQ,OAAQ,EAE7C,MAAI,cAAWA,CAAO,EACpB,GAAI,CACF,IAAMC,KAAS,WAAO,CAAE,KAAMD,CAAQ,CAAC,EACnCC,EAAO,SACT,KAAK,OAAS,CACZ,GAAG,KAAK,OACR,GAAG,KAAK,eAAeA,EAAO,MAAM,CACtC,EAEJ,OAASF,EAAO,CACd,QAAQ,KAAK,mCAAmCC,CAAO,IAAKD,CAAK,CACnE,MAEA,QAAQ,KAAK,wBAAwBC,CAAO,EAAE,CAElD,CAEQ,0BAAiC,CACvC,IAAME,EAAY,KAAK,eAAe,QAAQ,GAAG,EACjD,KAAK,OAAS,CAAE,GAAG,KAAK,OAAQ,GAAGA,CAAU,CAC/C,CAEQ,eACNC,EACoB,CACpB,IAAMC,EAA6B,CAAC,EAEpC,cAAO,OAAOA,EAAQD,CAAG,EAElBC,CACT,CAEQ,eAAeC,EAAuB,CAC5C,OAAOA,EAAK,WAAW,GAAG,GAAKA,EAAK,SAAS,GAAG,CAClD,CAIO,IAAaC,EAAsBC,EAAiC,CACzE,IAAMC,EAAQ,KAAK,OAAOF,CAAG,EAC7B,OAAOE,IAAU,OAAaA,EAAcD,CAC9C,CAEO,QAAoB,CACzB,MAAO,CAAE,GAAG,KAAK,MAAO,CAC1B,CAEO,eAAoC,CACzC,OACE,KAAK,IAAI,aAAa,GACtB,KAAK,IAAI,aAAa,GACtB,KAAK,IAAI,YAAY,CAEzB,CAEO,IAAID,EAA+B,CACxC,OAAO,KAAK,OAAOA,CAAG,IAAM,MAC9B,CAEO,IAAIA,EAAsBE,EAAkB,CACjD,KAAK,OAAOF,CAAG,EAAIE,CACrB,CAEO,QAAe,CACpB,KAAK,OAAS,CAAC,EACf,KAAK,WAAW,CAClB,CAEO,kBAA2B,CAChC,IAAMC,EAAoB,CAAC,EAE3B,OAAI,KAAK,QAAQ,aAAe,KAAK,QAAQ,UAC3CA,EAAQ,KAAK,SAAS,KAAK,QAAQ,QAAQ,EAAE,EAG3C,KAAK,QAAQ,YACfA,EAAQ,KAAK,QAAQ,KAAK,QAAQ,OAAO,EAAE,EAGzC,KAAK,QAAQ,yBACfA,EAAQ,KAAK,uBAAuB,EAG/B,mBAAmBA,EAAQ,KAAK,IAAI,CAAC,EAC9C,CACF,EAEaC,EAAgB,IAAIhB,ECpKjC,IAAAiB,GAAe,sBAETC,GAAW,UAGV,SAASC,KAAOC,EAAa,CAKlC,GAJA,QAAQ,IAAI,GAAGA,CAAI,EAIf,CAFiB,GAGnB,OAIF,IAAMC,EAAa,IADD,IAAI,KAAK,EAAE,YAAY,CACT,KAC9B,MAAM,QAAQD,CAAI,EACdA,EACG,IAAKE,GACJ,OAAOA,GAAQ,SAAW,KAAK,UAAUA,CAAG,EAAI,OAAOA,CAAG,CAC5D,EACC,KAAK,GAAG,EACX,EACN;AAAA,EAGA,GAAAC,QAAG,eAAeL,GAAUG,EAAY,MAAM,CAChD,CCnBO,SAASG,EACdC,EACAC,EAAqB,IACrBC,EAAe,iBACfC,EAAe,YACL,CACV,IAAMC,EAAQ,IAAI,MAAMJ,CAAO,EAC/B,OAAAI,EAAM,WAAaH,EACnBG,EAAM,KAAOF,EACbE,EAAM,KAAOD,EACNC,CACT,CAEA,eAAsBC,GACpBD,EACAE,EACAC,EACA,CACAD,EAAQ,IAAI,MAAMF,CAAK,EAEvB,IAAMH,EAAaG,EAAM,YAAc,IACjCI,EAAW,CACf,MAAO,CACL,QAASJ,EAAM,SAAW,wBAC1B,KAAMA,EAAM,MAAQ,YACpB,KAAMA,EAAM,MAAQ,gBACtB,CACF,EAEA,OAAOG,EAAM,KAAKN,CAAU,EAAE,KAAKO,CAAQ,CAC7C,CC5BO,IAAMC,EAAN,KAAsB,CACnB,UAAsC,IAAI,IAC1C,YAAuC,IAAI,IAEnD,aAAc,CACZ,KAAK,0BAA0B,CACjC,CAEQ,2BAA4B,CAClC,IAAMC,EAAkBC,EAAc,IAAsB,WAAW,EACvE,GAAID,GAAmB,MAAM,QAAQA,CAAe,EAAG,CACrD,KAAK,6BAA6BA,CAAe,EACjD,MACF,CACF,CAEQ,6BAA6BA,EAAmC,CACtEA,EAAgB,QAASE,GAAmC,CAC1D,GAAI,CACF,GACE,CAACA,EAAe,MAChB,CAACA,EAAe,cAChB,CAACA,EAAe,QAEhB,OAGF,KAAK,iBAAiB,CACpB,KAAMA,EAAe,KACrB,QAASA,EAAe,aACxB,OAAQA,EAAe,QACvB,OAAQA,EAAe,QAAU,CAAC,GAAGA,EAAe,EAAE,UAAU,EAChE,YAAaA,EAAe,aAAe,CAAC,CAC9C,CAAC,EAEDC,EAAI,GAAGD,EAAe,IAAI,sBAAsB,CAClD,OAASE,EAAO,CACdD,EAAI,GAAGD,EAAe,IAAI,+BAA+BE,CAAK,EAAE,CAClE,CACF,CAAC,CACH,CAKA,iBAAiBC,EAA+C,CAC9D,IAAMC,EAAwB,CAC5B,GAAGD,CACL,EAEA,YAAK,UAAU,IAAIC,EAAS,KAAMA,CAAQ,EAG1CD,EAAQ,OAAO,QAASE,GAAU,CAChC,IAAMC,EAAY,GAAGF,EAAS,IAAI,IAAIC,CAAK,GACrCE,EAAoB,CACxB,SAAUH,EAAS,KACnB,MAAAC,EACA,UAAAC,CACF,EACA,KAAK,YAAY,IAAIA,EAAWC,CAAK,EAEhC,KAAK,YAAY,IAAIF,CAAK,GAC7B,KAAK,YAAY,IAAIA,EAAOE,CAAK,CAErC,CAAC,EAEMH,CACT,CAKA,cAA8B,CAC5B,OAAO,MAAM,KAAK,KAAK,UAAU,OAAO,CAAC,CAC3C,CAKA,YAAYI,EAAqC,CAC/C,OAAO,KAAK,UAAU,IAAIA,CAAE,CAC9B,CAKA,eACEA,EACAC,EACoB,CACpB,IAAML,EAAW,KAAK,UAAU,IAAII,CAAE,EACtC,GAAI,CAACJ,EACH,OAAO,KAGT,IAAMM,EAAkB,CACtB,GAAGN,EACH,GAAGK,EACH,UAAW,IAAI,IACjB,EAEA,YAAK,UAAU,IAAID,EAAIE,CAAe,EAGlCD,EAAQ,SAEVL,EAAS,OAAO,QAASC,GAAU,CACjC,IAAMC,EAAY,GAAGF,EAAS,EAAE,IAAIC,CAAK,GACzC,KAAK,YAAY,OAAOC,CAAS,EACjC,KAAK,YAAY,OAAOD,CAAK,CAC/B,CAAC,EAGDI,EAAQ,OAAO,QAASJ,GAAU,CAChC,IAAMC,EAAY,GAAGF,EAAS,EAAE,IAAIC,CAAK,GACnCE,EAAoB,CACxB,WAAYH,EAAS,GACrB,MAAAC,EACA,UAAAC,CACF,EACA,KAAK,YAAY,IAAIA,EAAWC,CAAK,EAChC,KAAK,YAAY,IAAIF,CAAK,GAC7B,KAAK,YAAY,IAAIA,EAAOE,CAAK,CAErC,CAAC,GAGHN,EAAI,yCAAWS,EAAgB,IAAI,KAAKF,CAAE,GAAG,EACtCE,CACT,CAKA,eAAeF,EAAqB,CAClC,IAAMJ,EAAW,KAAK,UAAU,IAAII,CAAE,EACtC,OAAKJ,GAKLA,EAAS,OAAO,QAASC,GAAU,CACjC,IAAMC,EAAY,GAAGF,EAAS,EAAE,IAAIC,CAAK,GACzC,KAAK,YAAY,OAAOC,CAAS,EACjC,KAAK,YAAY,OAAOD,CAAK,CAC/B,CAAC,EAED,KAAK,UAAU,OAAOG,CAAE,EACxBP,EAAI,yCAAWG,EAAS,IAAI,KAAKI,CAAE,GAAG,EAC/B,IAZE,EAaX,CAKA,eAAeA,EAAYG,EAA2B,CACpD,IAAMP,EAAW,KAAK,UAAU,IAAII,CAAE,EACtC,OAAKJ,GAILA,EAAS,QAAUO,EACnBP,EAAS,UAAY,IAAI,KAEzBH,EAAI,UAAKU,EAAU,eAAO,cAAI,sBAAOP,EAAS,IAAI,KAAKI,CAAE,GAAG,EACrD,IAPE,EAQX,CAKA,kBAAkBI,EAA4C,CAC5D,IAAML,EAAQ,KAAK,YAAY,IAAIK,CAAS,EAC5C,GAAI,CAACL,EACH,OAAO,KAGT,IAAMH,EAAW,KAAK,UAAU,IAAIG,EAAM,UAAU,EACpD,MAAI,CAACH,GAAY,CAACA,EAAS,QAClB,KAGF,CACL,SAAAA,EACA,cAAeQ,EACf,YAAaL,EAAM,KACrB,CACF,CAKA,wBAAmC,CACjC,IAAMM,EAAuB,CAAC,EAC9B,YAAK,UAAU,QAAST,GAAa,CAC/BA,EAAS,SACXA,EAAS,OAAO,QAASC,GAAU,CACjCQ,EAAW,KAAKR,CAAK,EACrBQ,EAAW,KAAK,GAAGT,EAAS,EAAE,IAAIC,CAAK,EAAE,CAC3C,CAAC,CAEL,CAAC,EACMQ,CACT,CAKA,gBAA+B,CAC7B,OAAO,MAAM,KAAK,KAAK,YAAY,OAAO,CAAC,CAC7C,CAKA,MAAM,oBASH,CACD,IAAMC,EAMD,CAAC,EAEN,YAAK,UAAU,QAASV,GAAa,CAC/BA,EAAS,SACXA,EAAS,OAAO,QAASC,GAAU,CACjCS,EAAO,KAAK,CACV,GAAIT,EACJ,OAAQ,QACR,QAAS,KAAK,MAAMD,EAAS,UAAU,QAAQ,EAAI,GAAI,EACvD,SAAUA,EAAS,KACnB,SAAUA,EAAS,IACrB,CAAC,EAGDU,EAAO,KAAK,CACV,GAAI,GAAGV,EAAS,EAAE,IAAIC,CAAK,GAC3B,OAAQ,QACR,QAAS,KAAK,MAAMD,EAAS,UAAU,QAAQ,EAAI,GAAI,EACvD,SAAUA,EAAS,KACnB,SAAUA,EAAS,EACrB,CAAC,CACH,CAAC,CAEL,CAAC,EAEM,CACL,OAAQ,OACR,KAAMU,CACR,CACF,CACF,EClQO,SAASC,GACdC,EACsB,CACtB,OAAOA,EAAM,IAAKC,IAAU,CAC1B,KAAM,WACN,SAAU,CACR,KAAMA,EAAK,SAAS,KACpB,YAAaA,EAAK,SAAS,YAC3B,WAAYA,EAAK,SAAS,UAC5B,CACF,EAAE,CACJ,CAEO,SAASC,GAAwBF,EAAuC,CAC7E,OAAOA,EAAM,IAAKC,IAAU,CAC1B,KAAMA,EAAK,SAAS,KACpB,YAAaA,EAAK,SAAS,YAC3B,aAAcA,EAAK,SAAS,UAC9B,EAAE,CACJ,CAEO,SAASE,GACdH,EACe,CACf,OAAOA,EAAM,IAAKC,IAAU,CAC1B,KAAM,WACN,SAAU,CACR,KAAMA,EAAK,SAAS,KACpB,YAAaA,EAAK,SAAS,aAAe,GAC1C,WAAYA,EAAK,SAAS,UAC5B,CACF,EAAE,CACJ,CAEO,SAASG,GACdJ,EACe,CACf,OAAOA,EAAM,IAAKC,IAAU,CAC1B,KAAM,WACN,SAAU,CACR,KAAMA,EAAK,KACX,YAAaA,EAAK,aAAe,GACjC,WAAYA,EAAK,YACnB,CACF,EAAE,CACJ,CAEO,SAASI,GACdC,EACmB,CACnB,IAAMC,EAA4B,CAAC,EAC7BC,EAAuC,IAAI,IAEjDF,EAAQ,SAAS,QAASG,GAAQ,CAC5BA,EAAI,OAAS,QAAUA,EAAI,eACxBD,EAAmB,IAAIC,EAAI,YAAY,GAC1CD,EAAmB,IAAIC,EAAI,aAAc,CAAC,CAAC,EAE7CD,EAAmB,IAAIC,EAAI,YAAY,EAAE,KAAK,CAC5C,KAAM,OACN,QAASA,EAAI,QACb,aAAcA,EAAI,YACpB,CAAC,EAEL,CAAC,EAED,QAASC,EAAI,EAAGA,EAAIJ,EAAQ,SAAS,OAAQI,IAAK,CAChD,IAAMD,EAAMH,EAAQ,SAASI,CAAC,EAE9B,GAAID,EAAI,OAAS,OACf,SAGF,IAAME,EAAe,CACnB,KAAMF,EAAI,KACV,QAASA,EAAI,OACf,EAWA,GATIA,EAAI,YAAcA,EAAI,WAAW,OAAS,IAC5CE,EAAQ,WAAaF,EAAI,WACrBE,EAAQ,UAAY,OACtBA,EAAQ,QAAU,OAItBJ,EAAS,KAAKI,CAAO,EAGnBF,EAAI,OAAS,aACbA,EAAI,YACJA,EAAI,WAAW,OAAS,EAExB,QAAWG,KAAYH,EAAI,WACrBD,EAAmB,IAAII,EAAS,EAAE,GAClBJ,EAAmB,IAAII,EAAS,EAAE,EAE1C,QAASC,GAAa,CAC9BN,EAAS,KAAKM,CAAQ,CACxB,CAAC,EAEDL,EAAmB,OAAOI,EAAS,EAAE,GAErCL,EAAS,KAAK,CACZ,KAAM,OACN,QAAS,KAAK,UAAU,CACtB,QAAS,GACT,QAAS,kCACT,aAAcK,EAAS,EACzB,CAAC,EACD,aAAcA,EAAS,EACzB,CAAQ,CAIhB,CAEA,GAAIJ,EAAmB,KAAO,EAC5B,OAAW,CAACM,EAAIC,CAAS,IAAKP,EAAmB,QAAQ,EACvDO,EAAU,QAASF,GAAa,CAC9BN,EAAS,KAAKM,CAAQ,CACxB,CAAC,EAIL,IAAMG,EAAc,CAClB,SAAAT,EACA,MAAOD,EAAQ,MACf,WAAYA,EAAQ,WACpB,YAAaA,EAAQ,YACrB,OAAQA,EAAQ,MAClB,EAEA,OAAIA,EAAQ,OAASA,EAAQ,MAAM,OAAS,IAC1CU,EAAO,MAAQjB,GAAqBO,EAAQ,KAAK,EAC7CA,EAAQ,cACNA,EAAQ,cAAgB,QAAUA,EAAQ,cAAgB,OAC5DU,EAAO,YAAcV,EAAQ,YAE7BU,EAAO,YAAc,CACnB,KAAM,WACN,SAAU,CAAE,KAAMV,EAAQ,WAAY,CACxC,IAKCU,CACT,CAEO,SAASC,GACdX,EACsB,CAEtB,IAAMY,EAAiBZ,EAAQ,SAAS,OACrCG,GAAQA,EAAI,OAAS,QACxB,EACMU,EAAoBb,EAAQ,SAAS,OACxCG,GAAQA,EAAI,OAAS,QACxB,EAGMW,EACJF,EAAe,OAAS,EACpBA,EAAe,IAAKT,GAAQA,EAAI,OAAO,EAAE,KAAK;AAAA,CAAI,EAClD,OAEAF,EAA+B,CAAC,EAGtC,QAASG,EAAI,EAAGA,EAAIS,EAAkB,OAAQT,IAAK,CACjD,IAAMD,EAAMU,EAAkBT,CAAC,EAE/B,GAAID,EAAI,OAAS,OAEf,SAGF,IAAME,EAAe,CACnB,KAAMF,EAAI,IACZ,EAGA,GAAIA,EAAI,YAAcA,EAAI,WAAW,OAAS,EAAG,CAC/CY,EAAI,6DAA6B,EACjC,IAAMC,EAAiB,CAAC,EAItBb,EAAI,SACJA,EAAI,UAAY,MAChBA,EAAI,UAAY,QAChBA,EAAI,QAAQ,KAAK,GAEjBa,EAAQ,KAAK,CACX,KAAM,OACN,KAAMb,EAAI,OACZ,CAAC,EAIHA,EAAI,WAAW,QAASG,GAAa,CACnCU,EAAQ,KAAK,CACX,KAAM,WACN,GAAIV,EAAS,GACb,KAAMA,EAAS,SAAS,KACxB,MAAO,KAAK,MAAMA,EAAS,SAAS,WAAa,IAAI,CACvD,CAAC,CACH,CAAC,EAEDD,EAAQ,QAAUW,CACpB,SAAWb,EAAI,OAAS,OAAQ,CAE9B,IAAMa,EAAiB,CAAC,EAGpBC,EAAIb,EAAI,EACNc,EAAuB,CAAC,EAC9B,KAAOD,GAAK,GAAKJ,EAAkBI,CAAC,EAAE,OAAS,QAC7CC,EAAc,QAAQL,EAAkBI,CAAC,CAAC,EAC1CA,IAIFC,EAAc,QAASC,GAAY,CACjCH,EAAQ,KAAK,CACX,KAAM,cACN,YAAaG,EAAQ,aACrB,QAASA,EAAQ,SAAW,EAC9B,CAAC,CACH,CAAC,EAGGhB,EAAI,SAAWA,EAAI,QAAQ,KAAK,GAClCa,EAAQ,KAAK,CACX,KAAM,OACN,KAAMb,EAAI,OACZ,CAAC,EAICa,EAAQ,SAAW,GAAKA,EAAQ,CAAC,EAAE,OAAS,OAC9CX,EAAQ,QAAUW,EAAQ,CAAC,EAAE,KACpBA,EAAQ,SAAW,EAE5BX,EAAQ,QAAU,GAElBA,EAAQ,QAAUW,CAEtB,MAEEX,EAAQ,QAAUF,EAAI,SAAW,GAGnCF,EAAS,KAAKI,CAAO,CACvB,CAIA,IAAMe,EAAqBP,EAAkB,OAAS,EAClDQ,EAA6B,GAC3BC,EAAiC,CAAC,EAGxC,QACMlB,EAAIgB,EACRhB,GAAK,GAAKS,EAAkBT,CAAC,EAAE,OAAS,OACxCA,IAEAkB,EAAwB,QAAQT,EAAkBT,CAAC,CAAC,EACpDiB,EAA6B,GAG/B,GAAIA,EAA4B,CAC9BN,EAAI,8HAAwB,EAC5B,IAAMQ,EAA4B,CAAC,EAEnCD,EAAwB,QAASH,GAAY,CAC3CI,EAAmB,KAAK,CACtB,KAAM,cACN,YAAaJ,EAAQ,aACrB,QAASA,EAAQ,SAAW,EAC9B,CAAC,CACH,CAAC,EAGDlB,EAAS,KAAK,CACZ,KAAM,OACN,QAASsB,CACX,CAAC,CACH,CAEA,IAAMb,EAAc,CAClB,SAAAT,EACA,MAAOD,EAAQ,MACf,WAAYA,EAAQ,YAAc,KAClC,YAAaA,EAAQ,YACrB,OAAQA,EAAQ,OAChB,OAAAc,CACF,EAGA,OAAId,EAAQ,OAASA,EAAQ,MAAM,OAAS,IAC1CU,EAAO,MAAQd,GAAwBI,EAAQ,KAAK,EAGhDA,EAAQ,cACNA,EAAQ,cAAgB,OAC1BU,EAAO,YAAc,CAAE,KAAM,MAAO,EAC3BV,EAAQ,cAAgB,OAEjC,OAAOU,EAAO,MAGdA,EAAO,YAAc,CACnB,KAAM,OACN,KAAMV,EAAQ,WAChB,IAKCU,CACT,CAEA,SAASc,GAAkBR,EAA0B,CACnD,GAAI,CACF,IAAMS,EAAS,KAAK,MAAMT,CAAO,EACjC,OACE,MAAM,QAAQS,CAAM,GACpBA,EAAO,KAAMC,GAASA,EAAK,OAAS,YAAcA,EAAK,IAAMA,EAAK,IAAI,CAE1E,MAAQ,CACN,MAAO,EACT,CACF,CAEO,SAASC,GACd3B,EACoB,CAoDpB,IAAMU,EAA6B,CACjC,SApDiCV,EAAQ,SAAS,IAAKG,GAAQ,CAC/D,GACEA,EAAI,OAAS,aACb,OAAOA,EAAI,SAAY,UACvBqB,GAAkBrB,EAAI,OAAO,EAE7B,GAAI,CAEF,IAAMyB,EADY,KAAK,MAAMzB,EAAI,OAAO,EACH,IAAK0B,IAAe,CACvD,GAAIA,EAAK,GACT,KAAM,WACN,SAAU,CACR,KAAMA,EAAK,KACX,UAAW,KAAK,UAAUA,EAAK,OAAS,CAAC,CAAC,CAC5C,CACF,EAAE,EAEF,MAAO,CACL,KAAM1B,EAAI,KACV,QAAS,KACT,WAAYyB,CACd,CACF,MAAgB,CACd,MAAO,CACL,KAAMzB,EAAI,KACV,QAASA,EAAI,OACf,CACF,CAGF,OAAIA,EAAI,OAAS,OACR,CACL,KAAMA,EAAI,KACV,QACE,OAAOA,EAAI,SAAY,SACnBA,EAAI,QACJ,KAAK,UAAUA,EAAI,OAAO,EAChC,aAAeA,EAAY,YAC7B,EAGK,CACL,KAAMA,EAAI,KACV,QACE,OAAOA,EAAI,SAAY,SACnBA,EAAI,QACJ,KAAK,UAAUA,EAAI,OAAO,EAChC,GAAKA,EAAY,YAAc,CAAE,WAAaA,EAAY,UAAW,CACvE,CACF,CAAC,EAIC,MAAOH,EAAQ,MACf,WAAYA,EAAQ,WACpB,YAAaA,EAAQ,YACrB,OAAQA,EAAQ,MAClB,EAEA,OAAIA,EAAQ,OAASA,EAAQ,MAAM,OAAS,IAC1CU,EAAO,MAAQb,GAAuBG,EAAQ,KAAK,EAE/CA,EAAQ,cACN,OAAOA,EAAQ,aAAgB,SACjCU,EAAO,YAAcV,EAAQ,YACpBA,EAAQ,YAAY,OAAS,aACtCU,EAAO,YAAcV,EAAQ,YAAY,SAAS,QAKjDU,CACT,CAEO,SAASoB,GACd9B,EACoB,CACpB,IAAMC,EAA6B,CAAC,EAEhCD,EAAQ,QACVC,EAAS,KAAK,CACZ,KAAM,SACN,QAASD,EAAQ,MACnB,CAAC,EAEH,IAAM+B,EAA0B,CAAC,EAC3BC,EAA+B,CAAC,EAClCC,EAA0B,KAE9B,QAAS7B,EAAI,EAAGA,EAAIJ,EAAQ,SAAS,OAAQI,IAAK,CAChD,IAAMD,EAAMH,EAAQ,SAASI,CAAC,EAE9B,GAAI,OAAOD,EAAI,SAAY,SAAU,CACnC,GACE8B,IAAa,aACbF,EAAiB,OAAS,GAC1B5B,EAAI,OAAS,YACb,CACA,IAAM+B,EAAmC,CACvC,KAAM,YACN,QAASF,EAAmB,KAAK,EAAE,GAAK,KACxC,WACED,EAAiB,OAAS,EAAIA,EAAmB,MACrD,EACIG,EAAiB,YAAcF,EAAmB,SAAW,IAC/DE,EAAiB,QAAU,MAE7BjC,EAAS,KAAKiC,CAAgB,EAC9BH,EAAiB,OAAS,EAC1BC,EAAmB,OAAS,CAC9B,CAEA/B,EAAS,KAAK,CACZ,KAAME,EAAI,KACV,QAASA,EAAI,OACf,CAAC,CACH,SAAW,MAAM,QAAQA,EAAI,OAAO,EAAG,CACrC,IAAMgC,EAAuB,CAAC,EACxBC,EAAmB,CAAC,EACpBC,EAAqB,CAAC,EAmB5B,GAjBAlC,EAAI,QAAQ,QAASmC,GAAU,CACzBA,EAAM,OAAS,OACjBH,EAAW,KAAKG,EAAM,IAAI,EACjBA,EAAM,OAAS,WACxBF,EAAU,KAAK,CACb,GAAIE,EAAM,GACV,KAAM,WACN,SAAU,CACR,KAAMA,EAAM,KACZ,UAAW,KAAK,UAAUA,EAAM,OAAS,CAAC,CAAC,CAC7C,CACF,CAAC,EACQA,EAAM,OAAS,eACxBD,EAAY,KAAKC,CAAK,CAE1B,CAAC,EAEGD,EAAY,OAAS,EAAG,CAC1B,GAAIJ,IAAa,aAAeF,EAAiB,OAAS,EAAG,CAC3D,IAAMG,EAAmC,CACvC,KAAM,YACN,QAASF,EAAmB,KAAK,EAAE,GAAK,KACxC,WAAYD,CACd,EACIC,EAAmB,SAAW,IAChCE,EAAiB,QAAU,MAE7BjC,EAAS,KAAKiC,CAAgB,EAC9BH,EAAiB,OAAS,EAC1BC,EAAmB,OAAS,CAC9B,CAEAK,EAAY,QAASE,GAAe,CAClCtC,EAAS,KAAK,CACZ,KAAM,OACN,QACE,OAAOsC,EAAW,SAAY,SAC1BA,EAAW,QACX,KAAK,UAAUA,EAAW,OAAO,EACvC,aAAcA,EAAW,WAC3B,CAAC,CACH,CAAC,CACH,SAAWpC,EAAI,OAAS,YACtB,GAAI8B,IAAa,YACfF,EAAiB,KAAK,GAAGK,CAAS,EAClCJ,EAAmB,KAAK,GAAGG,CAAU,MAChC,CACL,GAAIJ,EAAiB,OAAS,EAAG,CAC/B,IAAMS,EAAuC,CAC3C,KAAM,YACN,QAASR,EAAmB,KAAK,EAAE,GAAK,KACxC,WAAYD,CACd,EACIC,EAAmB,SAAW,IAChCQ,EAAqB,QAAU,MAEjCvC,EAAS,KAAKuC,CAAoB,CACpC,CAEAT,EAAiB,OAAS,EAC1BC,EAAmB,OAAS,EAC5BD,EAAiB,KAAK,GAAGK,CAAS,EAClCJ,EAAmB,KAAK,GAAGG,CAAU,CACvC,KACK,CACL,GAAIF,IAAa,aAAeF,EAAiB,OAAS,EAAG,CAC3D,IAAMG,EAAmC,CACvC,KAAM,YACN,QAASF,EAAmB,KAAK,EAAE,GAAK,KACxC,WAAYD,CACd,EACIC,EAAmB,SAAW,IAChCE,EAAiB,QAAU,MAE7BjC,EAAS,KAAKiC,CAAgB,EAC9BH,EAAiB,OAAS,EAC1BC,EAAmB,OAAS,CAC9B,CAEA,IAAM3B,EAA0B,CAC9B,KAAMF,EAAI,KACV,QAASgC,EAAW,KAAK,EAAE,GAAK,IAClC,EAEIC,EAAU,OAAS,IACrB/B,EAAQ,WAAa+B,EACjBD,EAAW,SAAW,IACxB9B,EAAQ,QAAU,OAItBJ,EAAS,KAAKI,CAAO,CACvB,CACF,KAAO,CACL,GAAI4B,IAAa,aAAeF,EAAiB,OAAS,EAAG,CAC3D,IAAMG,EAAmC,CACvC,KAAM,YACN,QAASF,EAAmB,KAAK,EAAE,GAAK,KACxC,WAAYD,CACd,EACIC,EAAmB,SAAW,IAChCE,EAAiB,QAAU,MAE7BjC,EAAS,KAAKiC,CAAgB,EAC9BH,EAAiB,OAAS,EAC1BC,EAAmB,OAAS,CAC9B,CAEA/B,EAAS,KAAK,CACZ,KAAME,EAAI,KACV,QAAS,KAAK,UAAUA,EAAI,OAAO,CACrC,CAAC,CACH,CAEA8B,EAAW9B,EAAI,IACjB,CAEA,GAAI8B,IAAa,aAAeF,EAAiB,OAAS,EAAG,CAC3D,IAAMG,EAAmC,CACvC,KAAM,YACN,QAASF,EAAmB,KAAK,EAAE,GAAK,KACxC,WAAYD,CACd,EACIC,EAAmB,SAAW,IAChCE,EAAiB,QAAU,MAE7BjC,EAAS,KAAKiC,CAAgB,CAChC,CAEA,IAAMxB,EAA6B,CACjC,SAAAT,EACA,MAAOD,EAAQ,MACf,WAAYA,EAAQ,WACpB,YAAaA,EAAQ,YACrB,OAAQA,EAAQ,MAClB,EAEA,OAAIA,EAAQ,OAASA,EAAQ,MAAM,OAAS,IAC1CU,EAAO,MAAQZ,GAA0BE,EAAQ,KAAK,EAElDA,EAAQ,cACNA,EAAQ,YAAY,OAAS,OAC/BU,EAAO,YAAc,OACZV,EAAQ,YAAY,OAAS,SACtCU,EAAO,YAAcV,EAAQ,YAAY,QAKxCU,CACT,CAEO,SAAS+B,GACdzC,EACA0C,EAC0C,CAC1C,IAAIC,EASJ,OARID,EAAQ,iBAAmB,SAC7BC,EAAiBhB,GAAkB3B,CAA4B,EACtD0C,EAAQ,iBAAmB,YACpCC,EAAiBb,GAAqB9B,CAA+B,EAErE2C,EAAiB3C,EAGf0C,EAAQ,iBAAmB,SACtB3C,GAAgB4C,CAAc,EAE9BhC,GAAmBgC,CAAc,CAE5C,CCloBA,IAAAC,GAA2B,kBAEpB,SAASC,EACdC,EACAC,EACAC,EACmB,CACnB,IAAMC,EAAU,IAAI,QAAQ,CAC1B,eAAgB,kBAClB,CAAC,EACGD,EAAO,SACT,OAAO,QAAQA,EAAO,OAAO,EAAE,QAAQ,CAAC,CAACE,EAAKC,CAAK,IAAM,CACvDF,EAAQ,IAAIC,EAAKC,CAAe,CAClC,CAAC,EAEH,IAAIC,EACEC,EAAgB,YAAY,QAAQL,EAAO,SAAW,GAAK,IAAO,EAAE,EAE1E,GAAIA,EAAO,OAAQ,CACjB,IAAMM,EAAa,IAAI,gBACjBC,EAAe,IAAMD,EAAW,MAAM,EAC5CN,EAAO,OAAO,iBAAiB,QAASO,CAAY,EACpDF,EAAc,iBAAiB,QAASE,CAAY,EACpDH,EAAiBE,EAAW,MAC9B,MACEF,EAAiBC,EAGnB,IAAMG,EAA4B,CAChC,OAAQ,OACR,QAASP,EACT,KAAM,KAAK,UAAUF,CAAO,EAC5B,OAAQK,CACV,EACMK,EAAaC,EAAc,cAAc,EAC/C,OAAID,GAAc,OAAO,OAAW,MACjCD,EAAqB,WAAa,IAAI,cACrC,IAAI,IAAIC,CAAU,EAAE,SAAS,CAC/B,GAEK,MACL,OAAOX,GAAQ,SAAWA,EAAMA,EAAI,SAAS,EAC7CU,CACF,CACF,CC7BO,IAAMG,EAAN,KAAiB,CACd,gBAER,aAAc,CACZ,KAAK,gBAAkB,IAAIC,CAC7B,CAEA,iBAAiBC,EAA+C,CAC9D,OAAO,KAAK,gBAAgB,iBAAiBA,CAAO,CACtD,CAEA,cAA8B,CAC5B,OAAO,KAAK,gBAAgB,aAAa,CAC3C,CAEA,YAAYC,EAAqC,CAC/C,OAAO,KAAK,gBAAgB,YAAYA,CAAE,CAC5C,CAEA,eACEA,EACAC,EACoB,CAEpB,OADe,KAAK,gBAAgB,eAAeD,EAAIC,CAAO,CAEhE,CAEA,eAAeD,EAAqB,CAElC,OADe,KAAK,gBAAgB,eAAeA,CAAE,CAEvD,CAEA,eAAeA,EAAYE,EAA2B,CACpD,OAAO,KAAK,gBAAgB,eAAeF,EAAIE,CAAO,CACxD,CAEQ,aAAaC,EAAqC,CACxD,IAAMC,EAAQ,KAAK,gBAAgB,kBAAkBD,CAAS,EAC9D,GAAI,CAACC,EACH,MAAM,IAAI,MACR,SAASD,CAAS,iCAAiC,KAAK,uBAAuB,EAAE,KAC/E,IACF,CAAC,EACH,EAEF,OAAOC,CACT,CAEA,MAAM,0BACJC,EACAC,EACmB,CACnB,GAAI,CACF,KAAK,gBAAgBD,CAAW,EAChC,IAAMF,EAAYE,EAAY,MACxBD,EAAQ,KAAK,aAAaD,CAAS,EACnC,CAAE,SAAAI,EAAU,YAAAC,CAAY,EAAIJ,EAC5BK,EAAa,KAAK,uBAAuBJ,CAAW,EAC1DI,EAAW,MAAQD,EACnB,IAAIE,EASJ,GARIH,EAAS,OAAS,YACpBG,EAAkBC,GAAeF,EAAY,CAC3C,eAAgB,SAChB,eAAgB,WAClB,CAAC,EAEDC,EAAkBD,EAEhBH,GAAQ,QACV,MAAM,IAAI,MAAM,qBAAqB,EAEvC,IAAMM,EAAW,MAAMC,EACrB,KAAK,YAAYN,EAAS,EAAE,EAC5BG,EACA,CAAE,OAAAJ,CAAO,CACX,EACA,GAAIA,GAAQ,QACV,MAAM,IAAI,MAAM,qBAAqB,EAGvC,IAAMQ,EAAWT,EAAY,SAAW,GACxC,GAAIE,EAAS,OAAS,YACpB,GAAIO,EAAU,CACZ,GAAI,CAACF,EAAS,KACZ,MAAM,IAAI,MAAM,8BAA8B,EAEhD,IAAMG,EAAkB,MAAM,KAAK,+BACjCH,EAAS,IACX,EACA,OAAO,IAAI,SAASG,EAAiB,CACnC,QAAS,CACP,eAAgB,oBAChB,gBAAiB,WACjB,WAAY,YACd,CACF,CAAC,CACH,KAAO,CACL,IAAMC,EAAO,MAAMJ,EAAS,KAAK,EAC3BK,EAAiB,KAAK,iCAAiCD,CAAI,EACjE,OAAO,IAAI,SAAS,KAAK,UAAUC,CAAc,EAAG,CAClD,QAAS,CAAE,eAAgB,kBAAmB,CAChD,CAAC,CACH,KAEA,QAAOL,CAEX,OAASM,EAAO,CACd,GACEA,aAAiB,QAChBA,EAAM,QAAQ,SAAS,SAAS,GAAKA,EAAM,OAAS,cAErD,MAAMA,EAGR,GAAIb,GAAa,OAAQ,CACvB,IAAMc,EAAc,KAAK,wBAAwBD,CAAc,EAC/D,OAAO,IAAI,SAASC,EAAa,CAC/B,QAAS,CACP,eAAgB,oBAChB,gBAAiB,WACjB,WAAY,YACd,CACF,CAAC,CACH,KACE,OAAMD,CAEV,CACF,CAEQ,iCACNE,EACgB,CAChB,IAAMC,EAAcD,EAAkB,QAAQ,KAC3CE,GAAiBA,EAAQ,OAAS,MACrC,EAMMC,EALiBH,EAAkB,QAAQ,OAC9CE,GAAiBA,EAAQ,OAAS,UACrC,EAGkC,IAAI,CAACE,EAAcC,KAAmB,CACtE,GAAID,EAAQ,IAAM,QAAQ,KAAK,IAAI,CAAC,IAAIC,CAAK,GAC7C,KAAM,WACN,SAAU,CACR,KAAMD,EAAQ,KACd,UAAW,KAAK,UAAUA,EAAQ,OAAS,CAAC,CAAC,CAC/C,CACF,EAAE,EAEF,MAAO,CACL,GAAI,YAAY,KAAK,IAAI,CAAC,GAC1B,OAAQ,kBACR,QAAS,KAAK,MAAM,KAAK,IAAI,EAAI,GAAI,EACrC,MAAOJ,EAAkB,MACzB,QAAS,CACP,CACE,MAAO,EACP,QAAS,CACP,KAAM,YACN,QAASC,GAAa,MAAQ,KAC9B,QAAS,KACT,WAAYE,EAAW,OAAS,EAAIA,EAAa,MACnD,EACA,SAAU,KACV,cACEH,EAAkB,cAAgB,WAC9B,OACAA,EAAkB,cAAgB,aAClC,SACAA,EAAkB,cAAgB,WAClC,cACAA,EAAkB,cAAgB,gBAClC,OAER,CACF,EACA,MAAO,CACL,cAAeA,EAAkB,MAAM,aACvC,kBAAmBA,EAAkB,MAAM,cAC3C,aACEA,EAAkB,MAAM,aACxBA,EAAkB,MAAM,aAC5B,CACF,CACF,CAEA,MAAc,+BACZM,EACyB,CAqQzB,OApQiB,IAAI,eAAe,CAClC,MAAM,MAAMC,EAAY,CACtB,IAAMC,EAAU,IAAI,YAChBC,EAAY,GACZC,EAAQ,UACNC,EAAY,IAAI,IAClBC,EAAW,GAGTC,EAAejB,GAAqB,CACxC,GAAI,CAACgB,EACH,GAAI,CACFL,EAAW,QAAQX,CAAI,CACzB,OAASE,EAAO,CACd,GACEA,aAAiB,WACjBA,EAAM,QAAQ,SAAS,8BAA8B,EAErDgB,EAAI,6FAAkB,EACtBF,EAAW,OAEX,OAAMd,CAEV,CAEJ,EAGMiB,EAAY,IAAM,CACtB,GAAI,CAACH,EACH,GAAI,CACFL,EAAW,MAAM,EACjBK,EAAW,EACb,OAASd,EAAO,CACd,GACEA,aAAiB,WACjBA,EAAM,QAAQ,SAAS,8BAA8B,EAErDgB,EAAI,yDAAY,EAChBF,EAAW,OAEX,OAAMd,CAEV,CAEJ,EAEIkB,EAAyD,KAE7D,GAAI,CACFA,EAASV,EAAgB,UAAU,EACnC,IAAMW,EAAU,IAAI,YAChBC,EAAS,GAEb,OAAa,CACX,GAAIN,EAAU,CACZE,EAAI,uFAAiB,EACrB,KACF,CAEA,GAAM,CAAE,KAAAK,EAAM,MAAAC,CAAM,EAAI,MAAMJ,EAAO,KAAK,EAC1C,GAAIG,EAAM,MAEVD,GAAUD,EAAQ,OAAOG,EAAO,CAAE,OAAQ,EAAK,CAAC,EAChD,IAAMC,EAAQH,EAAO,MAAM;AAAA,CAAI,EAC/BA,EAASG,EAAM,IAAI,GAAK,GAExB,QAAWC,KAAQD,EAAO,CACxB,GAAIT,EAAU,MAEd,GAAIU,EAAK,WAAW,QAAQ,EAAG,CAC7B,IAAM1B,EAAO0B,EAAK,MAAM,CAAC,EACzB,GAAI1B,IAAS,SAAU,SAEvB,GAAI,CACF,IAAM2B,EAAQ,KAAK,MAAM3B,CAAI,EACzB4B,EAA0C,KAE9C,GAAID,EAAM,OAAS,iBAAmB,CAACX,EACrCH,EAAY,YAAY,KAAK,IAAI,CAAC,GAClCC,EAAQa,EAAM,SAAS,OAAS,UAChCC,EAAc,CACZ,GAAIf,EACJ,OAAQ,wBACR,QAAS,KAAK,MAAM,KAAK,IAAI,EAAI,GAAI,EACrC,MAAOC,EACP,QAAS,CACP,CACE,MAAO,EACP,MAAO,CACL,KAAM,YACN,QAAS,EACX,EACA,SAAU,KACV,cAAe,IACjB,CACF,CACF,UAEAa,EAAM,OAAS,uBACf,CAACX,EACD,CACA,IAAMa,EAASF,EAAc,cAC7B,GAAIE,GAAO,OAAS,WAAY,CAE9B,IAAMC,EACJD,EAAM,IACN,QAAQ,KAAK,IAAI,CAAC,IAAKF,EAAc,KAAK,GACtCI,EAAW,CACf,MAAQJ,EAAc,MACtB,GAAIG,EACJ,KAAM,WACN,SAAU,CACR,KAAMD,EAAM,KACZ,UAAW,EACb,CACF,EACAd,EAAU,IAAKY,EAAc,MAAOI,CAAQ,EAE5CH,EAAc,CACZ,GAAIf,GAAa,YAAY,KAAK,IAAI,CAAC,GACvC,OAAQ,wBACR,QAAS,KAAK,MAAM,KAAK,IAAI,EAAI,GAAI,EACrC,MAAOC,EACP,QAAS,CACP,CACE,MAAO,EACP,MAAO,CACL,WAAY,CAACiB,CAAQ,CACvB,EACA,SAAU,KACV,cAAe,IACjB,CACF,CACF,CACF,CACF,SACEJ,EAAM,OAAS,uBACf,CAACX,EACD,CACA,IAAMgB,EAASL,EAAc,MAC7B,GAAIK,GAAO,OAAS,cAAgBA,EAAM,KACxCJ,EAAc,CACZ,GAAIf,GAAa,YAAY,KAAK,IAAI,CAAC,GACvC,OAAQ,wBACR,QAAS,KAAK,MAAM,KAAK,IAAI,EAAI,GAAI,EACrC,MAAOC,EACP,QAAS,CACP,CACE,MAAO,EACP,MAAO,CAAE,QAASkB,EAAM,IAAK,EAC7B,SAAU,KACV,cAAe,IACjB,CACF,CACF,UAEAA,GAAO,OAAS,oBAChBA,EAAM,aACN,CAEA,IAAMvB,EAASkB,EAAc,MACJZ,EAAU,IAAIN,CAAK,IAE1CmB,EAAc,CACZ,GAAIf,GAAa,YAAY,KAAK,IAAI,CAAC,GACvC,OAAQ,wBACR,QAAS,KAAK,MAAM,KAAK,IAAI,EAAI,GAAI,EACrC,MAAOC,EACP,QAAS,CACP,CACE,MAAO,EACP,MAAO,CACL,WAAY,CACV,CACE,MAAOL,EACP,SAAU,CACR,UAAWuB,EAAM,YACnB,CACF,CACF,CACF,EACA,SAAU,KACV,cAAe,IACjB,CACF,CACF,EAEJ,CACF,SACEL,EAAM,OAAS,iBACdA,EAAM,OAAe,aACtB,CAACX,EACD,CACA,IAAMiB,EAAcN,EAAM,MAAc,YACxCC,EAAc,CACZ,GAAIf,GAAa,YAAY,KAAK,IAAI,CAAC,GACvC,OAAQ,wBACR,QAAS,KAAK,MAAM,KAAK,IAAI,EAAI,GAAI,EACrC,MAAOC,EACP,QAAS,CACP,CACE,MAAO,EACP,MAAO,CAAC,EACR,SAAU,KACV,cACEmB,IAAe,WACX,OACAA,IAAe,aACf,SACAA,IAAe,WACf,aACA,MACR,CACF,CACF,CACF,CAEA,GAAIL,GAAe,CAACZ,EAAU,CAC5B,IAAMhB,EAAO,SAAS,KAAK,UAAU4B,CAAW,CAAC;AAAA;AAAA,EACjDX,EAAYL,EAAQ,OAAOZ,CAAI,CAAC,CAClC,CACF,OAASkC,EAAY,CACnB,QAAQ,KAAK,yBAA0BA,CAAU,CACnD,CACF,CACF,CACF,CAGKlB,GACHC,EAAYL,EAAQ,OAAO;AAAA;AAAA,CAAkB,CAAC,EAEhDO,EAAU,CACZ,OAASjB,EAAO,CAEd,GADA,QAAQ,MAAM,kDAAqBA,CAAK,EACpC,CAACc,EACH,GAAI,CACFL,EAAW,MAAMT,CAAK,CACxB,OAASiC,EAAiB,CACxBjB,EAAI,mFAAmBiB,CAAe,CACxC,CAEJ,QAAE,CAEA,GAAIf,EACF,GAAI,CACFA,EAAO,YAAY,CACrB,OAASgB,EAAc,CACrBlB,EAAI,qDAAmBkB,CAAY,CACrC,CAEJ,CACF,EACA,OAAOC,EAAQ,CACbnB,EAAI,+CAAqBmB,CAAM,CAEjC,CACF,CAAC,CAGH,CAEQ,wBAAwBnC,EAA8B,CAC5D,OAAO,IAAI,eAAe,CACxB,MAAMS,EAAY,CAChB,IAAMC,EAAU,IAAI,YACd0B,EAAa,CACjB,GAAI,kBAAkB,KAAK,IAAI,CAAC,GAChC,OAAQ,wBACR,QAAS,KAAK,MAAM,KAAK,IAAI,EAAI,GAAI,EACrC,MAAO,QACP,QAAS,CACP,CACE,MAAO,EACP,MAAO,CAAE,QAAS,UAAUpC,EAAM,OAAO,EAAG,EAC5C,SAAU,KACV,cAAe,MACjB,CACF,CACF,EAEAS,EAAW,QACTC,EAAQ,OAAO,SAAS,KAAK,UAAU0B,CAAU,CAAC;AAAA;AAAA,CAAM,CAC1D,EACA3B,EAAW,QAAQC,EAAQ,OAAO;AAAA;AAAA,CAAkB,CAAC,EACrDD,EAAW,MAAM,CACnB,CACF,CAAC,CACH,CAEQ,gBAAgBtB,EAAwB,CAC9C,GAAI,CAACA,EACH,MAAM,IAAI,MAAM,0BAA0B,EAG5C,GAAI,CAACA,EAAY,MACf,MAAM,IAAI,MAAM,mCAAmC,EAGrD,GAAI,CAACA,EAAY,UAAY,CAAC,MAAM,QAAQA,EAAY,QAAQ,EAC9D,MAAM,IAAI,MAAM,4CAA4C,EAG9D,GAAIA,EAAY,SAAS,SAAW,EAClC,MAAM,IAAI,MAAM,kCAAkC,CAEtD,CAEQ,uBAAuBkD,EAAwC,CACrE,MAAO,CACL,SAAUA,EAAc,SAAS,IAAKC,IAAc,CAClD,KAAMA,EAAI,KACV,QAASA,EAAI,QACb,WAAYA,EAAI,WAChB,aAAcA,EAAI,YACpB,EAAE,EACF,MAAOD,EAAc,MACrB,WAAYA,EAAc,WAC1B,YAAaA,EAAc,YAC3B,OAAQA,EAAc,OACtB,MAAOA,EAAc,MACjB,KAAK,4BAA4BA,EAAc,KAAK,EACpD,OACJ,YAAaA,EAAc,WAC7B,CACF,CAEQ,4BAA4BE,EAA6B,CAC/D,OAAOA,EAAM,IAAKC,IAAU,CAC1B,KAAM,WACN,SAAU,CACR,KAAMA,EAAK,SAAS,KACpB,YAAaA,EAAK,SAAS,aAAe,GAC1C,WAAYA,EAAK,SAAS,UAC5B,CACF,EAAE,CACJ,CAEA,MAAM,oBAAmC,CAGvC,MAAO,CACL,OAAQ,OACR,KAJgB,KAAK,gBAAgB,mBAAmB,EAIxC,QAASnD,GACvBA,EAAS,OAAO,IAAKuB,IAAW,CAC9B,GAAIA,EACJ,OAAQ,QACR,SAAUvB,EAAS,SACnB,QAAS,KAAK,MAAM,KAAK,IAAI,EAAI,GAAI,EACrC,SAAUA,EAAS,QACrB,EAAE,CACJ,CACF,CACF,CAEQ,wBAAmC,CACzC,OAAO,KAAK,gBACT,eAAe,EACf,IAAKH,GAAUA,EAAM,SAAS,CACnC,CAEA,gBAAiB,CACf,OAAO,KAAK,gBAAgB,eAAe,CAC7C,CACF,ECtjBO,IAAMuD,EAAN,KAAkD,CACvD,KAAO,YACP,SAAW,eAEX,oBAAoBC,EAAkD,CACpEC,EAAI,qBAAsB,KAAK,UAAUD,EAAS,KAAM,CAAC,CAAC,EAE1D,IAAME,EAA6B,CAAC,EACpC,GAAIF,EAAQ,OAAQ,CAClB,IAAIG,EAAgB,GAChB,OAAOH,EAAQ,QAAW,SAC5BG,EAAgBH,EAAQ,OACf,MAAM,QAAQA,EAAQ,MAAM,IAIrCG,EAHkBH,EAAQ,OACvB,OAAQI,GAAcA,EAAK,OAAS,MAAM,EAC1C,IAAKA,GAAcA,EAAK,IAAI,EACL,KAAK;AAAA,CAAI,GAGjCD,GACFD,EAAS,KAAK,CACZ,KAAM,SACN,QAASC,CACX,CAAC,CAEL,CAEA,IAAME,EAAkB,KAAK,MAAM,KAAK,UAAUL,EAAQ,UAAY,CAAC,CAAC,CAAC,EAGzE,OAF6B,KAAK,mBAAmBK,CAAe,GAE9C,QAAQ,CAACC,EAAUC,IAAkB,CACzD,GAAI,CAAAD,EAAI,WACJA,EAAI,OAAS,QAAUA,EAAI,OAAS,aAAa,CACnD,IAAME,EAA6B,CACjC,KAAMF,EAAI,KACV,QAAS,IACX,EACA,GAAI,OAAOA,EAAI,SAAY,SACzBE,EAAW,QAAUF,EAAI,QACzBJ,EAAS,KAAKM,CAAU,UACf,MAAM,QAAQF,EAAI,OAAO,EAAG,CACrC,IAAMG,EAAsB,CAAC,EACvBC,EAAiBJ,EAAI,QAAQ,OAChCK,GAAWA,EAAE,OAAS,UACzB,EACMC,EAAoBN,EAAI,QAAQ,OACnCK,GAAWA,EAAE,OAAS,aACzB,EAEAL,EAAI,QAAQ,QAAQ,CAACO,EAAkBC,IAAyB,CAC1DD,EAAY,OAAS,QACnBA,EAAY,MACdJ,EAAU,KAAKI,EAAY,IAAI,CAGrC,CAAC,EAEGJ,EAAU,OAAS,EACrBD,EAAW,QAAUC,EAAU,KAAK;AAAA,CAAI,EAExCR,EAAI,WAAWM,EAAQ,CAAC,8BAA8B,EAGpDG,EAAe,OAAS,IAC1BF,EAAW,WAAaE,EAAe,IACrC,CAACK,EAAWC,IAAsB,CAChC,IAAIC,EAAe,KACnB,GAAI,CACEF,EAAK,OAAS,OAAOA,EAAK,OAAU,SACtCE,EAAe,KAAK,UAAUF,EAAK,KAAK,EAC/B,OAAOA,EAAK,OAAU,WAC/B,KAAK,MAAMA,EAAK,KAAK,EACrBE,EAAeF,EAAK,MAExB,OAASG,EAAO,CACdjB,EACE,yBACAiB,EACA,oBACAH,EAAK,KACP,EACAE,EAAe,KAAK,UAAUF,EAAK,OAAS,CAAC,CAAC,CAChD,CAEA,MAAO,CACL,GAAIA,EAAK,GACT,KAAM,WACN,SAAU,CACR,KAAMA,EAAK,KACX,UAAWE,CACb,CACF,CACF,CACF,GAEF,IAAME,EACJX,EAAW,SACVA,EAAW,YAAcA,EAAW,WAAW,OAAS,EAEvDW,GACFjB,EAAS,KAAKM,CAAU,EAGtBI,EAAkB,OAAS,GAC7BA,EAAkB,QAAQ,CAACQ,EAAaC,IAAwB,CAC9D,IAAMC,EAA8B,CAClC,KAAM,OACN,QACE,OAAOF,EAAO,SAAY,SACtBA,EAAO,QACP,KAAK,UAAUA,EAAO,OAAO,EACnC,aAAcA,EAAO,WACvB,EACAlB,EAAS,KAAKoB,CAAW,CAC3B,CAAC,EAGC,CAACH,GAAuBP,EAAkB,OAAS,CAEzD,CACF,CACF,CAAC,EAEkC,CACjC,SAAAV,EACA,MAAOF,EAAQ,MACf,WAAYA,EAAQ,WACpB,YAAaA,EAAQ,YACrB,OAAQA,EAAQ,OAChB,MAAOA,EAAQ,MACX,KAAK,+BAA+BA,EAAQ,KAAK,EACjD,OACJ,YAAaA,EAAQ,WACvB,CAEF,CAEA,MAAM,qBAAqBuB,EAAoB,CAI7C,GAHiBA,EAAS,QACvB,IAAI,cAAc,GACjB,SAAS,mBAAmB,EAClB,CACZ,GAAI,CAACA,EAAS,KACZ,MAAM,IAAI,MAAM,8BAA8B,EAEhD,IAAMC,EAAkB,MAAM,KAAK,+BACjCD,EAAS,IACX,EACA,OAAO,IAAI,SAASC,EAAiB,CACnC,QAAS,CACP,eAAgB,oBAChB,gBAAiB,WACjB,WAAY,YACd,CACF,CAAC,CACH,KAAO,CACL,IAAMC,EAAO,MAAMF,EAAS,KAAK,EAC3BG,EAAoB,KAAK,iCAAiCD,CAAI,EACpE,OAAO,IAAI,SAAS,KAAK,UAAUC,CAAiB,EAAG,CACrD,QAAS,CAAE,eAAgB,kBAAmB,CAChD,CAAC,CACH,CACF,CAEQ,mBAAmBxB,EAAwB,CACjD,IAAMyB,EAA2B,CAAC,EAC5BC,EAAiB,IAAI,IACrBC,EAA2B,IAAI,IACrC3B,EAAS,QAAQ,CAACI,EAAKwB,IAAa,CAC9B,MAAM,QAAQxB,EAAI,OAAO,GAC3BA,EAAI,QAAQ,QAASF,GAAc,CAC7BA,EAAK,OAAS,eAAiBA,EAAK,cACtCwB,EAAe,IAAIxB,EAAK,YAAaA,CAAI,EACzCyB,EAAyB,IAAIzB,EAAK,YAAa0B,CAAQ,EAE3D,CAAC,CAEL,CAAC,EACD,IAAMC,EAAoB,IAAI,IAE9B,QAASC,EAAI,EAAGA,EAAI9B,EAAS,OAAQ8B,IAAK,CACxC,IAAMC,EAAa/B,EAAS8B,CAAC,EAC7B,GACEC,EAAW,OAAS,aACpB,MAAM,QAAQA,EAAW,OAAO,EAChC,CACA,IAAMC,EAAeD,EAAW,QAAQ,OACrC7B,GAAcA,EAAK,OAAS,UAC/B,EAEA,GAAI8B,EAAa,OAAS,EAAG,CAC3BP,EAAkB,KAAKM,CAAU,EAEjC,IAAME,EAAUH,EAAI,EAAI9B,EAAS,OAASA,EAAS8B,EAAI,CAAC,EAAI,KACtDI,EAA4BF,EAAa,IAC5C9B,GAAcA,EAAK,EACtB,EAEIiC,EAAgB,GAChBC,EAAiC,CAAC,EActC,GAZIH,GAAW,MAAM,QAAQA,EAAQ,OAAO,IAI1CG,EAHoBH,EAAQ,QAAQ,OACjC/B,GAAcA,EAAK,OAAS,aAC/B,EACmC,IAChCA,GAAcA,EAAK,WACtB,EACAiC,EAAgBD,EAAW,MAAOG,GAChCD,EAAqB,SAASC,CAAE,CAClC,GAGE,CAACF,EAAe,CAClB,IAAMG,EAAaJ,EAAW,OAC3BG,GAAO,CAACD,EAAqB,SAASC,CAAE,CAC3C,EACME,EAAsB,CAAC,EAU7B,GARAD,EAAW,QAASE,GAAc,CAChC,IAAMC,EAAcf,EAAe,IAAIc,CAAS,EAC5CC,IACFF,EAAa,KAAKE,CAAW,EAC7BZ,EAAkB,IAAIW,CAAS,EAEnC,CAAC,EAEGD,EAAa,OAAS,EAAG,CAC3B,IAAMG,EAAgB,CACpB,KAAM,OACN,QAASH,EACT,SAAU,EACZ,EAEAd,EAAkB,KAAKiB,CAAa,CACtC,CACF,CACF,CACF,SACM,MAAM,QAAQX,EAAW,OAAO,EAAG,CACrC,IAAMY,EAAmBZ,EAAW,QAAQ,OAAQ7B,GAC9CA,EAAK,OAAS,eAAiBA,EAAK,YAC/B,CAAC2B,EAAkB,IAAI3B,EAAK,WAAW,EAEzC,EACR,EAED,GAAIyC,EAAiB,OAAS,EAAG,CAC/B,IAAMC,EAAc,CAClB,GAAGb,EACH,QAASY,CACX,EAGA,GAFAlB,EAAkB,KAAKmB,CAAW,EAE9BD,EAAiB,SAAWZ,EAAW,QAAQ,OAAQ,CACzD,IAAMc,EACJd,EAAW,QAAQ,OAASY,EAAiB,MACjD,CACF,CACF,MACElB,EAAkB,KAAKM,CAAU,CAGvC,CACA,OAAON,CACT,CAEQ,+BAA+BqB,EAA6B,CAClE,OAAOA,EAAM,IAAKjC,IAAU,CAC1B,KAAM,WACN,SAAU,CACR,KAAMA,EAAK,KACX,YAAaA,EAAK,aAAe,GACjC,WAAYA,EAAK,YACnB,CACF,EAAE,CACJ,CAEA,MAAc,+BACZkC,EACyB,CAkjBzB,OAjjBiB,IAAI,eAAe,CAClC,MAAM,MAAMC,EAAY,CACtB,IAAMC,EAAU,IAAI,YACdC,EAAY,OAAO,KAAK,IAAI,CAAC,GAC/BC,EAAQ,UACRC,EAAa,GACbC,EAAwB,GACxBC,EAAc,GACZC,EAAY,IAAI,IAChBC,EAAmC,IAAI,IACzCC,EAAc,EACdC,EAAgB,EAChBC,EAAiB,EACjBC,EAAW,GACXC,EAAoB,GAClBC,EAAkB,CACtB,eAAgB,EAChB,gBAAiB,EACjB,WAAY,EACZ,eAAgB,EAChB,YAAa,EACb,cAAe,EACf,WAAY,CACd,EAEMC,EAAexC,GAAqB,CACxC,GAAI,CAACqC,EACH,GAAI,CACFZ,EAAW,QAAQzB,CAAI,EACvBuC,EAAgB,aAChB,IAAME,EAAU,IAAI,YAAY,EAAE,OAAOzC,CAAI,EAC7CxB,EAAI,aAAciE,EAAQ,KAAK,CAAC,CAClC,OAAShD,EAAO,CACd,GACEA,aAAiB,WACjBA,EAAM,QAAQ,SAAS,8BAA8B,EAErD4C,EAAW,OAEX,OAAA7D,EAAI,oBAAoBiB,EAAM,OAAO,EAAE,EACjCA,CAEV,CAEJ,EAEMiD,EAAY,IAAM,CACtB,GAAI,CAACL,EACH,GAAI,CACFZ,EAAW,MAAM,EACjBY,EAAW,EACb,OAAS5C,EAAO,CACd,GACEA,aAAiB,WACjBA,EAAM,QAAQ,SAAS,8BAA8B,EAErD4C,EAAW,OAEX,OAAM5C,CAEV,CAEJ,EAEIkD,EAAyD,KAE7D,GAAI,CACFA,EAASnB,EAAa,UAAU,EAChC,IAAMoB,EAAU,IAAI,YAChBC,EAAS,GAEb,KACM,CAAAR,GADO,CAKX,GAAM,CAAE,KAAAS,EAAM,MAAAC,EAAM,EAAI,MAAMJ,EAAO,KAAK,EAC1C,GAAIG,EAAM,MAEVD,GAAUD,EAAQ,OAAOG,GAAO,CAAE,OAAQ,EAAK,CAAC,EAChD,IAAMC,EAAQH,EAAO,MAAM;AAAA,CAAI,EAC/BA,EAASG,EAAM,IAAI,GAAK,GAExB,QAAWC,KAAQD,EAAO,CACxB,GAAIX,GAAYN,EAAa,MAE7B,GAAIkB,EAAK,WAAW,QAAQ,EAAG,CAC7B,IAAMjD,EAAOiD,EAAK,MAAM,CAAC,EACzB,GAAIjD,IAAS,SACX,SAGF,GAAI,CACF,IAAMkD,EAAQ,KAAK,MAAMlD,CAAI,EAO7B,GANAuC,EAAgB,iBAChBL,IACA1D,EAAI,wBAAyB,KAAK,UAAU0E,EAAO,KAAM,CAAC,CAAC,EAE3DtB,EAAQsB,EAAM,OAAStB,EAEnB,CAACC,GAAc,CAACQ,GAAY,CAACN,EAAa,CAC5CF,EAAa,GAEb,IAAMsB,EAAe,CACnB,KAAM,gBACN,QAAS,CACP,GAAIxB,EACJ,KAAM,UACN,KAAM,YACN,QAAS,CAAC,EACV,MAAOC,EACP,YAAa,KACb,cAAe,IACjB,CACF,EAEApD,EACE,4BACA,KAAK,UAAU2E,EAAc,KAAM,CAAC,CACtC,EACAX,EACEd,EAAQ,OACN;AAAA,QAA+B,KAAK,UAClCyB,CACF,CAAC;AAAA;AAAA,CACH,CACF,CACF,CAEA,IAAMC,EAASF,EAAM,UAAU,CAAC,EAChC,GAAI,CAACE,EAAQ,CACXb,EAAgB,gBAChB,QACF,CAKA,GAHA/D,EAAI,eAAgB,KAAK,UAAU4E,EAAQ,KAAM,CAAC,CAAC,EACnDb,EAAgB,kBAEZa,GAAQ,OAAO,UAAY,CAACf,GAAY,CAACN,EAAa,CACxD,GAAI,CAACO,EAAmB,CACtB,IAAMe,EAAoB,CACxB,KAAM,sBACN,MAAO,EACP,cAAe,CAAE,KAAM,WAAY,SAAU,EAAG,CAClD,EACAb,EACEd,EAAQ,OACN;AAAA,QAAqC,KAAK,UACxC2B,CACF,CAAC;AAAA;AAAA,CACH,CACF,EACAf,EAAoB,EACtB,CACA,GAAIc,EAAO,MAAM,SAAS,UAAW,CACnC,IAAME,EAAoB,CACxB,KAAM,sBACN,MAAO,EACP,MAAO,CACL,KAAM,kBACN,UAAWF,EAAO,MAAM,SAAS,SACnC,CACF,EACAZ,EACEd,EAAQ,OACN;AAAA,QAAqC,KAAK,UACxC4B,CACF,CAAC;AAAA;AAAA,CACH,CACF,EAEA,IAAMC,EAAmB,CACvB,KAAM,qBACN,MAAO,CACT,EACAf,EACEd,EAAQ,OACN;AAAA,QAAoC,KAAK,UACvC6B,CACF,CAAC;AAAA;AAAA,CACH,CACF,CACF,SAAWH,EAAO,MAAM,SAAS,QAAS,CACxC,IAAMI,EAAgB,CACpB,KAAM,sBACN,MAAO,EACP,MAAO,CACL,KAAM,iBACN,SAAUJ,EAAO,MAAM,SAAS,SAAW,EAC7C,CACF,EACAZ,EACEd,EAAQ,OACN;AAAA,QAAqC,KAAK,UACxC8B,CACF,CAAC;AAAA;AAAA,CACH,CACF,CACF,CACF,CAEA,GAAIJ,GAAQ,OAAO,SAAW,CAACf,GAAY,CAACN,EAAa,CAIvD,GAHAI,IACAI,EAAgB,aAEZ,CAACT,GAAyB,CAACC,EAAa,CAC1CD,EAAwB,GACxB,IAAMuB,EAAoB,CACxB,KAAM,sBACN,MAAO,EACP,cAAe,CACb,KAAM,OACN,KAAM,EACR,CACF,EACA7E,EACE,iCACA,KAAK,UAAU6E,EAAmB,KAAM,CAAC,CAC3C,EACAb,EACEd,EAAQ,OACN;AAAA,QAAqC,KAAK,UACxC2B,CACF,CAAC;AAAA;AAAA,CACH,CACF,CACF,CAEA,GAAI,CAAChB,GAAY,CAACN,EAAa,CAC7B,IAAM0B,EAAiB,CACrB,KAAM,sBACN,MAAO,EACP,MAAO,CACL,KAAM,aACN,KAAML,EAAO,MAAM,OACrB,CACF,EACA5E,EAAI,eAAe,EACnBA,EACE,yCAAyC4E,EAAO,MAAM,OAAO,GAC/D,EACA5E,EACE,+BAA+BiF,EAAe,MAAM,IAAI,GAC1D,EAEAjB,EACEd,EAAQ,OACN;AAAA,QAAqC,KAAK,UACxC+B,CACF,CAAC;AAAA;AAAA,CACH,CACF,CACF,CACF,CAEA,GAAIL,GAAQ,OAAO,YAAc,CAACf,GAAY,CAACN,EAAa,CAC1DK,IACAG,EAAgB,iBAChB,IAAMmB,EAAuB,IAAI,IAEjC,QAAWC,KAAYP,EAAO,MAAM,WAAY,CAC9C,GAAIf,EAAU,MACd,IAAMuB,EAAgBD,EAAS,OAAS,EACxC,GAAID,EAAqB,IAAIE,CAAa,EACxC,SAMF,GAJAF,EAAqB,IAAIE,CAAa,EAEpC,CAAC3B,EAAiC,IAAI2B,CAAa,EAEjC,CAClB,IAAMC,EAAuB/B,EACzBG,EAAiC,KAAO,EACxCA,EAAiC,KACrC,GAAI4B,IAAyB,EAAG,CAC9B,IAAMN,EAAmB,CACvB,KAAM,qBACN,MAAOM,EAAuB,CAChC,EACArB,EACEd,EAAQ,OACN;AAAA,QAAoC,KAAK,UACvC6B,CACF,CAAC;AAAA;AAAA,CACH,CACF,CACF,CACAtB,EAAiC,IAC/B2B,EACAC,CACF,EACA,IAAMC,EACJH,EAAS,IAAM,QAAQ,KAAK,IAAI,CAAC,IAAIC,CAAa,GAC9CG,EACJJ,EAAS,UAAU,MAAQ,QAAQC,CAAa,GAC5CP,EAAoB,CACxB,KAAM,sBACN,MAAOQ,EACP,cAAe,CACb,KAAM,WACN,GAAIC,EACJ,KAAMC,EACN,MAAO,CAAC,CACV,CACF,EAEAvB,EACEd,EAAQ,OACN;AAAA,QAAqC,KAAK,UACxC2B,CACF,CAAC;AAAA;AAAA,CACH,CACF,EAEA,IAAMW,EAAe,CACnB,GAAIF,EACJ,KAAMC,EACN,UAAW,GACX,kBAAmBF,CACrB,EACA7B,EAAU,IAAI4B,EAAeI,CAAY,CAC3C,SAAWL,EAAS,IAAMA,EAAS,UAAU,KAAM,CACjD,IAAMM,EAAmBjC,EAAU,IAAI4B,CAAa,EAElDK,EAAiB,GAAG,WAAW,OAAO,GACtCA,EAAiB,KAAK,WAAW,OAAO,IAGxCA,EAAiB,GAAKN,EAAS,GAC/BM,EAAiB,KAAON,EAAS,SAAS,KAE9C,CAEA,GACEA,EAAS,UAAU,WACnB,CAACtB,GACD,CAACN,EACD,CACA,IAAMmC,EACJjC,EAAiC,IAAI2B,CAAa,EACpD,GAAIM,IAAe,OACjB,SAEF,IAAMC,EAAkBnC,EAAU,IAAI4B,CAAa,EACnD,GAAIO,EAAiB,CACnB,IAAMC,EAAeD,EAAgB,UACrCA,EAAgB,WACdR,EAAS,SAAS,UACpB,GAAI,CACF,IAAIU,EAAe,KACbC,EACJH,EAAgB,UAAU,KAAK,EACjC,GACEG,EAAY,WAAW,GAAG,GAC1BA,EAAY,SAAS,GAAG,EAExB,GAAI,CACFD,EAAe,KAAK,MAAMC,CAAW,CACvC,OAASC,EAAQ,CACf/F,EACE,mBACAoF,EACA,QACAW,EAAE,OACJ,CACF,CAEJ,OAASA,EAAQ,CACf/F,EACE,mBACAoF,EACA,QACAW,EAAE,OACJ,CACF,CACF,CAEA,GAAI,CACF,IAAMd,EAAiB,CACrB,KAAM,sBACN,MAAOS,EACP,MAAO,CACL,KAAM,mBACN,aAAcP,EAAS,SAAS,SAClC,CACF,EACAnB,EACEd,EAAQ,OACN;AAAA,QAAqC,KAAK,UACxC+B,CACF,CAAC;AAAA;AAAA,CACH,CACF,CACF,MAAgB,CACd,GAAI,CACF,IAAMe,EAAgBb,EAAS,SAAS,UACrC,QAAQ,wBAAyB,EAAE,EACnC,QAAQ,MAAO,MAAM,EACrB,QAAQ,KAAM,KAAK,EAEhBc,EAAa,CACjB,KAAM,sBACN,MAAOP,EACP,MAAO,CACL,KAAM,mBACN,aAAcM,CAChB,CACF,EACAhC,EACEd,EAAQ,OACN;AAAA,QAAqC,KAAK,UACxC+C,CACF,CAAC;AAAA;AAAA,CACH,CACF,CACF,OAASC,EAAU,CACjB,QAAQ,MAAMA,CAAQ,CACxB,CACF,CACF,CACF,CACF,CAEA,GAAItB,GAAQ,eAAiB,CAACf,GAAY,CAACN,EAAa,CAQtD,GAPAA,EAAc,GACVI,IAAkB,GAAKC,IAAmB,GAC5C,QAAQ,MACN,6CACF,EAGEN,GAAyB,CAACO,EAAU,CACtC,IAAMkB,EAAmB,CACvB,KAAM,qBACN,MAAO,CACT,EACAf,EACEd,EAAQ,OACN;AAAA,QAAoC,KAAK,UACvC6B,CACF,CAAC;AAAA;AAAA,CACH,CACF,CACF,CAEA,GAAInB,EAAiB,GAAK,CAACC,EAAU,CACnC,OAAW,CACTsC,EACAC,CACF,IAAK3C,EAAiC,QAAQ,EAAG,CAC/C,GAAII,EAAU,MACd,IAAMsB,EAAW3B,EAAU,IAAI2C,CAAO,EACtC,GAAIhB,GAAYA,EAAS,UACvB,GAAI,CACF,IAAIkB,EAAalB,EAAS,UAAU,KAAK,EACpCkB,EAAW,WAAW,GAAG,IAC5BA,EAAa,IAAMA,GAEhBA,EAAW,SAAS,GAAG,IAC1BA,EAAaA,EAAa,KAE5B,KAAK,MAAMA,CAAU,CACvB,OAASN,EAAQ,CACf/F,EACE,4CACA+F,EAAE,QACF,sBACAZ,EAAS,SACX,CACF,CAEJ,CAEA,IAAMJ,EAAmB,CACvB,KAAM,qBACN,MAAOtB,EAAiC,KAAO,CACjD,EACAO,EACEd,EAAQ,OACN;AAAA,QAAoC,KAAK,UACvC6B,CACF,CAAC;AAAA;AAAA,CACH,CACF,CACF,CACA,GAAI,CAAClB,EAAU,CAWb,IAAMyC,EAAe,CACnB,KAAM,gBACN,MAAO,CACL,YAbsB,CACxB,KAAM,WACN,OAAQ,aACR,WAAY,WACZ,eAAgB,eAClB,EAGoB1B,EAAO,aAAa,GAAK,WAMzC,cAAe,IACjB,EACA,MAAO,CACL,aAAcF,EAAM,OAAO,eAAiB,EAC5C,cAAeA,EAAM,OAAO,mBAAqB,CACnD,CACF,EACAV,EACEd,EAAQ,OACN;AAAA,QAA+B,KAAK,UAClCoD,CACF,CAAC;AAAA;AAAA,CACH,CACF,CACF,CAEA,GAAI,CAACzC,EAAU,CACb,IAAM0C,EAAc,CAClB,KAAM,cACR,EACAvC,EACEd,EAAQ,OACN;AAAA,QAA8B,KAAK,UACjCqD,CACF,CAAC;AAAA;AAAA,CACH,CACF,CACF,CAEA,KACF,CACF,MAAqB,CACnBxC,EAAgB,aAClB,CACF,CACF,CACF,CACAG,EAAU,CACZ,OAASjD,EAAO,CACd,GAAI,CAAC4C,EACH,GAAI,CACFZ,EAAW,MAAMhC,CAAK,CACxB,OAASuF,EAAiB,CACxB,QAAQ,MAAMA,CAAe,CAC/B,CAEJ,QAAE,CACA,GAAIrC,EACF,GAAI,CACFA,EAAO,YAAY,CACrB,OAASsC,EAAc,CACrB,QAAQ,MAAMA,CAAY,CAC5B,CAEJ,CACF,EACA,OAAOC,EAAQ,CACb1G,EAAI,iBAAkB0G,CAAM,CAC9B,CACF,CAAC,CAGH,CAEQ,iCACNC,EACK,CACL3G,EAAI,4BAA6B,KAAK,UAAU2G,EAAgB,KAAM,CAAC,CAAC,EAExE,IAAM/B,EAAS+B,EAAe,QAAQ,CAAC,EACvC,GAAI,CAAC/B,EACH,MAAM,IAAI,MAAM,qCAAqC,EAEvD,IAAMgC,EAAiB,CAAC,EACpBhC,EAAO,QAAQ,SACjBgC,EAAQ,KAAK,CACX,KAAM,OACN,KAAMhC,EAAO,QAAQ,OACvB,CAAC,EAECA,EAAO,QAAQ,YAAcA,EAAO,QAAQ,WAAW,OAAS,GAClEA,EAAO,QAAQ,WAAW,QAAQ,CAACO,EAAU7E,IAAU,CACrD,IAAIuG,EAAc,CAAC,EACnB,GAAI,CACF,IAAM7F,EAAemE,EAAS,SAAS,WAAa,KAEhD,OAAOnE,GAAiB,SAC1B6F,EAAc7F,EACL,OAAOA,GAAiB,WACjC6F,EAAc,KAAK,MAAM7F,CAAY,EAEzC,MAAqB,CACnB6F,EAAc,CAAE,KAAM1B,EAAS,SAAS,WAAa,EAAG,CAC1D,CAEAyB,EAAQ,KAAK,CACX,KAAM,WACN,GAAIzB,EAAS,GACb,KAAMA,EAAS,SAAS,KACxB,MAAO0B,CACT,CAAC,CACH,CAAC,EAGH,IAAM1F,EAAS,CACb,GAAIwF,EAAe,GACnB,KAAM,UACN,KAAM,YACN,MAAOA,EAAe,MACtB,QAASC,EACT,YACEhC,EAAO,gBAAkB,OACrB,WACAA,EAAO,gBAAkB,SACzB,aACAA,EAAO,gBAAkB,aACzB,WACAA,EAAO,gBAAkB,iBACzB,gBACA,WACN,cAAe,KACf,MAAO,CACL,aAAc+B,EAAe,OAAO,eAAiB,EACrD,cAAeA,EAAe,OAAO,mBAAqB,CAC5D,CACF,EACA,OAAA3G,EACE,iDACA,KAAK,UAAUmB,EAAQ,KAAM,CAAC,CAChC,EACOA,CACT,CACF,ECn5BO,IAAM2F,EAAN,KAA+C,CACpD,KAAO,SAEP,SAAW,wBAyBX,oBAAoBC,EAAiD,CACnE,OAAI,MAAM,QAAQA,EAAQ,KAAK,GAE7BA,EAAQ,MAAM,QAASC,GAAS,CAC9B,GAAIA,EAAK,SAAS,OAAS,YAAa,CAEtCA,EAAK,SAAS,WAAW,WAAW,YAAY,MAAM,WAAW,MAAM,KACrE,SACF,MACF,CACA,OAAO,KAAKA,EAAK,SAAS,WAAW,UAAU,EAAE,QAASC,GAAQ,CAChE,IAAMC,EAAOF,EAAK,SAAS,WAAW,WAAWC,CAAG,EAElDC,EAAK,OAAS,UACd,CAAC,CAAC,OAAQ,WAAW,EAAE,SAASA,EAAK,MAAM,GAE3C,OAAOA,EAAK,MAEhB,CAAC,CACH,CAAC,EAEIH,CACT,CAuBA,MAAM,qBAAqBI,EAAuC,CAChE,OAAOA,CACT,CACF,EC5EO,IAAMC,EAAN,KAAiD,CACtD,KAAO,WAEP,oBAAoBC,EAAiD,CACnE,OAAIA,EAAQ,YAAcA,EAAQ,WAAa,OAC7CA,EAAQ,WAAa,MAEhBA,CACT,CAEA,MAAM,qBAAqBC,EAAuC,CAChE,GAAIA,EAAS,QAAQ,IAAI,cAAc,GAAG,SAAS,kBAAkB,EAAG,CACtE,IAAMC,EAAe,MAAMD,EAAS,KAAK,EAEzC,OAAO,IAAI,SAAS,KAAK,UAAUC,CAAY,EAAG,CAChD,OAAQD,EAAS,OACjB,WAAYA,EAAS,WACrB,QAASA,EAAS,OACpB,CAAC,CACH,SAAWA,EAAS,QAAQ,IAAI,cAAc,GAAG,SAAS,QAAQ,EAAG,CAEnE,GAAI,CAACA,EAAS,KACZ,OAAOA,EAGT,IAAME,EAAU,IAAI,YACdC,EAAU,IAAI,YAChBC,EAAmB,GACnBC,EAAsB,GAEpBC,EAAS,IAAI,eAAe,CAChC,MAAM,MAAMC,EAAY,CACtB,IAAMC,EAASR,EAAS,KAAM,UAAU,EACxC,GAAI,CACF,OAAa,CACX,GAAM,CAAE,KAAAS,EAAM,MAAAC,CAAM,EAAI,MAAMF,EAAO,KAAK,EAC1C,GAAIC,EAAM,MAGV,IAAME,EADQT,EAAQ,OAAOQ,EAAO,CAAE,OAAQ,EAAK,CAAC,EAChC,MAAM;AAAA,CAAI,EAE9B,QAAWE,KAAQD,EACjB,GAAIC,EAAK,WAAW,QAAQ,GAAKA,EAAK,KAAK,IAAM,eAC/C,GAAI,CACF,IAAMC,EAAO,KAAK,MAAMD,EAAK,MAAM,CAAC,CAAC,EAGrC,GAAIC,EAAK,UAAU,CAAC,GAAG,OAAO,kBAAmB,CAC/CT,GAAoBS,EAAK,QAAQ,CAAC,EAAE,MAAM,kBAC1C,IAAMC,EAAgB,CACpB,GAAGD,EACH,QAAS,CAAC,CACR,GAAGA,EAAK,QAAQ,CAAC,EACjB,MAAO,CACL,GAAGA,EAAK,QAAQ,CAAC,EAAE,MACnB,SAAU,CACR,QAASA,EAAK,QAAQ,CAAC,EAAE,MAAM,iBACjC,CACF,CACF,CAAC,CACH,EACME,EAAe,SAAS,KAAK,UAAUD,CAAa,CAAC;AAAA;AAAA,EAC3DP,EAAW,QAAQJ,EAAQ,OAAOY,CAAY,CAAC,CACjD,CAGA,GAAIF,EAAK,UAAU,CAAC,GAAG,OAAO,SAAW,CAACA,EAAK,QAAQ,CAAC,EAAE,MAAM,mBAAqBT,GAAoB,CAACC,EAAqB,CAC7HA,EAAsB,GACtB,IAAMW,EAAY,KAAK,IAAI,EAAE,SAAS,EAGhCF,EAAgB,CACpB,GAAGD,EACH,QAAS,CAAC,CACR,GAAGA,EAAK,QAAQ,CAAC,EACjB,MAAO,CACL,GAAGA,EAAK,QAAQ,CAAC,EAAE,MACnB,SAAU,CACR,QAAST,EACT,UAAWY,CACb,CACF,CACF,CAAC,CACH,EAEA,QAAQ,IAAI,0BAA2BF,CAAa,EAGpD,IAAMC,EAAe,SAAS,KAAK,UAAUD,CAAa,CAAC;AAAA;AAAA,EAC3DP,EAAW,QAAQJ,EAAQ,OAAOY,CAAY,CAAC,CACjD,CAQA,GALIF,EAAK,UAAU,CAAC,GAAG,OAAO,mBAC5B,OAAOA,EAAK,QAAQ,CAAC,EAAE,MAAM,kBAI3BA,EAAK,UAAU,CAAC,GAAG,OAAS,OAAO,KAAKA,EAAK,QAAQ,CAAC,EAAE,KAAK,EAAE,OAAS,EAAG,CAC7E,IAAMI,EAAe,SAAS,KAAK,UAAUJ,CAAI,CAAC;AAAA;AAAA,EAClDN,EAAW,QAAQJ,EAAQ,OAAOc,CAAY,CAAC,CACjD,CACF,MAAY,CAEVV,EAAW,QAAQJ,EAAQ,OAAOS,EAAO;AAAA,CAAI,CAAC,CAChD,MAGAL,EAAW,QAAQJ,EAAQ,OAAOS,EAAO;AAAA,CAAI,CAAC,CAGpD,CACF,OAASM,EAAO,CACdX,EAAW,MAAMW,CAAK,CACxB,QAAE,CACA,GAAI,CACFV,EAAO,YAAY,CACrB,MAAY,CAEZ,CACAD,EAAW,MAAM,CACnB,CACF,CACF,CAAC,EAED,OAAO,IAAI,SAASD,EAAQ,CAC1B,OAAQN,EAAS,OACjB,WAAYA,EAAS,WACrB,QAAS,CACP,eAAgBA,EAAS,QAAQ,IAAI,cAAc,GAAK,aACxD,gBAAiB,WACjB,WAAc,YAChB,CACF,CAAC,CACH,CAEA,OAAOA,CACT,CACF,EC7HO,IAAMmB,EAAN,KAAyB,CACtB,aAAyC,IAAI,IAErD,aAAc,CACZ,KAAK,WAAW,CAClB,CAEA,oBAAoBC,EAAcC,EAAgC,CAChE,KAAK,aAAa,IAAID,EAAMC,CAAW,EACvCC,EACE,yBAAyBF,CAAI,GAC3BC,EAAY,SACR,eAAeA,EAAY,QAAQ,IACnC,mBACN,EACF,CACF,CAEA,eAAeD,EAAuC,CACpD,OAAO,KAAK,aAAa,IAAIA,CAAI,CACnC,CAEA,oBAA+C,CAC7C,OAAO,IAAI,IAAI,KAAK,YAAY,CAClC,CAEA,6BAA4E,CAC1E,IAAMG,EAAuD,CAAC,EAE9D,YAAK,aAAa,QAAQ,CAACF,EAAaD,IAAS,CAC3CC,EAAY,UACdE,EAAO,KAAK,CAAE,KAAAH,EAAM,YAAAC,CAAY,CAAC,CAErC,CAAC,EAEME,CACT,CAEA,gCAGI,CACF,IAAMA,EAAuD,CAAC,EAE9D,YAAK,aAAa,QAAQ,CAACF,EAAaD,IAAS,CAC1CC,EAAY,UACfE,EAAO,KAAK,CAAE,KAAAH,EAAM,YAAAC,CAAY,CAAC,CAErC,CAAC,EAEME,CACT,CAEA,kBAAkBH,EAAuB,CACvC,OAAO,KAAK,aAAa,OAAOA,CAAI,CACtC,CAEA,eAAeA,EAAuB,CACpC,OAAO,KAAK,aAAa,IAAIA,CAAI,CACnC,CAEA,MAAM,8BAA8BI,EAGf,CACnB,GAAI,CACF,GAAIA,EAAO,KAAM,CACf,IAAMC,EAAS,QAAQD,EAAO,IAAI,EAClC,GAAIC,EAAQ,CACV,IAAMC,EAAW,IAAID,EAAOD,EAAO,OAAO,EAC1C,GAAI,CAACE,EAAS,KACZ,MAAM,IAAI,MACR,6BAA6BF,EAAO,IAAI,iCAC1C,EAEF,YAAK,oBAAoBE,EAAS,KAAMA,CAAQ,EACzC,EACT,CACF,CACA,MAAO,EACT,OAASC,EAAO,CACd,OAAAL,EAAI,qBAAqBE,EAAO,IAAI,KAAMG,CAAK,EACxC,EACT,CACF,CAEA,MAAc,YAA4B,CACxC,GAAI,CACF,MAAM,KAAK,oCAAoC,EAC/C,MAAM,KAAK,eAAe,CAC5B,OAASA,EAAO,CACdL,EAAI,iCAAkCK,CAAK,CAC7C,CACF,CAEA,MAAc,qCAAqD,CACjE,GAAI,CACF,IAAMC,EAAY,IAAIC,EAChBC,EAAS,IAAIC,EACbC,EAAW,IAAIC,EACrB,KAAK,oBAAoBL,EAAU,KAAMA,CAAS,EAClD,KAAK,oBAAoBE,EAAO,KAAMA,CAAM,EAC5C,KAAK,oBAAoBE,EAAS,KAAMA,CAAQ,CAClD,OAASL,EAAO,CACdL,EAAI,4BAA6BK,CAAK,CACxC,CACF,CAEA,MAAc,gBAAgC,CAC5C,IAAMO,EAAeC,EAAc,IACjC,eACA,CAAC,CACH,EACA,QAAWd,KAAea,EACxB,MAAM,KAAK,8BAA8Bb,CAAW,CAExD,CACF,ECpHO,IAAMe,GAAwC,MACnDC,GACG,CACH,IAAMC,EAAa,IAAIC,EACjBC,EAAkB,IAAIC,EACtBC,EAAqB,IAAIC,EAG/BN,EAAQ,IAAI,IAAK,MAAOO,EAASC,KACxB,CAAE,QAAS,WAAY,QAAS,OAAQ,EAChD,EAEDR,EAAQ,IAAI,UAAW,MAAOO,EAASC,KAC9B,CAAE,OAAQ,KAAM,UAAW,IAAI,KAAK,EAAE,YAAY,CAAE,EAC5D,EAGDR,EAAQ,KACN,uBACA,CACE,OAAQ,CACN,KAAM,CACJ,KAAM,SACN,WAAY,CACV,SAAU,CAAE,KAAM,OAAQ,EAC1B,MAAO,CAAE,KAAM,QAAS,EACxB,WAAY,CAAE,KAAM,QAAS,EAC7B,YAAa,CAAE,KAAM,QAAS,EAC9B,OAAQ,CAAE,KAAM,SAAU,CAC5B,EACA,SAAU,CAAC,WAAY,OAAO,CAChC,CACF,CACF,EACA,MAAOO,EAAyBC,IAAwB,CACtD,IAAMC,EAAW,MAAMR,EAAW,0BAA0B,CAC1D,GAAIM,EAAQ,KACZ,MAAO,yBACP,WAAY,IACd,CAAC,EAGD,OADkBA,EAAQ,MAAc,SAAW,IAEjDC,EAAM,OAAO,eAAgB,mBAAmB,EAChDA,EAAM,OAAO,gBAAiB,UAAU,EACxCA,EAAM,OAAO,aAAc,YAAY,EAChCA,EAAM,KAAKC,EAAS,IAAI,GAExBA,EAAS,KAAK,CAEzB,CACF,EAEA,IAAMC,EACJL,EAAmB,4BAA4B,EAEjD,OAAW,CAAE,KAAAM,EAAM,YAAAC,CAAY,IAAKF,EAC9BE,EAAY,UACdZ,EAAQ,KACNY,EAAY,SACZ,MAAOC,EAAqBL,IAAwB,CAClD,IAAMM,EAAOD,EAAI,KACXE,EAAeF,EAAI,SACnBG,EAAWb,EAAgB,YAAYY,CAAY,EACzD,GAAI,CAACC,EACH,MAAMC,EACJ,aAAaF,CAAY,cACzB,IACA,oBACF,EAEF,IAAIG,EACF,OAAON,EAAY,qBAAwB,WACvCA,EAAY,oBAAoBE,CAA0B,EAC1DA,EACN,GAAIE,EAAS,aAAa,KAAK,OAC7B,QAAWG,KAAmBH,EAAS,YAAY,IAAK,CACtD,IAAMJ,EAAcP,EAAmB,eAAec,CAAe,EACjE,CAACP,GAAe,OAAOA,EAAY,qBAAwB,aAG/DM,EAAcN,EAAY,oBAAoBM,CAAW,EAC3D,CAEF,GAAIF,EAAS,eAAeH,EAAI,KAAK,KAAK,GAAG,KAAK,OAChD,QAAWM,KAAmBH,EAAS,aAAaH,EAAI,KAAK,KAAK,EAAE,IAAK,CACvE,IAAMD,EAAcP,EAAmB,eAAec,CAAe,EACjE,CAACP,GAAe,OAAOA,EAAY,qBAAwB,aAG/DM,EAAcN,EAAY,oBAAoBM,CAAW,EAC3D,CAEF,IAAME,EAAM,IAAI,IACd,uBACAJ,EAAS,QAAQ,SAAS,GAAG,EAAIA,EAAS,QAAU,GAAGA,EAAS,OAAO,GACzE,EAMIK,EALa,MAAMC,EAAmBF,EAAKF,EAAa,CAC1D,QAAS,CACP,cAAiB,UAAUF,EAAS,MAAM,EAC5C,CACF,CAAC,EAED,GAAIA,EAAS,aAAa,KAAK,OAC7B,QAAWG,KAAmBH,EAAS,YAAY,IAAK,CACtD,IAAMJ,EAAcP,EAAmB,eAAec,CAAe,EACjE,CAACP,GAAe,OAAOA,EAAY,sBAAyB,aAGhES,EAAgB,MAAMT,EAAY,qBAAqBS,CAAa,EACtE,CAEF,GAAIL,EAAS,eAAeH,EAAI,KAAK,KAAK,GAAG,KAAK,OAChD,QAAWM,KAAmBH,EAAS,aAAaH,EAAI,KAAK,KAAK,EAAE,IAAK,CACvE,IAAMD,EAAcP,EAAmB,eAAec,CAAe,EACjE,CAACP,GAAe,OAAOA,EAAY,sBAAyB,aAGhES,EAAgB,MAAMT,EAAY,qBAAqBS,CAAa,EACtE,CASF,OAPIT,EAAY,uBACdS,EAAgB,MAAMT,EAAY,qBAAqBS,CAAa,GAEjEA,EAAc,IACjBb,EAAM,KAAKa,EAAc,MAAM,EAEhBP,GAAM,SAAW,IAEhCN,EAAM,OAAO,eAAgB,mBAAmB,EAChDA,EAAM,OAAO,gBAAiB,UAAU,EACxCA,EAAM,OAAO,aAAc,YAAY,EAChCA,EAAM,KAAKa,EAAc,IAAI,GAE7BA,EAAc,KAAK,CAE9B,CACF,EAIJrB,EAAQ,KACN,aACA,CACE,OAAQ,CACN,KAAM,CACJ,KAAM,SACN,WAAY,CACV,GAAI,CAAE,KAAM,QAAS,EACrB,KAAM,CAAE,KAAM,QAAS,EACvB,KAAM,CAAE,KAAM,SAAU,KAAM,CAAC,SAAU,WAAW,CAAE,EACtD,QAAS,CAAE,KAAM,QAAS,EAC1B,OAAQ,CAAE,KAAM,QAAS,EACzB,OAAQ,CAAE,KAAM,QAAS,MAAO,CAAE,KAAM,QAAS,CAAE,CACrD,EACA,SAAU,CAAC,KAAM,OAAQ,OAAQ,UAAW,SAAU,QAAQ,CAChE,CACF,CACF,EACA,MACEO,EACAC,IACG,CAEH,GAAM,CAAE,KAAAG,EAAM,KAAAY,EAAM,QAAAC,EAAS,OAAAC,EAAQ,OAAAC,CAAO,EAAInB,EAAQ,KAExD,GAAI,CAACI,GAAM,KAAK,EACd,MAAMM,EACJ,4BACA,IACA,iBACF,EAGF,GAAI,CAACO,GAAW,CAACG,GAAWH,CAAO,EACjC,MAAMP,EACJ,6BACA,IACA,iBACF,EAGF,GAAI,CAACQ,GAAQ,KAAK,EAChB,MAAMR,EAAe,sBAAuB,IAAK,iBAAiB,EAGpE,GAAI,CAACS,GAAU,CAAC,MAAM,QAAQA,CAAM,GAAKA,EAAO,SAAW,EACzD,MAAMT,EACJ,iCACA,IACA,iBACF,EAIF,GAAId,EAAgB,YAAY,EAAE,EAChC,MAAMc,EACJ,qBAAqB,EAAE,mBACvB,IACA,iBACF,EAIF,OADiBd,EAAgB,iBAAiBI,EAAQ,IAAI,CAEhE,CACF,EAEAP,EAAQ,IAAI,aAAc,MAAOO,EAASC,IACjCL,EAAgB,aAAa,CACrC,EAEDH,EAAQ,IACN,iBACA,CACE,OAAQ,CACN,OAAQ,CACN,KAAM,SACN,WAAY,CAAE,GAAI,CAAE,KAAM,QAAS,CAAE,EACrC,SAAU,CAAC,IAAI,CACjB,CACF,CACF,EACA,MAAOO,EAAqDC,IAAU,CACpE,IAAMQ,EAAWb,EAAgB,YAAYI,EAAQ,OAAO,EAAE,EAC9D,OAAKS,GACIR,EAAM,KAAK,GAAG,EAAE,KAAK,CAAE,MAAO,oBAAqB,CAAC,CAG/D,CACF,EAEAR,EAAQ,IACN,iBACA,CACE,OAAQ,CACN,OAAQ,CACN,KAAM,SACN,WAAY,CAAE,GAAI,CAAE,KAAM,QAAS,CAAE,EACrC,SAAU,CAAC,IAAI,CACjB,EACA,KAAM,CACJ,KAAM,SACN,WAAY,CACV,KAAM,CAAE,KAAM,QAAS,EACvB,KAAM,CAAE,KAAM,SAAU,KAAM,CAAC,SAAU,WAAW,CAAE,EACtD,QAAS,CAAE,KAAM,QAAS,EAC1B,OAAQ,CAAE,KAAM,QAAS,EACzB,OAAQ,CAAE,KAAM,QAAS,MAAO,CAAE,KAAM,QAAS,CAAE,EACnD,QAAS,CAAE,KAAM,SAAU,CAC7B,CACF,CACF,CACF,EACA,MACEO,EAIAC,IACG,CACH,IAAMQ,EAAWb,EAAgB,eAC/BI,EAAQ,OAAO,GACfA,EAAQ,IACV,EACA,OAAKS,GACIR,EAAM,KAAK,GAAG,EAAE,KAAK,CAAE,MAAO,oBAAqB,CAAC,CAG/D,CACF,EAEAR,EAAQ,OACN,iBACA,CACE,OAAQ,CACN,OAAQ,CACN,KAAM,SACN,WAAY,CAAE,GAAI,CAAE,KAAM,QAAS,CAAE,EACrC,SAAU,CAAC,IAAI,CACjB,CACF,CACF,EACA,MAAOO,EAAqDC,IAC1CL,EAAgB,eAAeI,EAAQ,OAAO,EAAE,EAIzD,CAAE,QAAS,+BAAgC,EAFzCC,EAAM,KAAK,GAAG,EAAE,KAAK,CAAE,MAAO,oBAAqB,CAAC,CAIjE,EAEAR,EAAQ,MACN,wBACA,CACE,OAAQ,CACN,OAAQ,CACN,KAAM,SACN,WAAY,CAAE,GAAI,CAAE,KAAM,QAAS,CAAE,EACrC,SAAU,CAAC,IAAI,CACjB,EACA,KAAM,CACJ,KAAM,SACN,WAAY,CAAE,QAAS,CAAE,KAAM,SAAU,CAAE,EAC3C,SAAU,CAAC,SAAS,CACtB,CACF,CACF,EACA,MACEO,EAIAC,IAEgBL,EAAgB,eAC9BI,EAAQ,OAAO,GACfA,EAAQ,KAAK,OACf,EAIO,CACL,QAAS,YAAYA,EAAQ,KAAK,QAAU,UAAY,UACtD,eACJ,EALSC,EAAM,KAAK,GAAG,EAAE,KAAK,CAAE,MAAO,oBAAqB,CAAC,CAOjE,CACF,EAGA,SAASmB,GAAWP,EAAsB,CACxC,GAAI,CACF,WAAI,IAAIA,CAAG,EACJ,EACT,MAAQ,CACN,MAAO,EACT,CACF,CZhVA,eAAeQ,IAAsC,CACnD,IAAMC,KAAU,GAAAC,SAAQ,CACtB,OAAQC,EAAc,IAAI,UAAU,IAAM,MAC5C,CAAC,EAGD,OAAAF,EAAQ,gBAAgBG,EAAY,EAGpC,MAAMH,EAAQ,SAAS,GAAAI,OAAI,EAE3BJ,EAAQ,QACN,aACA,MAAOK,EAAqBC,IAAwB,CAClD,GAAI,CAEF,GAAI,CAACD,EAAI,MAAQ,CAACA,EAAI,KAAK,MACzB,OAAOC,EACJ,KAAK,GAAG,EACR,KAAK,CAAE,MAAO,+BAAgC,CAAC,EAEpD,GAAM,CAACC,EAAUC,CAAK,EAAIH,EAAI,KAAK,MAAM,MAAM,GAAG,EAClDA,EAAI,KAAK,MAAQG,EACjBH,EAAI,SAAWE,EACf,MACF,OAASE,EAAK,CACZ,OAAAJ,EAAI,IAAI,MAAM,oCAAqCI,CAAG,EAC/CH,EAAM,KAAK,GAAG,EAAE,KAAK,CAAE,MAAO,uBAAwB,CAAC,CAChE,CACF,CACF,EAGA,MAAMN,EAAQ,SAASU,EAAiB,EAEjCV,CACT,CAGA,IAAMW,EAAN,KAAa,CACH,OAER,aAAc,CACZ,KAAK,OAAS,CACZ,KAAM,SAAST,EAAc,IAAI,MAAM,GAAK,OAAQ,EAAE,EACtD,KAAMA,EAAc,IAAI,MAAM,GAAK,UACnC,OAAQA,EAAc,IAAI,UAAU,IAAM,MAC5C,CACF,CAEA,MAAM,OAAuB,CAC3B,GAAI,CACF,IAAMU,EAAM,MAAMb,GAAU,EAEtBc,EAAU,MAAMD,EAAI,OAAO,CAC/B,KAAM,KAAK,OAAO,KAClB,KAAM,KAAK,OAAO,IACpB,CAAC,EAEDE,EAAI,sDAA+CD,CAAO,EAAE,EAE5D,IAAME,EAAW,MAAOC,GAAmB,CACzCF,EAAI,YAAYE,CAAM,+BAA+B,EACrD,MAAMJ,EAAI,MAAM,EAChB,QAAQ,KAAK,CAAC,CAChB,EAEA,QAAQ,GAAG,SAAU,IAAMG,EAAS,QAAQ,CAAC,EAC7C,QAAQ,GAAG,UAAW,IAAMA,EAAS,SAAS,CAAC,CACjD,OAASE,EAAO,CACdH,EAAI,0BAA0BG,CAAK,EAAE,EACrC,QAAQ,KAAK,CAAC,CAChB,CACF,CACF,EAGA,eAAeC,IAAO,CAEpBJ,EAAI,iCAA0B,EAC9BA,EAAIZ,EAAc,iBAAiB,CAAC,EAGpC,MADe,IAAIS,EAAO,EACb,MAAM,CACrB,CAGA,QAAQ,GAAG,qBAAsB,CAACQ,EAAQC,IAAY,CACpDN,EAAI,2BAA2BM,CAAO,aAAaD,CAAM,EAAE,EAC3D,QAAQ,KAAK,CAAC,CAChB,CAAC,EAED,QAAQ,GAAG,oBAAsBF,GAAU,CACzCH,EAAI,uBAAuBG,CAAK,EAAE,EAClC,QAAQ,KAAK,CAAC,CAChB,CAAC,EAEG,QAAQ,OAAS,QACnBC,GAAK,EAAE,MAAM,QAAQ,KAAK",
  "names": ["import_fastify", "import_cors", "import_fs", "import_path", "import_dotenv", "ConfigService", "options", "jsonPath", "jsonContent", "jsonConfig", "error", "envPath", "result", "envConfig", "env", "parsed", "path", "key", "defaultValue", "value", "summary", "configService", "import_node_fs", "LOG_FILE", "log", "args", "logMessage", "arg", "fs", "createApiError", "message", "statusCode", "code", "type", "error", "errorHandler", "request", "reply", "response", "ProviderService", "providersConfig", "configService", "providerConfig", "log", "error", "request", "provider", "model", "fullModel", "route", "id", "updates", "updatedProvider", "enabled", "modelName", "modelNames", "models", "convertToolsToOpenAI", "tools", "tool", "convertToolsToAnthropic", "convertToolsFromOpenAI", "convertToolsFromAnthropic", "convertToOpenAI", "request", "messages", "toolResponsesQueue", "msg", "i", "message", "toolCall", "response", "id", "responses", "result", "convertToAnthropic", "systemMessages", "nonSystemMessages", "system", "log", "content", "j", "toolResponses", "toolMsg", "lastProcessedIndex", "hasUnprocessedToolMessages", "unprocessedToolMessages", "toolResultsContent", "isToolCallContent", "parsed", "item", "convertFromOpenAI", "convertedToolCalls", "call", "convertFromAnthropic", "pendingToolCalls", "pendingTextContent", "lastRole", "assistantMessage", "textBlocks", "toolCalls", "toolResults", "block", "toolResult", "prevAssistantMessage", "convertRequest", "options", "unifiedRequest", "import_undici", "sendUnifiedRequest", "url", "request", "config", "headers", "key", "value", "combinedSignal", "timeoutSignal", "controller", "abortHandler", "fetchOptions", "httpsProxy", "configService", "LLMService", "ProviderService", "request", "id", "updates", "enabled", "modelName", "route", "requestBody", "signal", "provider", "targetModel", "unifiedReq", "providerRequest", "convertRequest", "response", "sendUnifiedRequest", "isStream", "convertedStream", "data", "openaiResponse", "error", "errorStream", "anthropicResponse", "textContent", "content", "tool_calls", "toolUse", "index", "anthropicStream", "controller", "encoder", "messageId", "model", "toolCalls", "isClosed", "safeEnqueue", "log", "safeClose", "reader", "decoder", "buffer", "done", "value", "lines", "line", "chunk", "openaiChunk", "block", "toolCallId", "toolCall", "delta", "stopReason", "parseError", "controllerError", "releaseError", "reason", "errorChunk", "openaiRequest", "msg", "tools", "tool", "AnthropicTransformer", "request", "log", "messages", "systemContent", "item", "requestMessages", "msg", "index", "unifiedMsg", "textParts", "toolUseContent", "c", "toolResultContent", "contentItem", "contentIndex", "tool", "toolIndex", "argumentsStr", "error", "hasAssistantContent", "result", "resultIndex", "toolMessage", "response", "convertedStream", "data", "anthropicResponse", "processedMessages", "allToolResults", "toolResultToMessageIndex", "msgIndex", "usedToolResultIds", "i", "currentMsg", "toolUseItems", "nextMsg", "toolUseIds", "hasAllResults", "nextMsgToolResultIds", "id", "missingIds", "foundResults", "missingId", "foundResult", "toolResultMsg", "remainingContent", "modifiedMsg", "removedCount", "tools", "openaiStream", "controller", "encoder", "messageId", "model", "hasStarted", "hasTextContentStarted", "hasFinished", "toolCalls", "toolCallIndexToContentBlockIndex", "totalChunks", "contentChunks", "toolCallChunks", "isClosed", "isThinkingStarted", "conversionStats", "safeEnqueue", "dataStr", "safeClose", "reader", "decoder", "buffer", "done", "value", "lines", "line", "chunk", "messageStart", "choice", "contentBlockStart", "thinkingSignature", "contentBlockStop", "thinkingChunk", "anthropicChunk", "processedInThisChunk", "toolCall", "toolCallIndex", "newContentBlockIndex", "toolCallId", "toolCallName", "toolCallInfo", "existingToolCall", "blockIndex", "currentToolCall", "oldArguments", "parsedParams", "trimmedArgs", "e", "fixedArgument", "fixedChunk", "fixError", "toolIdx", "blockIdx", "jsonString", "messageDelta", "messageStop", "controllerError", "releaseError", "reason", "openaiResponse", "content", "parsedInput", "GeminiTransformer", "request", "tool", "key", "prop", "response", "DeepseekTransformer", "request", "response", "jsonResponse", "decoder", "encoder", "reasoningContent", "isReasoningComplete", "stream", "controller", "reader", "done", "value", "lines", "line", "data", "thinkingChunk", "thinkingLine", "signature", "modifiedLine", "error", "TransformerService", "name", "transformer", "log", "result", "config", "module", "instance", "error", "anthropic", "AnthropicTransformer", "gemini", "GeminiTransformer", "deepseek", "DeepseekTransformer", "transformers", "configService", "registerApiRoutes", "fastify", "llmService", "LLMService", "providerService", "ProviderService", "transformerService", "TransformerService", "request", "reply", "response", "transformersWithEndpoint", "name", "transformer", "req", "body", "providerNmae", "provider", "createApiError", "requestBody", "transformerName", "url", "finalResponse", "sendUnifiedRequest", "type", "baseUrl", "apiKey", "models", "isValidUrl", "createApp", "fastify", "Fastify", "configService", "errorHandler", "cors", "req", "reply", "provider", "model", "err", "registerApiRoutes", "Server", "app", "address", "log", "shutdown", "signal", "error", "main", "reason", "promise"]
}
